//! # cudnn64_9
//!
//! Safe Rust wrapper for cudnn64_9 C library.
//!
//! This crate was automatically generated by [bindings-generat](https://github.com/your-repo/bindings-generat).
//! It provides safe, idiomatic Rust wrappers around the raw FFI bindings,
//! handling resource management, error conversion, and type safety.
//!
//! ## Features
//!
//! - **RAII Resource Management**: Automatically manages handle lifecycles
//!   with proper Drop implementations for leak-free usage
//! - **Type-Safe Error Handling**: Converts C error codes to Rust Result types
//!   with descriptive error messages
//! - **Idiomatic Rust API**: Methods on wrapper types instead of raw C functions
//! - **Comprehensive Safety**: All unsafe code is carefully encapsulated
//!   with safe interfaces
//!
//! ## Usage
//!
//! ```ignore
//! use cudnn64_9::*;
//!
//! fn main() -> Result<(), Error> {
//!     // Create a handle (specific constructor depends on library)
//!     // let handle = Handle::new()?;
//!     
//!     // Use methods on the handle
//!     // handle.some_operation()?;
//!     
//!     // Handle is automatically cleaned up when dropped
//!     Ok(())
//! }
//! ```
//!
//! ## Error Handling
//!
//! All fallible operations return `Result<T, Error>`. The `Error` type
//! implements `std::error::Error` and provides human-readable error messages.
//!
//! ```ignore
//! match handle.operation() {
//!     Ok(result) => { /* success */ },
//!     Err(Error::NotInitialized) => { /* handle specific error */ },
//!     Err(e) => { /* handle other errors */ },
//! }
//! ```
//!
//! ## Safety
//!
//! This crate encapsulates all `unsafe` FFI calls behind safe Rust interfaces.
//! Resource management is handled automatically through RAII patterns:
//!
//! - Handles are created with safe constructors
//! - Resources are automatically freed when handles are dropped
//! - Null pointer checks prevent undefined behavior
//! - Error codes are converted to Rust Result types
//!
//! ## Thread Safety
//!
//! Thread safety depends on the underlying C library. Check the
//! original library documentation for threading requirements and restrictions.
//! Most handles are `!Send` and `!Sync` by default for safety.
//!
//! ## Performance
//!
//! The wrapper layer has minimal overhead:
//!
//! - Wrapper types are zero-cost abstractions (transparent wrappers)
//! - Methods are marked `#[inline]` for optimization
//! - No runtime overhead beyond error code checks
//!
//! ## Documentation
//!
//! For detailed documentation about the underlying C library, please refer
//! to the official cudnn64_9 documentation.
//!
//! ## Generated Code
//!
//! This crate is automatically generated. To customize the bindings:
//!
//! 1. Modify the source headers or configuration
//! 2. Re-run bindings-generat
//! 3. Review the generated code for correctness
//!
//! ## License
//!
//! The generated bindings follow the same license as the original cudnn64_9 library.
//! Please check the library's license before using these bindings.

#![allow(dead_code)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]

// Note: FFI bindings should be in src/ffi.rs
// Run bindgen on your headers and place the output there
#[path = "ffi.rs"]
mod ffi;

// FFI types are available via the `ffi` module (use `ffi::TypeName`)

/// Error type for this library
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Error {
    /// Null pointer returned
    NullPointer,
    /// Invalid parameter value
    InvalidParameter,
    /// Invalid string (contains null byte)
    InvalidString,
    /// FFI function returned an error status
    FfiError(i32),
    /// Unknown error
    Unknown,
}

impl From<i32> for Error {
    fn from(code: i32) -> Self {
        if code == 0 {
            // Success code should not become an error
            Error::Unknown
        } else {
            Error::FfiError(code)
        }
    }
}

impl std::fmt::Display for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Error::NullPointer => write!(f, "Null pointer returned"),
            Error::InvalidParameter => write!(f, "Invalid parameter value"),
            Error::InvalidString => write!(f, "Invalid string: contains null byte"),
            Error::FfiError(code) => write!(f, "FFI error: {}", code),
            Error::Unknown => write!(f, "Unknown error"),
        }
    }
}

impl std::error::Error for Error {}

impl Error {
    /// Returns true if this error might be retryable
    pub fn is_retryable(&self) -> bool {
        // Basic errors are generally not retryable
        false
    }

    /// Returns true if this error indicates a fatal condition
    pub fn is_fatal(&self) -> bool {
        match self {
            Error::NullPointer => true,
            Error::InvalidParameter => false,
            Error::InvalidString => false,
            Error::Unknown => true,
            Error::FfiError(_) => false, // Unknown without enum details
        }
    }
}

/// Safe wrapper for `cudnnRNNDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnRNNDescriptor {
    handle: ffi::cudnnRNNDescriptor_t,
}

impl CudnnRNNDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateRNNDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnRNNDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnRNNDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnRNNDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnRNNDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyRNNDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnSpatialTransformerDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnSpatialTransformerDescriptor {
    handle: ffi::cudnnSpatialTransformerDescriptor_t,
}

impl CudnnSpatialTransformerDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateSpatialTransformerDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnSpatialTransformerDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnSpatialTransformerDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnSpatialTransformerDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnSpatialTransformerDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroySpatialTransformerDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaUserObject_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaUserObject {
    handle: ffi::cudaUserObject_t,
}

impl CudaUserObject {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaUserObjectCreate
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaUserObject_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaUserObject_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaUserObject_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaUserObject {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaUserObjectRelease(self.handle, 1);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnSeqDataDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnSeqDataDescriptor {
    handle: ffi::cudnnSeqDataDescriptor_t,
}

impl CudnnSeqDataDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateSeqDataDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnSeqDataDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnSeqDataDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnSeqDataDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnSeqDataDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroySeqDataDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnActivationDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnActivationDescriptor {
    handle: ffi::cudnnActivationDescriptor_t,
}

impl CudnnActivationDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateActivationDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnActivationDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnActivationDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnActivationDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnActivationDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyActivationDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnAttnDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnAttnDescriptor {
    handle: ffi::cudnnAttnDescriptor_t,
}

impl CudnnAttnDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateAttnDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnAttnDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnAttnDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnAttnDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnAttnDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyAttnDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaStream_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaStream {
    handle: ffi::cudaStream_t,
}

impl CudaStream {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaStreamCreate
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaStream_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaStream_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaStream_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaStream {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaStreamDestroy(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnFusedOpsPlan_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnFusedOpsPlan {
    handle: ffi::cudnnFusedOpsPlan_t,
}

impl CudnnFusedOpsPlan {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateFusedOpsPlan
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnFusedOpsPlan_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnFusedOpsPlan_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnFusedOpsPlan_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnFusedOpsPlan {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyFusedOpsPlan(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaMipmappedArray_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaMipmappedArray {
    handle: ffi::cudaMipmappedArray_t,
}

impl CudaMipmappedArray {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaMallocMipmappedArray
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaMipmappedArray_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaMipmappedArray_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaMipmappedArray_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaMipmappedArray {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaFreeMipmappedArray(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnFusedOpsConstParamPack_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnFusedOpsConstParamPack {
    handle: ffi::cudnnFusedOpsConstParamPack_t,
}

impl CudnnFusedOpsConstParamPack {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateFusedOpsConstParamPack
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnFusedOpsConstParamPack_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnFusedOpsConstParamPack_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnFusedOpsConstParamPack_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnFusedOpsConstParamPack {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyFusedOpsConstParamPack(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnTensorTransformDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnTensorTransformDescriptor {
    handle: ffi::cudnnTensorTransformDescriptor_t,
}

impl CudnnTensorTransformDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateTensorTransformDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnTensorTransformDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnTensorTransformDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnTensorTransformDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnTensorTransformDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyTensorTransformDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnPoolingDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnPoolingDescriptor {
    handle: ffi::cudnnPoolingDescriptor_t,
}

impl CudnnPoolingDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreatePoolingDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnPoolingDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnPoolingDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnPoolingDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnPoolingDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyPoolingDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnOpTensorDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnOpTensorDescriptor {
    handle: ffi::cudnnOpTensorDescriptor_t,
}

impl CudnnOpTensorDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateOpTensorDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnOpTensorDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnOpTensorDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnOpTensorDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnOpTensorDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyOpTensorDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnReduceTensorDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnReduceTensorDescriptor {
    handle: ffi::cudnnReduceTensorDescriptor_t,
}

impl CudnnReduceTensorDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateReduceTensorDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnReduceTensorDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnReduceTensorDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnReduceTensorDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnReduceTensorDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyReduceTensorDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnDropoutDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnDropoutDescriptor {
    handle: ffi::cudnnDropoutDescriptor_t,
}

impl CudnnDropoutDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateDropoutDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnDropoutDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnDropoutDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnDropoutDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnDropoutDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyDropoutDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaEvent_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaEvent {
    handle: ffi::cudaEvent_t,
}

impl CudaEvent {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaIpcOpenEventHandle
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaEvent_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaEvent_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaEvent_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaEvent {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaEventDestroy(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnCTCLossDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnCTCLossDescriptor {
    handle: ffi::cudnnCTCLossDescriptor_t,
}

impl CudnnCTCLossDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateCTCLossDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnCTCLossDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnCTCLossDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnCTCLossDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnCTCLossDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyCTCLossDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnHandle_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnHandle {
    handle: ffi::cudnnHandle_t,
}

impl CudnnHandle {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreate
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnHandle_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnHandle_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnHandle_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnHandle {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroy(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnFilterDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnFilterDescriptor {
    handle: ffi::cudnnFilterDescriptor_t,
}

impl CudnnFilterDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateFilterDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnFilterDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnFilterDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnFilterDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnFilterDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyFilterDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaMemPool_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaMemPool {
    handle: ffi::cudaMemPool_t,
}

impl CudaMemPool {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaMemPoolCreate
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaMemPool_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaMemPool_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaMemPool_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaMemPool {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaMemPoolDestroy(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnConvolutionDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnConvolutionDescriptor {
    handle: ffi::cudnnConvolutionDescriptor_t,
}

impl CudnnConvolutionDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateConvolutionDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnConvolutionDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnConvolutionDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnConvolutionDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnConvolutionDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyConvolutionDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaArray_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaArray {
    handle: ffi::cudaArray_t,
}

impl CudaArray {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaMallocArray
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaArray_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaArray_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaArray_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaArray {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaFreeArray(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnFusedOpsVariantParamPack_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnFusedOpsVariantParamPack {
    handle: ffi::cudnnFusedOpsVariantParamPack_t,
}

impl CudnnFusedOpsVariantParamPack {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateFusedOpsVariantParamPack
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnFusedOpsVariantParamPack_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnFusedOpsVariantParamPack_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnFusedOpsVariantParamPack_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnFusedOpsVariantParamPack {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyFusedOpsVariantParamPack(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnLRNDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnLRNDescriptor {
    handle: ffi::cudnnLRNDescriptor_t,
}

impl CudnnLRNDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateLRNDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnLRNDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnLRNDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnLRNDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnLRNDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyLRNDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnRNNDataDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnRNNDataDescriptor {
    handle: ffi::cudnnRNNDataDescriptor_t,
}

impl CudnnRNNDataDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateRNNDataDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnRNNDataDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnRNNDataDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnRNNDataDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnRNNDataDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyRNNDataDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudnnTensorDescriptor_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnTensorDescriptor {
    handle: ffi::cudnnTensorDescriptor_t,
}

impl CudnnTensorDescriptor {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudnnCreateTensorDescriptor
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnTensorDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnTensorDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnTensorDescriptor_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudnnTensorDescriptor {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudnnDestroyTensorDescriptor(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Safe wrapper for `cudaGraph_t`
///
/// This wrapper provides RAII-style resource management with automatic cleanup.
/// The wrapper is a zero-cost abstraction - it has the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaGraph {
    handle: ffi::cudaGraph_t,
}

impl CudaGraph {
    /// Create a new instance
    #[inline]
    /// Create a new instance
    // Warning: Unable to analyze function signature
    #[doc(hidden)]
    pub fn new() -> Result<Self, Error> {
        unsafe {
            // TODO: Implement proper constructor for cudaGraphCreate
            Err(Error::Unknown)
        }
    }

    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaGraph_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaGraph_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    /// The wrapper will take ownership and call the destructor on drop.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaGraph_t) -> Self {
        Self { handle }
    }
}

impl Drop for CudaGraph {
    fn drop(&mut self) {
        unsafe {
            if !self.handle.is_null() {
                let _status = ffi::cudaGraphDestroy(self.handle);
                // Ignoring status in drop - can't propagate errors
            }
        }
    }
}

/// Wrapper for `cudnnLossNormalizationMode_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnLossNormalizationMode {
    handle: ffi::cudnnLossNormalizationMode_t,
}

impl CudnnLossNormalizationMode {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnLossNormalizationMode_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnLossNormalizationMode_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnLossNormalizationMode_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaLogsCallback_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaLogsCallback {
    handle: ffi::cudaLogsCallback_t,
}

impl CudaLogsCallback {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaLogsCallback_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaLogsCallback_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaLogsCallback_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaLibrary_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaLibrary {
    handle: ffi::cudaLibrary_t,
}

impl CudaLibrary {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaLibrary_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaLibrary_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaLibrary_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaHostFn_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaHostFn {
    handle: ffi::cudaHostFn_t,
}

impl CudaHostFn {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaHostFn_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaHostFn_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaHostFn_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudnnCallback_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnCallback {
    handle: ffi::cudnnCallback_t,
}

impl CudnnCallback {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnCallback_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnCallback_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnCallback_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaAsyncCallbackHandle_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaAsyncCallbackHandle {
    handle: ffi::cudaAsyncCallbackHandle_t,
}

impl CudaAsyncCallbackHandle {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaAsyncCallbackHandle_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaAsyncCallbackHandle_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaAsyncCallbackHandle_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaGraphExec_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaGraphExec {
    handle: ffi::cudaGraphExec_t,
}

impl CudaGraphExec {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaGraphExec_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaGraphExec_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaGraphExec_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaRoundMode`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaRoundMode {
    handle: ffi::cudaRoundMode,
}

impl CudaRoundMode {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaRoundMode {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaRoundMode {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaRoundMode) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaExternalMemory_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaExternalMemory {
    handle: ffi::cudaExternalMemory_t,
}

impl CudaExternalMemory {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaExternalMemory_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaExternalMemory_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaExternalMemory_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaKernel_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaKernel {
    handle: ffi::cudaKernel_t,
}

impl CudaKernel {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaKernel_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaKernel_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaKernel_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaFunction_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaFunction {
    handle: ffi::cudaFunction_t,
}

impl CudaFunction {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaFunction_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaFunction_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaFunction_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaExternalSemaphore_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaExternalSemaphore {
    handle: ffi::cudaExternalSemaphore_t,
}

impl CudaExternalSemaphore {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaExternalSemaphore_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaExternalSemaphore_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaExternalSemaphore_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaMipmappedArray_const_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaMipmappedArrayConst {
    handle: ffi::cudaMipmappedArray_const_t,
}

impl CudaMipmappedArrayConst {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaMipmappedArray_const_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaMipmappedArray_const_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaMipmappedArray_const_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaArray_const_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaArrayConst {
    handle: ffi::cudaArray_const_t,
}

impl CudaArrayConst {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaArray_const_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaArray_const_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaArray_const_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaLogsCallbackHandle`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaLogsCallbackHandle {
    handle: ffi::cudaLogsCallbackHandle,
}

impl CudaLogsCallbackHandle {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaLogsCallbackHandle {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaLogsCallbackHandle {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaLogsCallbackHandle) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaAsyncCallback`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaAsyncCallback {
    handle: ffi::cudaAsyncCallback,
}

impl CudaAsyncCallback {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaAsyncCallback {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaAsyncCallback {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaAsyncCallback) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudnnBackendDescriptor_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudnnBackendDescriptor {
    handle: ffi::cudnnBackendDescriptor_t,
}

impl CudnnBackendDescriptor {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudnnBackendDescriptor_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudnnBackendDescriptor_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudnnBackendDescriptor_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaGraphicsResource_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaGraphicsResource {
    handle: ffi::cudaGraphicsResource_t,
}

impl CudaGraphicsResource {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaGraphicsResource_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaGraphicsResource_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaGraphicsResource_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaGraphDeviceNode_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaGraphDeviceNode {
    handle: ffi::cudaGraphDeviceNode_t,
}

impl CudaGraphDeviceNode {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaGraphDeviceNode_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaGraphDeviceNode_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaGraphDeviceNode_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `va_list`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct VaList {
    handle: ffi::va_list,
}

impl VaList {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::va_list {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::va_list {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::va_list) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaGraphNode_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaGraphNode {
    handle: ffi::cudaGraphNode_t,
}

impl CudaGraphNode {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaGraphNode_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaGraphNode_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaGraphNode_t) -> Self {
        Self { handle }
    }
}

/// Wrapper for `cudaStreamCallback_t`
/// Note: No automatic resource management - handle cleanup manually
///
/// This wrapper is a zero-cost abstraction with the same memory layout
/// as the underlying handle type.
#[repr(transparent)]
pub struct CudaStreamCallback {
    handle: ffi::cudaStreamCallback_t,
}

impl CudaStreamCallback {
    /// Returns the raw FFI handle
    #[inline]
    pub fn as_raw(&self) -> ffi::cudaStreamCallback_t {
        self.handle
    }

    /// Returns a mutable pointer to the raw FFI handle
    #[inline]
    pub fn as_raw_mut(&mut self) -> *mut ffi::cudaStreamCallback_t {
        &mut self.handle
    }

    /// Constructs a wrapper from a raw FFI handle
    ///
    /// # Safety
    ///
    /// The caller must ensure the handle is valid and properly initialized.
    #[inline]
    pub unsafe fn from_raw(handle: ffi::cudaStreamCallback_t) -> Self {
        Self { handle }
    }
}

// Additional methods for cudnnLossNormalizationMode_t
impl CudnnLossNormalizationMode {
    pub fn set_ctc_loss_descriptor_ex(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        gradmode: ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnSetCTCLossDescriptorEx(ctclossdesc, comptype, normmode, gradmode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_ctc_loss_descriptor_v_8(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        gradmode: ffi::cudnnNanPropagation_t,
        maxlabellength: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetCTCLossDescriptor_v8(
                ctclossdesc,
                comptype,
                normmode,
                gradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_ctc_loss_descriptor_v_9(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        ctcgradmode: ffi::cudnnCTCGradMode_t,
        maxlabellength: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetCTCLossDescriptor_v9(
                ctclossdesc,
                comptype,
                normmode,
                ctcgradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_descriptor_ex(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        gradmode: *mut ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnGetCTCLossDescriptorEx(ctclossdesc, comptype, normmode, gradmode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_descriptor_v_8(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        gradmode: *mut ffi::cudnnNanPropagation_t,
        maxlabellength: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossDescriptor_v8(
                ctclossdesc,
                comptype,
                normmode,
                gradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_descriptor_v_9(
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        ctcgradmode: *mut ffi::cudnnCTCGradMode_t,
        maxlabellength: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossDescriptor_v9(
                ctclossdesc,
                comptype,
                normmode,
                ctcgradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnRNNDescriptor_t
impl CudnnRNNDescriptor {
    #[inline]
    pub fn set_rnn_descriptor_v_8(
        &mut self,
        algo: ffi::cudnnRNNAlgo_t,
        cellmode: ffi::cudnnRNNMode_t,
        biasmode: ffi::cudnnRNNBiasMode_t,
        dirmode: ffi::cudnnDirectionMode_t,
        inputmode: ffi::cudnnRNNInputMode_t,
        datatype: ffi::cudnnDataType_t,
        mathprec: ffi::cudnnDataType_t,
        mathtype: ffi::cudnnMathType_t,
        inputsize: i32,
        hiddensize: i32,
        projsize: i32,
        numlayers: i32,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        auxflags: u32,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetRNNDescriptor_v8").entered();
            let result = ffi::cudnnSetRNNDescriptor_v8(
                self.handle,
                algo,
                cellmode,
                biasmode,
                dirmode,
                inputmode,
                datatype,
                mathprec,
                mathtype,
                inputsize,
                hiddensize,
                projsize,
                numlayers,
                dropoutdesc,
                auxflags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_rnn_descriptor_v_8(
        &mut self,
        algo: *mut ffi::cudnnRNNAlgo_t,
        cellmode: *mut ffi::cudnnRNNMode_t,
        biasmode: *mut ffi::cudnnRNNBiasMode_t,
        dirmode: *mut ffi::cudnnDirectionMode_t,
        inputmode: *mut ffi::cudnnRNNInputMode_t,
        datatype: *mut ffi::cudnnDataType_t,
        mathprec: *mut ffi::cudnnDataType_t,
        mathtype: *mut ffi::cudnnMathType_t,
        inputsize: *mut i32,
        hiddensize: *mut i32,
        projsize: *mut i32,
        numlayers: *mut i32,
        dropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        auxflags: *mut u32,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if algo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if algo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if cellmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if cellmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if biasmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if biasmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dirmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dirmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if inputmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if inputmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if mathprec.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mathprec.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if inputsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if inputsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hiddensize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hiddensize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if projsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if projsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if numlayers.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if numlayers.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if auxflags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if auxflags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetRNNDescriptor_v8").entered();
            let result = ffi::cudnnGetRNNDescriptor_v8(
                self.handle,
                algo,
                cellmode,
                biasmode,
                dirmode,
                inputmode,
                datatype,
                mathprec,
                mathtype,
                inputsize,
                hiddensize,
                projsize,
                numlayers,
                dropoutdesc,
                auxflags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_set_clip_v_8(
        &mut self,
        clipmode: ffi::cudnnRNNClipMode_t,
        clipnanopt: ffi::cudnnNanPropagation_t,
        lclip: f64,
        rclip: f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnRNNSetClip_v8").entered();
            let result = ffi::cudnnRNNSetClip_v8(self.handle, clipmode, clipnanopt, lclip, rclip);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_set_clip_v_9(
        &mut self,
        clipmode: ffi::cudnnRNNClipMode_t,
        lclip: f64,
        rclip: f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnRNNSetClip_v9").entered();
            let result = ffi::cudnnRNNSetClip_v9(self.handle, clipmode, lclip, rclip);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_get_clip_v_8(
        &mut self,
        clipmode: *mut ffi::cudnnRNNClipMode_t,
        clipnanopt: *mut ffi::cudnnNanPropagation_t,
        lclip: *mut f64,
        rclip: *mut f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if clipmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if clipmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if clipnanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if lclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if rclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if rclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnRNNGetClip_v8").entered();
            let result = ffi::cudnnRNNGetClip_v8(self.handle, clipmode, clipnanopt, lclip, rclip);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_get_clip_v_9(
        &mut self,
        clipmode: *mut ffi::cudnnRNNClipMode_t,
        lclip: *mut f64,
        rclip: *mut f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if clipmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if clipmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if lclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if rclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if rclip.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnRNNGetClip_v9").entered();
            let result = ffi::cudnnRNNGetClip_v9(self.handle, clipmode, lclip, rclip);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn build_rnn_dynamic(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        minibatch: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBuildRNNDynamic(handle, rnndesc, minibatch);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_rnn_temp_space_sizes(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        workspacesize: *mut usize,
        reservespacesize: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNTempSpaceSizes(
                handle,
                rnndesc,
                fwdmode,
                xdesc,
                workspacesize,
                reservespacesize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_rnn_weight_space_size(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        weightspacesize: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNWeightSpaceSize(handle, rnndesc, weightspacesize);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_rnn_weight_params(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        pseudolayer: i32,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        linlayerid: i32,
        mdesc: ffi::cudnnTensorDescriptor_t,
        maddr: *mut *mut ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        baddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNWeightParams(
                handle,
                rnndesc,
                pseudolayer,
                weightspacesize,
                weightspace,
                linlayerid,
                mdesc,
                maddr,
                bdesc,
                baddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_forward(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        hy: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        cy: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNForward(
                handle,
                rnndesc,
                fwdmode,
                devseqlengths,
                xdesc,
                x,
                ydesc,
                y,
                hdesc,
                hx,
                hy,
                cdesc,
                cx,
                cy,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_data_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        devseqlengths: *const i32,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        dhy: *const ::core::ffi::c_void,
        dhx: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        dcy: *const ::core::ffi::c_void,
        dcx: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardData_v8(
                handle,
                rnndesc,
                devseqlengths,
                ydesc,
                y,
                dy,
                xdesc,
                dx,
                hdesc,
                hx,
                dhy,
                dhx,
                cdesc,
                cx,
                dcy,
                dcx,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_weights_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        weightspacesize: usize,
        dweightspace: *mut ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardWeights_v8(
                handle,
                rnndesc,
                addgrad,
                devseqlengths,
                xdesc,
                x,
                hdesc,
                hx,
                ydesc,
                y,
                weightspacesize,
                dweightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaLogsCallback_t
impl CudaLogsCallback {
    #[inline]
    pub fn logs_register_callback(
        &mut self,
        userdata: *mut ::core::ffi::c_void,
        callback_out: *mut ffi::cudaLogsCallbackHandle,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if callback_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if callback_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaLogsRegisterCallback").entered();
            let result = ffi::cudaLogsRegisterCallback(self.handle, userdata, callback_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnSpatialTransformerDescriptor_t
impl CudnnSpatialTransformerDescriptor {
    #[inline]
    pub fn set_spatial_transformer_nd_descriptor(
        &mut self,
        samplertype: ffi::cudnnSamplerType_t,
        datatype: ffi::cudnnDataType_t,
        nbdims: ::core::ffi::c_int,
        dima: *const ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnSetSpatialTransformerNdDescriptor"
            )
            .entered();
            let result = ffi::cudnnSetSpatialTransformerNdDescriptor(
                self.handle,
                samplertype,
                datatype,
                nbdims,
                dima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_grid_generator_forward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        theta: *const ::core::ffi::c_void,
        grid: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfGridGeneratorForward(handle, stdesc, theta, grid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_sampler_forward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfSamplerForward(
                handle, stdesc, alpha, xdesc, x, grid, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_grid_generator_backward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        dgrid: *const ::core::ffi::c_void,
        dtheta: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfGridGeneratorBackward(handle, stdesc, dgrid, dtheta);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_sampler_backward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        alphadgrid: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        betadgrid: *const ::core::ffi::c_void,
        dgrid: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfSamplerBackward(
                handle, stdesc, alpha, xdesc, x, beta, dxdesc, dx, alphadgrid, dydesc, dy, grid,
                betadgrid, dgrid,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaUserObject_t
impl CudaUserObject {
    #[inline]
    pub fn user_object_retain(&mut self, count: ::core::ffi::c_uint) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaUserObjectRetain").entered();
            let result = ffi::cudaUserObjectRetain(self.handle, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_retain_user_object(
        graph: ffi::cudaGraph_t,
        object: ffi::cudaUserObject_t,
        count: ::core::ffi::c_uint,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphRetainUserObject(graph, object, count, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_release_user_object(
        graph: ffi::cudaGraph_t,
        object: ffi::cudaUserObject_t,
        count: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphReleaseUserObject(graph, object, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaLibrary_t
impl CudaLibrary {
    #[inline]
    pub fn library_unload(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaLibraryUnload").entered();
            let result = ffi::cudaLibraryUnload(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_get_kernel(
        pkernel: *mut ffi::cudaKernel_t,
        library: ffi::cudaLibrary_t,
        name: &str,
    ) -> Result<(), Error> {
        unsafe {
            let name_cstr = std::ffi::CString::new(name).map_err(|_| Error::InvalidString)?;
            let result = ffi::cudaLibraryGetKernel(pkernel, library, name_cstr.as_ptr());
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_get_global(
        dptr: *mut *mut ::core::ffi::c_void,
        bytes: *mut usize,
        library: ffi::cudaLibrary_t,
        name: &str,
    ) -> Result<(), Error> {
        unsafe {
            let name_cstr = std::ffi::CString::new(name).map_err(|_| Error::InvalidString)?;
            let result = ffi::cudaLibraryGetGlobal(dptr, bytes, library, name_cstr.as_ptr());
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_get_managed(
        dptr: *mut *mut ::core::ffi::c_void,
        bytes: *mut usize,
        library: ffi::cudaLibrary_t,
        name: &str,
    ) -> Result<(), Error> {
        unsafe {
            let name_cstr = std::ffi::CString::new(name).map_err(|_| Error::InvalidString)?;
            let result = ffi::cudaLibraryGetManaged(dptr, bytes, library, name_cstr.as_ptr());
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_get_unified_function(
        fptr: *mut *mut ::core::ffi::c_void,
        library: ffi::cudaLibrary_t,
        symbol: &str,
    ) -> Result<(), Error> {
        unsafe {
            let symbol_cstr = std::ffi::CString::new(symbol).map_err(|_| Error::InvalidString)?;
            let result = ffi::cudaLibraryGetUnifiedFunction(fptr, library, symbol_cstr.as_ptr());
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_get_kernel_count(
        count: *mut ::core::ffi::c_uint,
        lib: ffi::cudaLibrary_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaLibraryGetKernelCount(count, lib);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn library_enumerate_kernels(
        kernels: *mut ffi::cudaKernel_t,
        numkernels: ::core::ffi::c_uint,
        lib: ffi::cudaLibrary_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaLibraryEnumerateKernels(kernels, numkernels, lib);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaHostFn_t
impl CudaHostFn {
    pub fn launch_host_func(
        stream: ffi::cudaStream_t,
        fn_: ffi::cudaHostFn_t,
        userdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaLaunchHostFunc(stream, fn_, userdata);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn user_object_create(
        object_out: *mut ffi::cudaUserObject_t,
        ptr: *mut ::core::ffi::c_void,
        destroy: ffi::cudaHostFn_t,
        initialrefcount: ::core::ffi::c_uint,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaUserObjectCreate(object_out, ptr, destroy, initialrefcount, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnSeqDataDescriptor_t
impl CudnnSeqDataDescriptor {
    #[inline]
    pub fn set_seq_data_descriptor(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        nbdims: ::core::ffi::c_int,
        dima: *const ::core::ffi::c_int,
        axes: *const ffi::cudnnSeqDataAxis_t,
        seqlengtharraysize: usize,
        seqlengtharray: *const ::core::ffi::c_int,
        paddingfill: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if axes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if axes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetSeqDataDescriptor").entered();
            let result = ffi::cudnnSetSeqDataDescriptor(
                self.handle,
                datatype,
                nbdims,
                dima,
                axes,
                seqlengtharraysize,
                seqlengtharray,
                paddingfill,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_seq_data_descriptor(
        &mut self,
        datatype: *mut ffi::cudnnDataType_t,
        nbdims: *mut ::core::ffi::c_int,
        nbdimsrequested: ::core::ffi::c_int,
        dima: *mut ::core::ffi::c_int,
        axes: *mut ffi::cudnnSeqDataAxis_t,
        seqlengtharraysize: *mut usize,
        seqlengthsizerequested: usize,
        seqlengtharray: *mut ::core::ffi::c_int,
        paddingfill: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if axes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if axes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if seqlengtharraysize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seqlengtharraysize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetSeqDataDescriptor").entered();
            let result = ffi::cudnnGetSeqDataDescriptor(
                self.handle,
                datatype,
                nbdims,
                nbdimsrequested,
                dima,
                axes,
                seqlengtharraysize,
                seqlengthsizerequested,
                seqlengtharray,
                paddingfill,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_forward(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        curridx: ::core::ffi::c_int,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsqo: *const ::core::ffi::c_int,
        devseqlengthskv: *const ::core::ffi::c_int,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        residuals: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        odesc: ffi::cudnnSeqDataDescriptor_t,
        out: *mut ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnForward(
                handle,
                attndesc,
                curridx,
                lowinidx,
                hiwinidx,
                devseqlengthsqo,
                devseqlengthskv,
                qdesc,
                queries,
                residuals,
                kdesc,
                keys,
                vdesc,
                values,
                odesc,
                out,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_backward_data(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsdqdo: *const ::core::ffi::c_int,
        devseqlengthsdkdv: *const ::core::ffi::c_int,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        dqdesc: ffi::cudnnSeqDataDescriptor_t,
        dqueries: *mut ::core::ffi::c_void,
        queries: *const ::core::ffi::c_void,
        dkdesc: ffi::cudnnSeqDataDescriptor_t,
        dkeys: *mut ::core::ffi::c_void,
        keys: *const ::core::ffi::c_void,
        dvdesc: ffi::cudnnSeqDataDescriptor_t,
        dvalues: *mut ::core::ffi::c_void,
        values: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnBackwardData(
                handle,
                attndesc,
                lowinidx,
                hiwinidx,
                devseqlengthsdqdo,
                devseqlengthsdkdv,
                dodesc,
                dout,
                dqdesc,
                dqueries,
                queries,
                dkdesc,
                dkeys,
                keys,
                dvdesc,
                dvalues,
                values,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_backward_weights(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        dweights: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnBackwardWeights(
                handle,
                attndesc,
                addgrad,
                qdesc,
                queries,
                kdesc,
                keys,
                vdesc,
                values,
                dodesc,
                dout,
                weightsizeinbytes,
                weights,
                dweights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnActivationDescriptor_t
impl CudnnActivationDescriptor {
    #[inline]
    pub fn set_activation_descriptor(
        &mut self,
        mode: ffi::cudnnActivationMode_t,
        relunanopt: ffi::cudnnNanPropagation_t,
        coef: f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetActivationDescriptor")
                .entered();
            let result = ffi::cudnnSetActivationDescriptor(self.handle, mode, relunanopt, coef);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_activation_descriptor(
        &mut self,
        mode: *mut ffi::cudnnActivationMode_t,
        relunanopt: *mut ffi::cudnnNanPropagation_t,
        coef: *mut f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if relunanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if coef.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if coef.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetActivationDescriptor")
                .entered();
            let result = ffi::cudnnGetActivationDescriptor(self.handle, mode, relunanopt, coef);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_activation_descriptor_swish_beta(&mut self, swish_beta: f64) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnSetActivationDescriptorSwishBeta"
            )
            .entered();
            let result = ffi::cudnnSetActivationDescriptorSwishBeta(self.handle, swish_beta);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_activation_descriptor_swish_beta(
        &mut self,
        swish_beta: *mut f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if swish_beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if swish_beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetActivationDescriptorSwishBeta"
            )
            .entered();
            let result = ffi::cudnnGetActivationDescriptorSwishBeta(self.handle, swish_beta);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn activation_forward(
        handle: ffi::cudnnHandle_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnActivationForward(
                handle,
                activationdesc,
                alpha,
                xdesc,
                x,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_forward_inference(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        estimatedmean: *const ::core::ffi::c_void,
        estimatedvariance: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        epsilon: f64,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationForwardInference(
                handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                x,
                normscalebiasdesc,
                normscale,
                normbias,
                normmeanvardesc,
                estimatedmean,
                estimatedvariance,
                zdesc,
                z,
                activationdesc,
                ydesc,
                y,
                epsilon,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn activation_backward(
        handle: ffi::cudnnHandle_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnActivationBackward(
                handle,
                activationdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_forward_training_ex_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
                handle,
                mode,
                bnops,
                xdesc,
                zdesc,
                ydesc,
                bnscalebiasmeanvardesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_backward_ex_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationBackwardExWorkspaceSize(
                handle,
                mode,
                bnops,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dbnscalebiasdesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_training_ex_reserve_space_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
                handle,
                mode,
                bnops,
                activationdesc,
                xdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_forward_training_ex(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationForwardTrainingEx(
                handle,
                mode,
                bnops,
                alpha,
                beta,
                xdesc,
                xdata,
                zdesc,
                zdata,
                ydesc,
                ydata,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                exponentialaveragefactor,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_backward_ex(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        bnscaledata: *const ::core::ffi::c_void,
        bnbiasdata: *const ::core::ffi::c_void,
        dbnscaledata: *mut ::core::ffi::c_void,
        dbnbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationBackwardEx(
                handle,
                mode,
                bnops,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dbnscalebiasdesc,
                bnscaledata,
                bnbiasdata,
                dbnscaledata,
                dbnbiasdata,
                epsilon,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_forward_training_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationForwardTrainingWorkspaceSize(
                handle,
                mode,
                normops,
                algo,
                xdesc,
                zdesc,
                ydesc,
                normscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_backward_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationBackwardWorkspaceSize(
                handle,
                mode,
                normops,
                algo,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dnormscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_training_reserve_space_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationTrainingReserveSpaceSize(
                handle,
                mode,
                normops,
                algo,
                activationdesc,
                xdesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_forward_training(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationForwardTraining(
                handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                xdata,
                normscalebiasdesc,
                normscale,
                normbias,
                exponentialaveragefactor,
                normmeanvardesc,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                zdesc,
                zdata,
                ydesc,
                ydata,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_backward(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscaledata: *const ::core::ffi::c_void,
        normbiasdata: *const ::core::ffi::c_void,
        dnormscaledata: *mut ::core::ffi::c_void,
        dnormbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationBackward(
                handle,
                mode,
                normops,
                algo,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dnormscalebiasdesc,
                normscaledata,
                normbiasdata,
                dnormscaledata,
                dnormbiasdata,
                epsilon,
                normmeanvardesc,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_bias_activation_forward(
        handle: ffi::cudnnHandle_t,
        alpha1: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha2: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        biasdesc: ffi::cudnnTensorDescriptor_t,
        bias: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBiasActivationForward(
                handle,
                alpha1,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                alpha2,
                zdesc,
                z,
                biasdesc,
                bias,
                activationdesc,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnCallback_t
impl CudnnCallback {
    pub fn set_callback(
        mask: ::core::ffi::c_uint,
        udata: *mut ::core::ffi::c_void,
        fptr: ffi::cudnnCallback_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetCallback(mask, udata, fptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_callback(
        mask: *mut ::core::ffi::c_uint,
        udata: *mut *mut ::core::ffi::c_void,
        fptr: *mut ffi::cudnnCallback_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCallback(mask, udata, fptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnAttnDescriptor_t
impl CudnnAttnDescriptor {
    #[inline]
    pub fn set_attn_descriptor(
        &mut self,
        attnmode: ::core::ffi::c_uint,
        nheads: ::core::ffi::c_int,
        smscaler: f64,
        datatype: ffi::cudnnDataType_t,
        computeprec: ffi::cudnnDataType_t,
        mathtype: ffi::cudnnMathType_t,
        attndropoutdesc: ffi::cudnnDropoutDescriptor_t,
        postdropoutdesc: ffi::cudnnDropoutDescriptor_t,
        qsize: ::core::ffi::c_int,
        ksize: ::core::ffi::c_int,
        vsize: ::core::ffi::c_int,
        qprojsize: ::core::ffi::c_int,
        kprojsize: ::core::ffi::c_int,
        vprojsize: ::core::ffi::c_int,
        oprojsize: ::core::ffi::c_int,
        qomaxseqlength: ::core::ffi::c_int,
        kvmaxseqlength: ::core::ffi::c_int,
        maxbatchsize: ::core::ffi::c_int,
        maxbeamsize: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetAttnDescriptor").entered();
            let result = ffi::cudnnSetAttnDescriptor(
                self.handle,
                attnmode,
                nheads,
                smscaler,
                datatype,
                computeprec,
                mathtype,
                attndropoutdesc,
                postdropoutdesc,
                qsize,
                ksize,
                vsize,
                qprojsize,
                kprojsize,
                vprojsize,
                oprojsize,
                qomaxseqlength,
                kvmaxseqlength,
                maxbatchsize,
                maxbeamsize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_attn_descriptor(
        &mut self,
        attnmode: *mut ::core::ffi::c_uint,
        nheads: *mut ::core::ffi::c_int,
        smscaler: *mut f64,
        datatype: *mut ffi::cudnnDataType_t,
        computeprec: *mut ffi::cudnnDataType_t,
        mathtype: *mut ffi::cudnnMathType_t,
        attndropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        postdropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        qsize: *mut ::core::ffi::c_int,
        ksize: *mut ::core::ffi::c_int,
        vsize: *mut ::core::ffi::c_int,
        qprojsize: *mut ::core::ffi::c_int,
        kprojsize: *mut ::core::ffi::c_int,
        vprojsize: *mut ::core::ffi::c_int,
        oprojsize: *mut ::core::ffi::c_int,
        qomaxseqlength: *mut ::core::ffi::c_int,
        kvmaxseqlength: *mut ::core::ffi::c_int,
        maxbatchsize: *mut ::core::ffi::c_int,
        maxbeamsize: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if attnmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if attnmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nheads.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nheads.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if smscaler.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if smscaler.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if computeprec.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if computeprec.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if attndropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if attndropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if postdropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if postdropoutdesc.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if qsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if qsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ksize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ksize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if vsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if vsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if qprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if qprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if kprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if kprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if vprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if vprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if oprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if oprojsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if qomaxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if qomaxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if kvmaxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if kvmaxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxbatchsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maxbatchsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxbeamsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maxbeamsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetAttnDescriptor").entered();
            let result = ffi::cudnnGetAttnDescriptor(
                self.handle,
                attnmode,
                nheads,
                smscaler,
                datatype,
                computeprec,
                mathtype,
                attndropoutdesc,
                postdropoutdesc,
                qsize,
                ksize,
                vsize,
                qprojsize,
                kprojsize,
                vprojsize,
                oprojsize,
                qomaxseqlength,
                kvmaxseqlength,
                maxbatchsize,
                maxbeamsize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_multi_head_attn_buffers(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        weightsizeinbytes: *mut usize,
        workspacesizeinbytes: *mut usize,
        reservespacesizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetMultiHeadAttnBuffers(
                handle,
                attndesc,
                weightsizeinbytes,
                workspacesizeinbytes,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_multi_head_attn_weights(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        wkind: ffi::cudnnMultiHeadAttnWeightKind_t,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnTensorDescriptor_t,
        waddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetMultiHeadAttnWeights(
                handle,
                attndesc,
                wkind,
                weightsizeinbytes,
                weights,
                wdesc,
                waddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_forward(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        curridx: ::core::ffi::c_int,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsqo: *const ::core::ffi::c_int,
        devseqlengthskv: *const ::core::ffi::c_int,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        residuals: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        odesc: ffi::cudnnSeqDataDescriptor_t,
        out: *mut ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnForward(
                handle,
                attndesc,
                curridx,
                lowinidx,
                hiwinidx,
                devseqlengthsqo,
                devseqlengthskv,
                qdesc,
                queries,
                residuals,
                kdesc,
                keys,
                vdesc,
                values,
                odesc,
                out,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_backward_data(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsdqdo: *const ::core::ffi::c_int,
        devseqlengthsdkdv: *const ::core::ffi::c_int,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        dqdesc: ffi::cudnnSeqDataDescriptor_t,
        dqueries: *mut ::core::ffi::c_void,
        queries: *const ::core::ffi::c_void,
        dkdesc: ffi::cudnnSeqDataDescriptor_t,
        dkeys: *mut ::core::ffi::c_void,
        keys: *const ::core::ffi::c_void,
        dvdesc: ffi::cudnnSeqDataDescriptor_t,
        dvalues: *mut ::core::ffi::c_void,
        values: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnBackwardData(
                handle,
                attndesc,
                lowinidx,
                hiwinidx,
                devseqlengthsdqdo,
                devseqlengthsdkdv,
                dodesc,
                dout,
                dqdesc,
                dqueries,
                queries,
                dkdesc,
                dkeys,
                keys,
                dvdesc,
                dvalues,
                values,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn multi_head_attn_backward_weights(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        dweights: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMultiHeadAttnBackwardWeights(
                handle,
                attndesc,
                addgrad,
                qdesc,
                queries,
                kdesc,
                keys,
                vdesc,
                values,
                dodesc,
                dout,
                weightsizeinbytes,
                weights,
                dweights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaAsyncCallbackHandle_t
impl CudaAsyncCallbackHandle {
    pub fn device_register_async_notification(
        device: ::core::ffi::c_int,
        callbackfunc: ffi::cudaAsyncCallback,
        userdata: *mut ::core::ffi::c_void,
        callback: *mut ffi::cudaAsyncCallbackHandle_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaDeviceRegisterAsyncNotification(device, callbackfunc, userdata, callback);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn device_unregister_async_notification(
        device: ::core::ffi::c_int,
        callback: ffi::cudaAsyncCallbackHandle_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaDeviceUnregisterAsyncNotification(device, callback);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaGraphExec_t
impl CudaGraphExec {
    #[inline]
    pub fn graph_exec_get_flags(
        &mut self,
        flags: *mut ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if flags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if flags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecGetFlags").entered();
            let result = ffi::cudaGraphExecGetFlags(self.handle, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_kernel_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaKernelNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecKernelNodeSetParams")
                    .entered();
            let result = ffi::cudaGraphExecKernelNodeSetParams(self.handle, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_memcpy_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaMemcpy3DParms,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecMemcpyNodeSetParams")
                    .entered();
            let result = ffi::cudaGraphExecMemcpyNodeSetParams(self.handle, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_memcpy_node_set_params_to_symbol(
        &mut self,
        node: ffi::cudaGraphNode_t,
        symbol: *const ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecMemcpyNodeSetParamsToSymbol"
            )
            .entered();
            let result = ffi::cudaGraphExecMemcpyNodeSetParamsToSymbol(
                self.handle,
                node,
                symbol,
                src,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_memcpy_node_set_params_from_symbol(
        &mut self,
        node: ffi::cudaGraphNode_t,
        dst: *mut ::core::ffi::c_void,
        symbol: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecMemcpyNodeSetParamsFromSymbol"
            )
            .entered();
            let result = ffi::cudaGraphExecMemcpyNodeSetParamsFromSymbol(
                self.handle,
                node,
                dst,
                symbol,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_memcpy_node_set_params_1d(
        &mut self,
        node: ffi::cudaGraphNode_t,
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecMemcpyNodeSetParams1D")
                    .entered();
            let result =
                ffi::cudaGraphExecMemcpyNodeSetParams1D(self.handle, node, dst, src, count, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_memset_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaMemsetParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecMemsetNodeSetParams")
                    .entered();
            let result = ffi::cudaGraphExecMemsetNodeSetParams(self.handle, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_host_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaHostNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecHostNodeSetParams")
                    .entered();
            let result = ffi::cudaGraphExecHostNodeSetParams(self.handle, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_child_graph_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        childgraph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecChildGraphNodeSetParams"
            )
            .entered();
            let result = ffi::cudaGraphExecChildGraphNodeSetParams(self.handle, node, childgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_event_record_node_set_event(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecEventRecordNodeSetEvent"
            )
            .entered();
            let result = ffi::cudaGraphExecEventRecordNodeSetEvent(self.handle, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_event_wait_node_set_event(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecEventWaitNodeSetEvent")
                    .entered();
            let result = ffi::cudaGraphExecEventWaitNodeSetEvent(self.handle, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_external_semaphores_signal_node_set_params(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        nodeparams: *const ffi::cudaExternalSemaphoreSignalNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecExternalSemaphoresSignalNodeSetParams"
            )
            .entered();
            let result = ffi::cudaGraphExecExternalSemaphoresSignalNodeSetParams(
                self.handle,
                hnode,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_external_semaphores_wait_node_set_params(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        nodeparams: *const ffi::cudaExternalSemaphoreWaitNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExecExternalSemaphoresWaitNodeSetParams"
            )
            .entered();
            let result = ffi::cudaGraphExecExternalSemaphoresWaitNodeSetParams(
                self.handle,
                hnode,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_set_enabled(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        isenabled: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphNodeSetEnabled").entered();
            let result = ffi::cudaGraphNodeSetEnabled(self.handle, hnode, isenabled);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_get_enabled(
        &mut self,
        hnode: ffi::cudaGraphNode_t,
        isenabled: *mut ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if isenabled.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if isenabled.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphNodeGetEnabled").entered();
            let result = ffi::cudaGraphNodeGetEnabled(self.handle, hnode, isenabled);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_update(
        &mut self,
        hgraph: ffi::cudaGraph_t,
        resultinfo: *mut ffi::cudaGraphExecUpdateResultInfo,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if resultinfo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultinfo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecUpdate").entered();
            let result = ffi::cudaGraphExecUpdate(self.handle, hgraph, resultinfo);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_upload(&mut self, stream: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphUpload").entered();
            let result = ffi::cudaGraphUpload(self.handle, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_launch(&mut self, stream: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphLaunch").entered();
            let result = ffi::cudaGraphLaunch(self.handle, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_destroy(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecDestroy").entered();
            let result = ffi::cudaGraphExecDestroy(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_exec_node_set_params(
        &mut self,
        node: ffi::cudaGraphNode_t,
        nodeparams: *mut ffi::cudaGraphNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphExecNodeSetParams").entered();
            let result = ffi::cudaGraphExecNodeSetParams(self.handle, node, nodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaStream_t
impl CudaStream {
    #[inline]
    pub fn stream_get_priority(&mut self, priority: *mut ::core::ffi::c_int) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if priority.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if priority.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamGetPriority").entered();
            let result = ffi::cudaStreamGetPriority(self.handle, priority);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_get_flags(&mut self, flags: *mut ::core::ffi::c_uint) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if flags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if flags.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaStreamGetFlags").entered();
            let result = ffi::cudaStreamGetFlags(self.handle, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_get_id(&mut self, streamid: *mut ::core::ffi::c_ulonglong) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if streamid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if streamid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaStreamGetId").entered();
            let result = ffi::cudaStreamGetId(self.handle, streamid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_get_device(&mut self, device: *mut ::core::ffi::c_int) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if device.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if device.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamGetDevice").entered();
            let result = ffi::cudaStreamGetDevice(self.handle, device);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_copy_attributes(&mut self, src: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamCopyAttributes").entered();
            let result = ffi::cudaStreamCopyAttributes(self.handle, src);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_get_attribute(
        &mut self,
        attr: ffi::cudaLaunchAttributeID,
        value_out: *mut ffi::cudaLaunchAttributeValue,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamGetAttribute").entered();
            let result = ffi::cudaStreamGetAttribute(self.handle, attr, value_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_set_attribute(
        &mut self,
        attr: ffi::cudaLaunchAttributeID,
        value: *const ffi::cudaLaunchAttributeValue,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamSetAttribute").entered();
            let result = ffi::cudaStreamSetAttribute(self.handle, attr, value);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_wait_event(
        &mut self,
        event: ffi::cudaEvent_t,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamWaitEvent").entered();
            let result = ffi::cudaStreamWaitEvent(self.handle, event, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_add_callback(
        &mut self,
        callback: ffi::cudaStreamCallback_t,
        userdata: *mut ::core::ffi::c_void,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamAddCallback").entered();
            let result = ffi::cudaStreamAddCallback(self.handle, callback, userdata, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_synchronize(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamSynchronize").entered();
            let result = ffi::cudaStreamSynchronize(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_query(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaStreamQuery").entered();
            let result = ffi::cudaStreamQuery(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_attach_mem_async(
        &mut self,
        devptr: *mut ::core::ffi::c_void,
        length: usize,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if devptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamAttachMemAsync").entered();
            let result = ffi::cudaStreamAttachMemAsync(self.handle, devptr, length, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_begin_capture(&mut self, mode: ffi::cudaStreamCaptureMode) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamBeginCapture").entered();
            let result = ffi::cudaStreamBeginCapture(self.handle, mode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_begin_capture_to_graph(
        &mut self,
        graph: ffi::cudaGraph_t,
        dependencies: *const ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        mode: ffi::cudaStreamCaptureMode,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dependencydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dependencydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamBeginCaptureToGraph")
                    .entered();
            let result = ffi::cudaStreamBeginCaptureToGraph(
                self.handle,
                graph,
                dependencies,
                dependencydata,
                numdependencies,
                mode,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_end_capture(&mut self, pgraph: *mut ffi::cudaGraph_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pgraph.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pgraph.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamEndCapture").entered();
            let result = ffi::cudaStreamEndCapture(self.handle, pgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_is_capturing(
        &mut self,
        pcapturestatus: *mut ffi::cudaStreamCaptureStatus,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pcapturestatus.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pcapturestatus.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamIsCapturing").entered();
            let result = ffi::cudaStreamIsCapturing(self.handle, pcapturestatus);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_get_capture_info(
        &mut self,
        capturestatus_out: *mut ffi::cudaStreamCaptureStatus,
        id_out: *mut ::core::ffi::c_ulonglong,
        graph_out: *mut ffi::cudaGraph_t,
        dependencies_out: *mut *const ffi::cudaGraphNode_t,
        edgedata_out: *mut *const ffi::cudaGraphEdgeData,
        numdependencies_out: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if capturestatus_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if capturestatus_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if id_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if id_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if graph_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if graph_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dependencies_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dependencies_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if numdependencies_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if numdependencies_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamGetCaptureInfo").entered();
            let result = ffi::cudaStreamGetCaptureInfo(
                self.handle,
                capturestatus_out,
                id_out,
                graph_out,
                dependencies_out,
                edgedata_out,
                numdependencies_out,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn stream_update_capture_dependencies(
        &mut self,
        dependencies: *mut ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dependencydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dependencydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaStreamUpdateCaptureDependencies")
                    .entered();
            let result = ffi::cudaStreamUpdateCaptureDependencies(
                self.handle,
                dependencies,
                dependencydata,
                numdependencies,
                flags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn event_record(event: ffi::cudaEvent_t, stream: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaEventRecord(event, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn event_record_with_flags(
        event: ffi::cudaEvent_t,
        stream: ffi::cudaStream_t,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaEventRecordWithFlags(event, stream, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn signal_external_semaphores_async(
        extsemarray: *const ffi::cudaExternalSemaphore_t,
        paramsarray: *const ffi::cudaExternalSemaphoreSignalParams,
        numextsems: ::core::ffi::c_uint,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaSignalExternalSemaphoresAsync(
                extsemarray,
                paramsarray,
                numextsems,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn wait_external_semaphores_async(
        extsemarray: *const ffi::cudaExternalSemaphore_t,
        paramsarray: *const ffi::cudaExternalSemaphoreWaitParams,
        numextsems: ::core::ffi::c_uint,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaWaitExternalSemaphoresAsync(extsemarray, paramsarray, numextsems, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn launch_kernel(
        func: *const ::core::ffi::c_void,
        griddim: ffi::dim3,
        blockdim: ffi::dim3,
        args: *mut *mut ::core::ffi::c_void,
        sharedmem: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaLaunchKernel(func, griddim, blockdim, args, sharedmem, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn launch_cooperative_kernel(
        func: *const ::core::ffi::c_void,
        griddim: ffi::dim3,
        blockdim: ffi::dim3,
        args: *mut *mut ::core::ffi::c_void,
        sharedmem: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaLaunchCooperativeKernel(func, griddim, blockdim, args, sharedmem, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn launch_host_func(
        &mut self,
        fn_: ffi::cudaHostFn_t,
        userdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if userdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaLaunchHostFunc").entered();
            let result = ffi::cudaLaunchHostFunc(self.handle, fn_, userdata);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_3d_async(
        p: *const ffi::cudaMemcpy3DParms,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy3DAsync(p, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_3d_peer_async(
        p: *const ffi::cudaMemcpy3DPeerParms,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy3DPeerAsync(p, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_async(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyAsync(dst, src, count, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_peer_async(
        dst: *mut ::core::ffi::c_void,
        dstdevice: ::core::ffi::c_int,
        src: *const ::core::ffi::c_void,
        srcdevice: ::core::ffi::c_int,
        count: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyPeerAsync(dst, dstdevice, src, srcdevice, count, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_batch_async(
        dsts: *const *mut ::core::ffi::c_void,
        srcs: *const *const ::core::ffi::c_void,
        sizes: *const usize,
        count: usize,
        attrs: *mut ffi::cudaMemcpyAttributes,
        attrsidxs: *mut usize,
        numattrs: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyBatchAsync(
                dsts, srcs, sizes, count, attrs, attrsidxs, numattrs, stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_3d_batch_async(
        numops: usize,
        oplist: *mut ffi::cudaMemcpy3DBatchOp,
        flags: ::core::ffi::c_ulonglong,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy3DBatchAsync(numops, oplist, flags, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_2d_async(
        dst: *mut ::core::ffi::c_void,
        dpitch: usize,
        src: *const ::core::ffi::c_void,
        spitch: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMemcpy2DAsync(dst, dpitch, src, spitch, width, height, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_2d_to_array_async(
        dst: ffi::cudaArray_t,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        spitch: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy2DToArrayAsync(
                dst, woffset, hoffset, src, spitch, width, height, kind, stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_2d_from_array_async(
        dst: *mut ::core::ffi::c_void,
        dpitch: usize,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy2DFromArrayAsync(
                dst, dpitch, src, woffset, hoffset, width, height, kind, stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_to_symbol_async(
        symbol: *const ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyToSymbolAsync(symbol, src, count, offset, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_from_symbol_async(
        dst: *mut ::core::ffi::c_void,
        symbol: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyFromSymbolAsync(dst, symbol, count, offset, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memset_async(
        devptr: *mut ::core::ffi::c_void,
        value: ::core::ffi::c_int,
        count: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemsetAsync(devptr, value, count, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memset_2d_async(
        devptr: *mut ::core::ffi::c_void,
        pitch: usize,
        value: ::core::ffi::c_int,
        width: usize,
        height: usize,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemset2DAsync(devptr, pitch, value, width, height, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memset_3d_async(
        pitcheddevptr: ffi::cudaPitchedPtr,
        value: ::core::ffi::c_int,
        extent: ffi::cudaExtent,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemset3DAsync(pitcheddevptr, value, extent, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_prefetch_async(
        devptr: *const ::core::ffi::c_void,
        count: usize,
        location: ffi::cudaMemLocation,
        flags: ::core::ffi::c_uint,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemPrefetchAsync(devptr, count, location, flags, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_prefetch_batch_async(
        dptrs: *mut *mut ::core::ffi::c_void,
        sizes: *mut usize,
        count: usize,
        prefetchlocs: *mut ffi::cudaMemLocation,
        prefetchlocidxs: *mut usize,
        numprefetchlocs: usize,
        flags: ::core::ffi::c_ulonglong,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemPrefetchBatchAsync(
                dptrs,
                sizes,
                count,
                prefetchlocs,
                prefetchlocidxs,
                numprefetchlocs,
                flags,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_discard_batch_async(
        dptrs: *mut *mut ::core::ffi::c_void,
        sizes: *mut usize,
        count: usize,
        flags: ::core::ffi::c_ulonglong,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemDiscardBatchAsync(dptrs, sizes, count, flags, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_discard_and_prefetch_batch_async(
        dptrs: *mut *mut ::core::ffi::c_void,
        sizes: *mut usize,
        count: usize,
        prefetchlocs: *mut ffi::cudaMemLocation,
        prefetchlocidxs: *mut usize,
        numprefetchlocs: usize,
        flags: ::core::ffi::c_ulonglong,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemDiscardAndPrefetchBatchAsync(
                dptrs,
                sizes,
                count,
                prefetchlocs,
                prefetchlocidxs,
                numprefetchlocs,
                flags,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_to_array_async(
        dst: ffi::cudaArray_t,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMemcpyToArrayAsync(dst, woffset, hoffset, src, count, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_from_array_async(
        dst: *mut ::core::ffi::c_void,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        count: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMemcpyFromArrayAsync(dst, src, woffset, hoffset, count, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn malloc_async(
        devptr: *mut *mut ::core::ffi::c_void,
        size: usize,
        hstream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMallocAsync(devptr, size, hstream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn free_async(
        devptr: *mut ::core::ffi::c_void,
        hstream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaFreeAsync(devptr, hstream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn malloc_from_pool_async(
        ptr: *mut *mut ::core::ffi::c_void,
        size: usize,
        mempool: ffi::cudaMemPool_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMallocFromPoolAsync(ptr, size, mempool, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_map_resources(
        count: ::core::ffi::c_int,
        resources: *mut ffi::cudaGraphicsResource_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsMapResources(count, resources, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_unmap_resources(
        count: ::core::ffi::c_int,
        resources: *mut ffi::cudaGraphicsResource_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsUnmapResources(count, resources, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_upload(
        graphexec: ffi::cudaGraphExec_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphUpload(graphexec, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_launch(
        graphexec: ffi::cudaGraphExec_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphLaunch(graphexec, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_stream(
        handle: ffi::cudnnHandle_t,
        streamid: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetStream(handle, streamid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_stream(
        handle: ffi::cudnnHandle_t,
        streamid: *mut ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetStream(handle, streamid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaExternalMemory_t
impl CudaExternalMemory {
    pub fn external_memory_get_mapped_buffer(
        devptr: *mut *mut ::core::ffi::c_void,
        extmem: ffi::cudaExternalMemory_t,
        bufferdesc: *const ffi::cudaExternalMemoryBufferDesc,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaExternalMemoryGetMappedBuffer(devptr, extmem, bufferdesc);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn external_memory_get_mapped_mipmapped_array(
        mipmap: *mut ffi::cudaMipmappedArray_t,
        extmem: ffi::cudaExternalMemory_t,
        mipmapdesc: *const ffi::cudaExternalMemoryMipmappedArrayDesc,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaExternalMemoryGetMappedMipmappedArray(mipmap, extmem, mipmapdesc);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn destroy_external_memory(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaDestroyExternalMemory").entered();
            let result = ffi::cudaDestroyExternalMemory(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnFusedOpsPlan_t
impl CudnnFusedOpsPlan {
    pub fn make_fused_ops_plan(
        handle: ffi::cudnnHandle_t,
        plan: ffi::cudnnFusedOpsPlan_t,
        constpack: ffi::cudnnFusedOpsConstParamPack_t,
        workspacesizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMakeFusedOpsPlan(handle, plan, constpack, workspacesizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn fused_ops_execute(
        handle: ffi::cudnnHandle_t,
        plan: ffi::cudnnFusedOpsPlan_t,
        varpack: ffi::cudnnFusedOpsVariantParamPack_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFusedOpsExecute(handle, plan, varpack);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaMipmappedArray_t
impl CudaMipmappedArray {
    pub fn mipmapped_array_get_memory_requirements(
        memoryrequirements: *mut ffi::cudaArrayMemoryRequirements,
        mipmap: ffi::cudaMipmappedArray_t,
        device: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMipmappedArrayGetMemoryRequirements(memoryrequirements, mipmap, device);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mipmapped_array_get_sparse_properties(
        sparseproperties: *mut ffi::cudaArraySparseProperties,
        mipmap: ffi::cudaMipmappedArray_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMipmappedArrayGetSparseProperties(sparseproperties, mipmap);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnFusedOpsConstParamPack_t
impl CudnnFusedOpsConstParamPack {
    #[inline]
    pub fn set_fused_ops_const_param_pack_attribute(
        &mut self,
        paramlabel: ffi::cudnnFusedOpsConstParamLabel_t,
        param: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if param.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if param.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnSetFusedOpsConstParamPackAttribute"
            )
            .entered();
            let result =
                ffi::cudnnSetFusedOpsConstParamPackAttribute(self.handle, paramlabel, param);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_fused_ops_const_param_pack_attribute(
        &mut self,
        paramlabel: ffi::cudnnFusedOpsConstParamLabel_t,
        param: *mut ::core::ffi::c_void,
        isnull: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if param.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if param.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if isnull.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if isnull.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetFusedOpsConstParamPackAttribute"
            )
            .entered();
            let result = ffi::cudnnGetFusedOpsConstParamPackAttribute(
                self.handle,
                paramlabel,
                param,
                isnull,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn make_fused_ops_plan(
        handle: ffi::cudnnHandle_t,
        plan: ffi::cudnnFusedOpsPlan_t,
        constpack: ffi::cudnnFusedOpsConstParamPack_t,
        workspacesizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnMakeFusedOpsPlan(handle, plan, constpack, workspacesizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaKernel_t
impl CudaKernel {
    #[inline]
    pub fn kernel_set_attribute_for_device(
        &mut self,
        attr: ffi::cudaFuncAttribute,
        value: ::core::ffi::c_int,
        device: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaKernelSetAttributeForDevice")
                    .entered();
            let result = ffi::cudaKernelSetAttributeForDevice(self.handle, attr, value, device);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnTensorTransformDescriptor_t
impl CudnnTensorTransformDescriptor {
    #[inline]
    pub fn init_transform_dest(
        &mut self,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        destsizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if destsizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if destsizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnInitTransformDest").entered();
            let result =
                ffi::cudnnInitTransformDest(self.handle, srcdesc, destdesc, destsizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_tensor_transform_descriptor(
        &mut self,
        nbdims: u32,
        destformat: ffi::cudnnTensorFormat_t,
        padbeforea: *const i32,
        padaftera: *const i32,
        folda: *const u32,
        direction: ffi::cudnnFoldingDirection_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if padbeforea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if padbeforea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if padaftera.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if padaftera.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if folda.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if folda.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetTensorTransformDescriptor")
                    .entered();
            let result = ffi::cudnnSetTensorTransformDescriptor(
                self.handle,
                nbdims,
                destformat,
                padbeforea,
                padaftera,
                folda,
                direction,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_tensor_transform_descriptor(
        &mut self,
        nbdimsrequested: u32,
        destformat: *mut ffi::cudnnTensorFormat_t,
        padbeforea: *mut i32,
        padaftera: *mut i32,
        folda: *mut u32,
        direction: *mut ffi::cudnnFoldingDirection_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if destformat.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if destformat.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if padbeforea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if padbeforea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if padaftera.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if padaftera.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if folda.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if folda.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if direction.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if direction.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetTensorTransformDescriptor")
                    .entered();
            let result = ffi::cudnnGetTensorTransformDescriptor(
                self.handle,
                nbdimsrequested,
                destformat,
                padbeforea,
                padaftera,
                folda,
                direction,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn transform_tensor_ex(
        handle: ffi::cudnnHandle_t,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnTensorDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnTransformTensorEx(
                handle, transdesc, alpha, srcdesc, srcdata, beta, destdesc, destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn transform_filter(
        handle: ffi::cudnnHandle_t,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnFilterDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnFilterDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnTransformFilter(
                handle, transdesc, alpha, srcdesc, srcdata, beta, destdesc, destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_folded_conv_backward_data_descriptors(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        transformformat: ffi::cudnnTensorFormat_t,
        foldedfilterdesc: ffi::cudnnFilterDescriptor_t,
        paddeddiffdesc: ffi::cudnnTensorDescriptor_t,
        foldedconvdesc: ffi::cudnnConvolutionDescriptor_t,
        foldedgraddesc: ffi::cudnnTensorDescriptor_t,
        filterfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        diffpadtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradunfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetFoldedConvBackwardDataDescriptors(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                transformformat,
                foldedfilterdesc,
                paddeddiffdesc,
                foldedconvdesc,
                foldedgraddesc,
                filterfoldtransdesc,
                diffpadtransdesc,
                gradfoldtransdesc,
                gradunfoldtransdesc,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnPoolingDescriptor_t
impl CudnnPoolingDescriptor {
    #[inline]
    pub fn set_pooling_2d_descriptor(
        &mut self,
        mode: ffi::cudnnPoolingMode_t,
        maxpoolingnanopt: ffi::cudnnNanPropagation_t,
        windowheight: ::core::ffi::c_int,
        windowwidth: ::core::ffi::c_int,
        verticalpadding: ::core::ffi::c_int,
        horizontalpadding: ::core::ffi::c_int,
        verticalstride: ::core::ffi::c_int,
        horizontalstride: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetPooling2dDescriptor")
                .entered();
            let result = ffi::cudnnSetPooling2dDescriptor(
                self.handle,
                mode,
                maxpoolingnanopt,
                windowheight,
                windowwidth,
                verticalpadding,
                horizontalpadding,
                verticalstride,
                horizontalstride,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_pooling_2d_descriptor(
        &mut self,
        mode: *mut ffi::cudnnPoolingMode_t,
        maxpoolingnanopt: *mut ffi::cudnnNanPropagation_t,
        windowheight: *mut ::core::ffi::c_int,
        windowwidth: *mut ::core::ffi::c_int,
        verticalpadding: *mut ::core::ffi::c_int,
        horizontalpadding: *mut ::core::ffi::c_int,
        verticalstride: *mut ::core::ffi::c_int,
        horizontalstride: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxpoolingnanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if windowheight.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if windowheight.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if windowwidth.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if windowwidth.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if verticalpadding.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if verticalpadding.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if horizontalpadding.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if horizontalpadding.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if verticalstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if verticalstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if horizontalstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if horizontalstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetPooling2dDescriptor")
                .entered();
            let result = ffi::cudnnGetPooling2dDescriptor(
                self.handle,
                mode,
                maxpoolingnanopt,
                windowheight,
                windowwidth,
                verticalpadding,
                horizontalpadding,
                verticalstride,
                horizontalstride,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_pooling_nd_descriptor(
        &mut self,
        mode: ffi::cudnnPoolingMode_t,
        maxpoolingnanopt: ffi::cudnnNanPropagation_t,
        nbdims: ::core::ffi::c_int,
        windowdima: *const ::core::ffi::c_int,
        paddinga: *const ::core::ffi::c_int,
        stridea: *const ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if windowdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if windowdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddinga.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddinga.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetPoolingNdDescriptor")
                .entered();
            let result = ffi::cudnnSetPoolingNdDescriptor(
                self.handle,
                mode,
                maxpoolingnanopt,
                nbdims,
                windowdima,
                paddinga,
                stridea,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_pooling_nd_descriptor(
        &mut self,
        nbdimsrequested: ::core::ffi::c_int,
        mode: *mut ffi::cudnnPoolingMode_t,
        maxpoolingnanopt: *mut ffi::cudnnNanPropagation_t,
        nbdims: *mut ::core::ffi::c_int,
        windowdima: *mut ::core::ffi::c_int,
        paddinga: *mut ::core::ffi::c_int,
        stridea: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxpoolingnanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if windowdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if windowdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddinga.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddinga.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetPoolingNdDescriptor")
                .entered();
            let result = ffi::cudnnGetPoolingNdDescriptor(
                self.handle,
                nbdimsrequested,
                mode,
                maxpoolingnanopt,
                nbdims,
                windowdima,
                paddinga,
                stridea,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_pooling_nd_forward_output_dim(
        &mut self,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        nbdims: ::core::ffi::c_int,
        outputtensordima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if outputtensordima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if outputtensordima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetPoolingNdForwardOutputDim")
                    .entered();
            let result = ffi::cudnnGetPoolingNdForwardOutputDim(
                self.handle,
                inputtensordesc,
                nbdims,
                outputtensordima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_pooling_2d_forward_output_dim(
        &mut self,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetPooling2dForwardOutputDim")
                    .entered();
            let result =
                ffi::cudnnGetPooling2dForwardOutputDim(self.handle, inputtensordesc, n, c, h, w);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn pooling_forward(
        handle: ffi::cudnnHandle_t,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnPoolingForward(handle, poolingdesc, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn pooling_backward(
        handle: ffi::cudnnHandle_t,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnPoolingBackward(
                handle,
                poolingdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaExternalSemaphore_t
impl CudaExternalSemaphore {
    #[inline]
    pub fn signal_external_semaphores_async(
        &mut self,
        paramsarray: *const ffi::cudaExternalSemaphoreSignalParams,
        numextsems: ::core::ffi::c_uint,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if paramsarray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paramsarray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaSignalExternalSemaphoresAsync")
                    .entered();
            let result = ffi::cudaSignalExternalSemaphoresAsync(
                &self.handle,
                paramsarray,
                numextsems,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn wait_external_semaphores_async(
        &mut self,
        paramsarray: *const ffi::cudaExternalSemaphoreWaitParams,
        numextsems: ::core::ffi::c_uint,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if paramsarray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paramsarray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaWaitExternalSemaphoresAsync")
                    .entered();
            let result =
                ffi::cudaWaitExternalSemaphoresAsync(&self.handle, paramsarray, numextsems, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn destroy_external_semaphore(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaDestroyExternalSemaphore")
                .entered();
            let result = ffi::cudaDestroyExternalSemaphore(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaMipmappedArray_const_t
impl CudaMipmappedArrayConst {
    pub fn get_mipmapped_array_level(
        levelarray: *mut ffi::cudaArray_t,
        mipmappedarray: ffi::cudaMipmappedArray_const_t,
        level: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGetMipmappedArrayLevel(levelarray, mipmappedarray, level);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaArray_const_t
impl CudaArrayConst {
    pub fn memcpy_2d_from_array(
        dst: *mut ::core::ffi::c_void,
        dpitch: usize,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMemcpy2DFromArray(dst, dpitch, src, woffset, hoffset, width, height, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_2d_array_to_array(
        dst: ffi::cudaArray_t,
        woffsetdst: usize,
        hoffsetdst: usize,
        src: ffi::cudaArray_const_t,
        woffsetsrc: usize,
        hoffsetsrc: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy2DArrayToArray(
                dst, woffsetdst, hoffsetdst, src, woffsetsrc, hoffsetsrc, width, height, kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_2d_from_array_async(
        dst: *mut ::core::ffi::c_void,
        dpitch: usize,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpy2DFromArrayAsync(
                dst, dpitch, src, woffset, hoffset, width, height, kind, stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_from_array(
        dst: *mut ::core::ffi::c_void,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyFromArray(dst, src, woffset, hoffset, count, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_array_to_array(
        dst: ffi::cudaArray_t,
        woffsetdst: usize,
        hoffsetdst: usize,
        src: ffi::cudaArray_const_t,
        woffsetsrc: usize,
        hoffsetsrc: usize,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemcpyArrayToArray(
                dst, woffsetdst, hoffsetdst, src, woffsetsrc, hoffsetsrc, count, kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn memcpy_from_array_async(
        dst: *mut ::core::ffi::c_void,
        src: ffi::cudaArray_const_t,
        woffset: usize,
        hoffset: usize,
        count: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaMemcpyFromArrayAsync(dst, src, woffset, hoffset, count, kind, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_channel_desc(
        desc: *mut ffi::cudaChannelFormatDesc,
        array: ffi::cudaArray_const_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGetChannelDesc(desc, array);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaLogsCallbackHandle
impl CudaLogsCallbackHandle {
    pub fn logs_register_callback(
        callbackfunc: ffi::cudaLogsCallback_t,
        userdata: *mut ::core::ffi::c_void,
        callback_out: *mut ffi::cudaLogsCallbackHandle,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaLogsRegisterCallback(callbackfunc, userdata, callback_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn logs_unregister_callback(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaLogsUnregisterCallback").entered();
            let result = ffi::cudaLogsUnregisterCallback(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnOpTensorDescriptor_t
impl CudnnOpTensorDescriptor {
    #[inline]
    pub fn set_op_tensor_descriptor(
        &mut self,
        optensorop: ffi::cudnnOpTensorOp_t,
        optensorcomptype: ffi::cudnnDataType_t,
        optensornanopt: ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetOpTensorDescriptor").entered();
            let result = ffi::cudnnSetOpTensorDescriptor(
                self.handle,
                optensorop,
                optensorcomptype,
                optensornanopt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_op_tensor_descriptor(
        &mut self,
        optensorop: *mut ffi::cudnnOpTensorOp_t,
        optensorcomptype: *mut ffi::cudnnDataType_t,
        optensornanopt: *mut ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if optensorop.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if optensorcomptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if optensornanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetOpTensorDescriptor").entered();
            let result = ffi::cudnnGetOpTensorDescriptor(
                self.handle,
                optensorop,
                optensorcomptype,
                optensornanopt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn op_tensor(
        handle: ffi::cudnnHandle_t,
        optensordesc: ffi::cudnnOpTensorDescriptor_t,
        alpha1: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        alpha2: *const ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        b: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnOpTensor(
                handle,
                optensordesc,
                alpha1,
                adesc,
                a,
                alpha2,
                bdesc,
                b,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnReduceTensorDescriptor_t
impl CudnnReduceTensorDescriptor {
    #[inline]
    pub fn set_reduce_tensor_descriptor(
        &mut self,
        reducetensorop: ffi::cudnnReduceTensorOp_t,
        reducetensorcomptype: ffi::cudnnDataType_t,
        reducetensornanopt: ffi::cudnnNanPropagation_t,
        reducetensorindices: ffi::cudnnReduceTensorIndices_t,
        reducetensorindicestype: ffi::cudnnIndicesType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetReduceTensorDescriptor")
                    .entered();
            let result = ffi::cudnnSetReduceTensorDescriptor(
                self.handle,
                reducetensorop,
                reducetensorcomptype,
                reducetensornanopt,
                reducetensorindices,
                reducetensorindicestype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_reduce_tensor_descriptor(
        &mut self,
        reducetensorop: *mut ffi::cudnnReduceTensorOp_t,
        reducetensorcomptype: *mut ffi::cudnnDataType_t,
        reducetensornanopt: *mut ffi::cudnnNanPropagation_t,
        reducetensorindices: *mut ffi::cudnnReduceTensorIndices_t,
        reducetensorindicestype: *mut ffi::cudnnIndicesType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if reducetensorop.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reducetensorop.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reducetensorcomptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reducetensorcomptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reducetensornanopt.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reducetensorindices.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reducetensorindices.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reducetensorindicestype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reducetensorindicestype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetReduceTensorDescriptor")
                    .entered();
            let result = ffi::cudnnGetReduceTensorDescriptor(
                self.handle,
                reducetensorop,
                reducetensorcomptype,
                reducetensornanopt,
                reducetensorindices,
                reducetensorindicestype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_reduction_indices_size(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetReductionIndicesSize(
                handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_reduction_workspace_size(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetReductionWorkspaceSize(
                handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn reduce_tensor(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        indices: *mut ::core::ffi::c_void,
        indicessizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnReduceTensor(
                handle,
                reducetensordesc,
                indices,
                indicessizeinbytes,
                workspace,
                workspacesizeinbytes,
                alpha,
                adesc,
                a,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaAsyncCallback
impl CudaAsyncCallback {
    pub fn device_register_async_notification(
        device: ::core::ffi::c_int,
        callbackfunc: ffi::cudaAsyncCallback,
        userdata: *mut ::core::ffi::c_void,
        callback: *mut ffi::cudaAsyncCallbackHandle_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaDeviceRegisterAsyncNotification(device, callbackfunc, userdata, callback);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn device_unregister_async_notification(
        device: ::core::ffi::c_int,
        callback: ffi::cudaAsyncCallbackHandle_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaDeviceUnregisterAsyncNotification(device, callback);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnDropoutDescriptor_t
impl CudnnDropoutDescriptor {
    #[inline]
    pub fn set_dropout_descriptor(
        &mut self,
        handle: ffi::cudnnHandle_t,
        dropout: f32,
        states: *mut ::core::ffi::c_void,
        statesizeinbytes: usize,
        seed: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetDropoutDescriptor").entered();
            let result = ffi::cudnnSetDropoutDescriptor(
                self.handle,
                handle,
                dropout,
                states,
                statesizeinbytes,
                seed,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn restore_dropout_descriptor(
        &mut self,
        handle: ffi::cudnnHandle_t,
        dropout: f32,
        states: *mut ::core::ffi::c_void,
        statesizeinbytes: usize,
        seed: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnRestoreDropoutDescriptor")
                    .entered();
            let result = ffi::cudnnRestoreDropoutDescriptor(
                self.handle,
                handle,
                dropout,
                states,
                statesizeinbytes,
                seed,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_dropout_descriptor(
        &mut self,
        handle: ffi::cudnnHandle_t,
        dropout: *mut f32,
        states: *mut *mut ::core::ffi::c_void,
        seed: *mut ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dropout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dropout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if states.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if seed.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seed.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetDropoutDescriptor").entered();
            let result = ffi::cudnnGetDropoutDescriptor(self.handle, handle, dropout, states, seed);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn dropout_forward(
        handle: ffi::cudnnHandle_t,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDropoutForward(
                handle,
                dropoutdesc,
                xdesc,
                x,
                ydesc,
                y,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn dropout_backward(
        handle: ffi::cudnnHandle_t,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDropoutBackward(
                handle,
                dropoutdesc,
                dydesc,
                dy,
                dxdesc,
                dx,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_rnn_descriptor_v_8(
        rnndesc: ffi::cudnnRNNDescriptor_t,
        algo: ffi::cudnnRNNAlgo_t,
        cellmode: ffi::cudnnRNNMode_t,
        biasmode: ffi::cudnnRNNBiasMode_t,
        dirmode: ffi::cudnnDirectionMode_t,
        inputmode: ffi::cudnnRNNInputMode_t,
        datatype: ffi::cudnnDataType_t,
        mathprec: ffi::cudnnDataType_t,
        mathtype: ffi::cudnnMathType_t,
        inputsize: i32,
        hiddensize: i32,
        projsize: i32,
        numlayers: i32,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        auxflags: u32,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetRNNDescriptor_v8(
                rnndesc,
                algo,
                cellmode,
                biasmode,
                dirmode,
                inputmode,
                datatype,
                mathprec,
                mathtype,
                inputsize,
                hiddensize,
                projsize,
                numlayers,
                dropoutdesc,
                auxflags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_rnn_descriptor_v_8(
        rnndesc: ffi::cudnnRNNDescriptor_t,
        algo: *mut ffi::cudnnRNNAlgo_t,
        cellmode: *mut ffi::cudnnRNNMode_t,
        biasmode: *mut ffi::cudnnRNNBiasMode_t,
        dirmode: *mut ffi::cudnnDirectionMode_t,
        inputmode: *mut ffi::cudnnRNNInputMode_t,
        datatype: *mut ffi::cudnnDataType_t,
        mathprec: *mut ffi::cudnnDataType_t,
        mathtype: *mut ffi::cudnnMathType_t,
        inputsize: *mut i32,
        hiddensize: *mut i32,
        projsize: *mut i32,
        numlayers: *mut i32,
        dropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        auxflags: *mut u32,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNDescriptor_v8(
                rnndesc,
                algo,
                cellmode,
                biasmode,
                dirmode,
                inputmode,
                datatype,
                mathprec,
                mathtype,
                inputsize,
                hiddensize,
                projsize,
                numlayers,
                dropoutdesc,
                auxflags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_attn_descriptor(
        attndesc: ffi::cudnnAttnDescriptor_t,
        attnmode: ::core::ffi::c_uint,
        nheads: ::core::ffi::c_int,
        smscaler: f64,
        datatype: ffi::cudnnDataType_t,
        computeprec: ffi::cudnnDataType_t,
        mathtype: ffi::cudnnMathType_t,
        attndropoutdesc: ffi::cudnnDropoutDescriptor_t,
        postdropoutdesc: ffi::cudnnDropoutDescriptor_t,
        qsize: ::core::ffi::c_int,
        ksize: ::core::ffi::c_int,
        vsize: ::core::ffi::c_int,
        qprojsize: ::core::ffi::c_int,
        kprojsize: ::core::ffi::c_int,
        vprojsize: ::core::ffi::c_int,
        oprojsize: ::core::ffi::c_int,
        qomaxseqlength: ::core::ffi::c_int,
        kvmaxseqlength: ::core::ffi::c_int,
        maxbatchsize: ::core::ffi::c_int,
        maxbeamsize: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetAttnDescriptor(
                attndesc,
                attnmode,
                nheads,
                smscaler,
                datatype,
                computeprec,
                mathtype,
                attndropoutdesc,
                postdropoutdesc,
                qsize,
                ksize,
                vsize,
                qprojsize,
                kprojsize,
                vprojsize,
                oprojsize,
                qomaxseqlength,
                kvmaxseqlength,
                maxbatchsize,
                maxbeamsize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_attn_descriptor(
        attndesc: ffi::cudnnAttnDescriptor_t,
        attnmode: *mut ::core::ffi::c_uint,
        nheads: *mut ::core::ffi::c_int,
        smscaler: *mut f64,
        datatype: *mut ffi::cudnnDataType_t,
        computeprec: *mut ffi::cudnnDataType_t,
        mathtype: *mut ffi::cudnnMathType_t,
        attndropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        postdropoutdesc: *mut ffi::cudnnDropoutDescriptor_t,
        qsize: *mut ::core::ffi::c_int,
        ksize: *mut ::core::ffi::c_int,
        vsize: *mut ::core::ffi::c_int,
        qprojsize: *mut ::core::ffi::c_int,
        kprojsize: *mut ::core::ffi::c_int,
        vprojsize: *mut ::core::ffi::c_int,
        oprojsize: *mut ::core::ffi::c_int,
        qomaxseqlength: *mut ::core::ffi::c_int,
        kvmaxseqlength: *mut ::core::ffi::c_int,
        maxbatchsize: *mut ::core::ffi::c_int,
        maxbeamsize: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetAttnDescriptor(
                attndesc,
                attnmode,
                nheads,
                smscaler,
                datatype,
                computeprec,
                mathtype,
                attndropoutdesc,
                postdropoutdesc,
                qsize,
                ksize,
                vsize,
                qprojsize,
                kprojsize,
                vprojsize,
                oprojsize,
                qomaxseqlength,
                kvmaxseqlength,
                maxbatchsize,
                maxbeamsize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaEvent_t
impl CudaEvent {
    pub fn ipc_get_event_handle(
        handle: *mut ffi::cudaIpcEventHandle_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaIpcGetEventHandle(handle, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn stream_wait_event(
        stream: ffi::cudaStream_t,
        event: ffi::cudaEvent_t,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamWaitEvent(stream, event, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn event_record(&mut self, stream: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaEventRecord").entered();
            let result = ffi::cudaEventRecord(self.handle, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn event_record_with_flags(
        &mut self,
        stream: ffi::cudaStream_t,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaEventRecordWithFlags").entered();
            let result = ffi::cudaEventRecordWithFlags(self.handle, stream, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn event_query(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaEventQuery").entered();
            let result = ffi::cudaEventQuery(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn event_synchronize(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaEventSynchronize").entered();
            let result = ffi::cudaEventSynchronize(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn event_elapsed_time(
        ms: *mut f32,
        start: ffi::cudaEvent_t,
        end: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaEventElapsedTime(ms, start, end);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_event_record_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddEventRecordNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                event,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_event_record_node_get_event(
        node: ffi::cudaGraphNode_t,
        event_out: *mut ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphEventRecordNodeGetEvent(node, event_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_event_record_node_set_event(
        node: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphEventRecordNodeSetEvent(node, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_event_wait_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddEventWaitNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                event,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_event_wait_node_get_event(
        node: ffi::cudaGraphNode_t,
        event_out: *mut ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphEventWaitNodeGetEvent(node, event_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_event_wait_node_set_event(
        node: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphEventWaitNodeSetEvent(node, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_event_record_node_set_event(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecEventRecordNodeSetEvent(hgraphexec, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_event_wait_node_set_event(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecEventWaitNodeSetEvent(hgraphexec, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnCTCLossDescriptor_t
impl CudnnCTCLossDescriptor {
    #[inline]
    pub fn set_ctc_loss_descriptor(&mut self, comptype: ffi::cudnnDataType_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetCTCLossDescriptor").entered();
            let result = ffi::cudnnSetCTCLossDescriptor(self.handle, comptype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_ctc_loss_descriptor_ex(
        &mut self,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        gradmode: ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetCTCLossDescriptorEx")
                .entered();
            let result =
                ffi::cudnnSetCTCLossDescriptorEx(self.handle, comptype, normmode, gradmode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_ctc_loss_descriptor_v_8(
        &mut self,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        gradmode: ffi::cudnnNanPropagation_t,
        maxlabellength: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetCTCLossDescriptor_v8")
                .entered();
            let result = ffi::cudnnSetCTCLossDescriptor_v8(
                self.handle,
                comptype,
                normmode,
                gradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_ctc_loss_descriptor_v_9(
        &mut self,
        comptype: ffi::cudnnDataType_t,
        normmode: ffi::cudnnLossNormalizationMode_t,
        ctcgradmode: ffi::cudnnCTCGradMode_t,
        maxlabellength: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetCTCLossDescriptor_v9")
                .entered();
            let result = ffi::cudnnSetCTCLossDescriptor_v9(
                self.handle,
                comptype,
                normmode,
                ctcgradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_descriptor(
        &mut self,
        comptype: *mut ffi::cudnnDataType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossDescriptor").entered();
            let result = ffi::cudnnGetCTCLossDescriptor(self.handle, comptype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_descriptor_ex(
        &mut self,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        gradmode: *mut ffi::cudnnNanPropagation_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if gradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if gradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossDescriptorEx")
                .entered();
            let result =
                ffi::cudnnGetCTCLossDescriptorEx(self.handle, comptype, normmode, gradmode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_descriptor_v_8(
        &mut self,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        gradmode: *mut ffi::cudnnNanPropagation_t,
        maxlabellength: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if gradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if gradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxlabellength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maxlabellength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossDescriptor_v8")
                .entered();
            let result = ffi::cudnnGetCTCLossDescriptor_v8(
                self.handle,
                comptype,
                normmode,
                gradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_descriptor_v_9(
        &mut self,
        comptype: *mut ffi::cudnnDataType_t,
        normmode: *mut ffi::cudnnLossNormalizationMode_t,
        ctcgradmode: *mut ffi::cudnnCTCGradMode_t,
        maxlabellength: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if comptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ctcgradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ctcgradmode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxlabellength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maxlabellength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossDescriptor_v9")
                .entered();
            let result = ffi::cudnnGetCTCLossDescriptor_v9(
                self.handle,
                comptype,
                normmode,
                ctcgradmode,
                maxlabellength,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn ctc_loss(
        handle: ffi::cudnnHandle_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        hostlabels: *const ::core::ffi::c_int,
        hostlabellengths: *const ::core::ffi::c_int,
        hostinputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnCTCLoss(
                handle,
                probsdesc,
                probs,
                hostlabels,
                hostlabellengths,
                hostinputlengths,
                costs,
                gradientsdesc,
                gradients,
                algo,
                ctclossdesc,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn ctc_loss_v_8(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnCTCLoss_v8(
                handle,
                algo,
                ctclossdesc,
                probsdesc,
                probs,
                labels,
                labellengths,
                inputlengths,
                costs,
                gradientsdesc,
                gradients,
                workspacesizeinbytes,
                workspace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_workspace_size(
        handle: ffi::cudnnHandle_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossWorkspaceSize(
                handle,
                probsdesc,
                gradientsdesc,
                labels,
                labellengths,
                inputlengths,
                algo,
                ctclossdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_workspace_size_v_8(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossWorkspaceSize_v8(
                handle,
                algo,
                ctclossdesc,
                probsdesc,
                gradientsdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnBackendDescriptor_t
impl CudnnBackendDescriptor {
    pub fn backend_create_descriptor(
        descriptortype: ffi::cudnnBackendDescriptorType_t,
        descriptor: *mut ffi::cudnnBackendDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBackendCreateDescriptor(descriptortype, descriptor);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_destroy_descriptor(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendDestroyDescriptor")
                    .entered();
            let result = ffi::cudnnBackendDestroyDescriptor(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_initialize(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendInitialize").entered();
            let result = ffi::cudnnBackendInitialize(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_finalize(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendFinalize").entered();
            let result = ffi::cudnnBackendFinalize(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_set_attribute(
        &mut self,
        attributename: ffi::cudnnBackendAttributeName_t,
        attributetype: ffi::cudnnBackendAttributeType_t,
        elementcount: i64,
        arrayofelements: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if arrayofelements.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if arrayofelements.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendSetAttribute").entered();
            let result = ffi::cudnnBackendSetAttribute(
                self.handle,
                attributename,
                attributetype,
                elementcount,
                arrayofelements,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_get_attribute(
        &mut self,
        attributename: ffi::cudnnBackendAttributeName_t,
        attributetype: ffi::cudnnBackendAttributeType_t,
        requestedelementcount: i64,
        elementcount: *mut i64,
        arrayofelements: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if elementcount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if elementcount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if arrayofelements.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if arrayofelements.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendGetAttribute").entered();
            let result = ffi::cudnnBackendGetAttribute(
                self.handle,
                attributename,
                attributetype,
                requestedelementcount,
                elementcount,
                arrayofelements,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn backend_execute(
        handle: ffi::cudnnHandle_t,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBackendExecute(handle, executionplan, variantpack);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn backend_populate_cuda_graph(
        handle: ffi::cudnnHandle_t,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnBackendPopulateCudaGraph(handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn backend_update_cuda_graph(
        handle: ffi::cudnnHandle_t,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnBackendUpdateCudaGraph(handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnHandle_t
impl CudnnHandle {
    #[inline]
    pub fn query_runtime_error(
        &mut self,
        rstatus: *mut ffi::cudnnStatus_t,
        mode: ffi::cudnnErrQueryMode_t,
        tag: *mut ffi::cudnnRuntimeTag_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if rstatus.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if rstatus.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if tag.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if tag.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnQueryRuntimeError").entered();
            let result = ffi::cudnnQueryRuntimeError(self.handle, rstatus, mode, tag);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_stream(&mut self, streamid: ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetStream").entered();
            let result = ffi::cudnnSetStream(self.handle, streamid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_stream(&mut self, streamid: *mut ffi::cudaStream_t) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if streamid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if streamid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetStream").entered();
            let result = ffi::cudnnGetStream(self.handle, streamid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_execute(
        &mut self,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendExecute").entered();
            let result = ffi::cudnnBackendExecute(self.handle, executionplan, variantpack);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_populate_cuda_graph(
        &mut self,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBackendPopulateCudaGraph")
                    .entered();
            let result =
                ffi::cudnnBackendPopulateCudaGraph(self.handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn backend_update_cuda_graph(
        &mut self,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnBackendUpdateCudaGraph")
                .entered();
            let result =
                ffi::cudnnBackendUpdateCudaGraph(self.handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn transform_tensor(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnTransformTensor").entered();
            let result = ffi::cudnnTransformTensor(self.handle, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn transform_tensor_ex(
        &mut self,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnTensorDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if srcdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if srcdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if destdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if destdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnTransformTensorEx").entered();
            let result = ffi::cudnnTransformTensorEx(
                self.handle,
                transdesc,
                alpha,
                srcdesc,
                srcdata,
                beta,
                destdesc,
                destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn add_tensor(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnAddTensor").entered();
            let result = ffi::cudnnAddTensor(self.handle, alpha, adesc, a, beta, cdesc, c);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn op_tensor(
        &mut self,
        optensordesc: ffi::cudnnOpTensorDescriptor_t,
        alpha1: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        alpha2: *const ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        b: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha1.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha1.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alpha2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if b.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if b.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnOpTensor").entered();
            let result = ffi::cudnnOpTensor(
                self.handle,
                optensordesc,
                alpha1,
                adesc,
                a,
                alpha2,
                bdesc,
                b,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_reduction_indices_size(
        &mut self,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetReductionIndicesSize")
                .entered();
            let result = ffi::cudnnGetReductionIndicesSize(
                self.handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_reduction_workspace_size(
        &mut self,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetReductionWorkspaceSize")
                    .entered();
            let result = ffi::cudnnGetReductionWorkspaceSize(
                self.handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn reduce_tensor(
        &mut self,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        indices: *mut ::core::ffi::c_void,
        indicessizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if indices.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if indices.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if a.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnReduceTensor").entered();
            let result = ffi::cudnnReduceTensor(
                self.handle,
                reducetensordesc,
                indices,
                indicessizeinbytes,
                workspace,
                workspacesizeinbytes,
                alpha,
                adesc,
                a,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_tensor(
        &mut self,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        valueptr: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if valueptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if valueptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetTensor").entered();
            let result = ffi::cudnnSetTensor(self.handle, ydesc, y, valueptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn scale_tensor(
        &mut self,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        alpha: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnScaleTensor").entered();
            let result = ffi::cudnnScaleTensor(self.handle, ydesc, y, alpha);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn transform_filter(
        &mut self,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnFilterDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnFilterDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if srcdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if srcdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if destdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if destdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnTransformFilter").entered();
            let result = ffi::cudnnTransformFilter(
                self.handle,
                transdesc,
                alpha,
                srcdesc,
                srcdata,
                beta,
                destdesc,
                destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn softmax_forward(
        &mut self,
        algo: ffi::cudnnSoftmaxAlgorithm_t,
        mode: ffi::cudnnSoftmaxMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSoftmaxForward").entered();
            let result =
                ffi::cudnnSoftmaxForward(self.handle, algo, mode, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn pooling_forward(
        &mut self,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnPoolingForward").entered();
            let result =
                ffi::cudnnPoolingForward(self.handle, poolingdesc, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn activation_forward(
        &mut self,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnActivationForward").entered();
            let result = ffi::cudnnActivationForward(
                self.handle,
                activationdesc,
                alpha,
                xdesc,
                x,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn lrn_cross_channel_forward(
        &mut self,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnLRNCrossChannelForward")
                .entered();
            let result = ffi::cudnnLRNCrossChannelForward(
                self.handle,
                normdesc,
                lrnmode,
                alpha,
                xdesc,
                x,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn divisive_normalization_forward(
        &mut self,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if means.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if means.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if temp.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if temp.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if temp2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if temp2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDivisiveNormalizationForward")
                    .entered();
            let result = ffi::cudnnDivisiveNormalizationForward(
                self.handle,
                normdesc,
                mode,
                alpha,
                xdesc,
                x,
                means,
                temp,
                temp2,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn batch_normalization_forward_inference(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        estimatedmean: *const ::core::ffi::c_void,
        estimatedvariance: *const ::core::ffi::c_void,
        epsilon: f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if estimatedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if estimatedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if estimatedvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if estimatedvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnBatchNormalizationForwardInference"
            )
            .entered();
            let result = ffi::cudnnBatchNormalizationForwardInference(
                self.handle,
                mode,
                alpha,
                beta,
                xdesc,
                x,
                ydesc,
                y,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                estimatedmean,
                estimatedvariance,
                epsilon,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn normalization_forward_inference(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        estimatedmean: *const ::core::ffi::c_void,
        estimatedvariance: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        epsilon: f64,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if estimatedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if estimatedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if estimatedvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if estimatedvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if z.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if z.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnNormalizationForwardInference")
                    .entered();
            let result = ffi::cudnnNormalizationForwardInference(
                self.handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                x,
                normscalebiasdesc,
                normscale,
                normbias,
                normmeanvardesc,
                estimatedmean,
                estimatedvariance,
                zdesc,
                z,
                activationdesc,
                ydesc,
                y,
                epsilon,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn spatial_tf_grid_generator_forward(
        &mut self,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        theta: *const ::core::ffi::c_void,
        grid: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if theta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if theta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSpatialTfGridGeneratorForward")
                    .entered();
            let result = ffi::cudnnSpatialTfGridGeneratorForward(self.handle, stdesc, theta, grid);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn spatial_tf_sampler_forward(
        &mut self,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSpatialTfSamplerForward")
                .entered();
            let result = ffi::cudnnSpatialTfSamplerForward(
                self.handle,
                stdesc,
                alpha,
                xdesc,
                x,
                grid,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn dropout_get_states_size(&mut self, sizeinbytes: *mut usize) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDropoutGetStatesSize").entered();
            let result = ffi::cudnnDropoutGetStatesSize(self.handle, sizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_dropout_descriptor(
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        handle: ffi::cudnnHandle_t,
        dropout: f32,
        states: *mut ::core::ffi::c_void,
        statesizeinbytes: usize,
        seed: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetDropoutDescriptor(
                dropoutdesc,
                handle,
                dropout,
                states,
                statesizeinbytes,
                seed,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn restore_dropout_descriptor(
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        handle: ffi::cudnnHandle_t,
        dropout: f32,
        states: *mut ::core::ffi::c_void,
        statesizeinbytes: usize,
        seed: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRestoreDropoutDescriptor(
                dropoutdesc,
                handle,
                dropout,
                states,
                statesizeinbytes,
                seed,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_dropout_descriptor(
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        handle: ffi::cudnnHandle_t,
        dropout: *mut f32,
        states: *mut *mut ::core::ffi::c_void,
        seed: *mut ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetDropoutDescriptor(dropoutdesc, handle, dropout, states, seed);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn dropout_forward(
        &mut self,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDropoutForward").entered();
            let result = ffi::cudnnDropoutForward(
                self.handle,
                dropoutdesc,
                xdesc,
                x,
                ydesc,
                y,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn softmax_backward(
        &mut self,
        algo: ffi::cudnnSoftmaxAlgorithm_t,
        mode: ffi::cudnnSoftmaxMode_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSoftmaxBackward").entered();
            let result = ffi::cudnnSoftmaxBackward(
                self.handle,
                algo,
                mode,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn pooling_backward(
        &mut self,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnPoolingBackward").entered();
            let result = ffi::cudnnPoolingBackward(
                self.handle,
                poolingdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn activation_backward(
        &mut self,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnActivationBackward").entered();
            let result = ffi::cudnnActivationBackward(
                self.handle,
                activationdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn lrn_cross_channel_backward(
        &mut self,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnLRNCrossChannelBackward")
                .entered();
            let result = ffi::cudnnLRNCrossChannelBackward(
                self.handle,
                normdesc,
                lrnmode,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn divisive_normalization_backward(
        &mut self,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdmeansdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        dmeans: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if means.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if means.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if temp.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if temp.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if temp2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if temp2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dmeans.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dmeans.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDivisiveNormalizationBackward")
                    .entered();
            let result = ffi::cudnnDivisiveNormalizationBackward(
                self.handle,
                normdesc,
                mode,
                alpha,
                xdesc,
                x,
                means,
                dy,
                temp,
                temp2,
                beta,
                dxdmeansdesc,
                dx,
                dmeans,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_batch_normalization_forward_training_ex_workspace_size(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
                self.handle,
                mode,
                bnops,
                xdesc,
                zdesc,
                ydesc,
                bnscalebiasmeanvardesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_batch_normalization_backward_ex_workspace_size(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetBatchNormalizationBackwardExWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetBatchNormalizationBackwardExWorkspaceSize(
                self.handle,
                mode,
                bnops,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dbnscalebiasdesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_batch_normalization_training_ex_reserve_space_size(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetBatchNormalizationTrainingExReserveSpaceSize"
            )
            .entered();
            let result = ffi::cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
                self.handle,
                mode,
                bnops,
                activationdesc,
                xdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn batch_normalization_forward_training(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnBatchNormalizationForwardTraining"
            )
            .entered();
            let result = ffi::cudnnBatchNormalizationForwardTraining(
                self.handle,
                mode,
                alpha,
                beta,
                xdesc,
                x,
                ydesc,
                y,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                exponentialaveragefactor,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn batch_normalization_forward_training_ex(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if zdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if zdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnBatchNormalizationForwardTrainingEx"
            )
            .entered();
            let result = ffi::cudnnBatchNormalizationForwardTrainingEx(
                self.handle,
                mode,
                bnops,
                alpha,
                beta,
                xdesc,
                xdata,
                zdesc,
                zdata,
                ydesc,
                ydata,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                exponentialaveragefactor,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn batch_normalization_backward(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        dbnscaleresult: *mut ::core::ffi::c_void,
        dbnbiasresult: *mut ::core::ffi::c_void,
        epsilon: f64,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dbnscaleresult.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dbnscaleresult.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dbnbiasresult.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dbnbiasresult.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBatchNormalizationBackward")
                    .entered();
            let result = ffi::cudnnBatchNormalizationBackward(
                self.handle,
                mode,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                x,
                dydesc,
                dy,
                dxdesc,
                dx,
                dbnscalebiasdesc,
                bnscale,
                dbnscaleresult,
                dbnbiasresult,
                epsilon,
                savedmean,
                savedinvvariance,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn batch_normalization_backward_ex(
        &mut self,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        bnscaledata: *const ::core::ffi::c_void,
        bnbiasdata: *const ::core::ffi::c_void,
        dbnscaledata: *mut ::core::ffi::c_void,
        dbnbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dzdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dzdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dxdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dxdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bnbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bnbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dbnscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dbnscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dbnbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dbnbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBatchNormalizationBackwardEx")
                    .entered();
            let result = ffi::cudnnBatchNormalizationBackwardEx(
                self.handle,
                mode,
                bnops,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dbnscalebiasdesc,
                bnscaledata,
                bnbiasdata,
                dbnscaledata,
                dbnbiasdata,
                epsilon,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_normalization_forward_training_workspace_size(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetNormalizationForwardTrainingWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetNormalizationForwardTrainingWorkspaceSize(
                self.handle,
                mode,
                normops,
                algo,
                xdesc,
                zdesc,
                ydesc,
                normscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_normalization_backward_workspace_size(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetNormalizationBackwardWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetNormalizationBackwardWorkspaceSize(
                self.handle,
                mode,
                normops,
                algo,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dnormscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_normalization_training_reserve_space_size(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetNormalizationTrainingReserveSpaceSize"
            )
            .entered();
            let result = ffi::cudnnGetNormalizationTrainingReserveSpaceSize(
                self.handle,
                mode,
                normops,
                algo,
                activationdesc,
                xdesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn normalization_forward_training(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normscale.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normbias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultrunningvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsavemean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if resultsaveinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if zdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if zdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnNormalizationForwardTraining")
                    .entered();
            let result = ffi::cudnnNormalizationForwardTraining(
                self.handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                xdata,
                normscalebiasdesc,
                normscale,
                normbias,
                exponentialaveragefactor,
                normmeanvardesc,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                zdesc,
                zdata,
                ydesc,
                ydata,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn normalization_backward(
        &mut self,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscaledata: *const ::core::ffi::c_void,
        normbiasdata: *const ::core::ffi::c_void,
        dnormscaledata: *mut ::core::ffi::c_void,
        dnormbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betadatadiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betaparamdiff.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if xdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dydata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dzdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dzdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dxdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dxdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if normbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if normbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dnormscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dnormscaledata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dnormbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dnormbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedmean.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if savedinvvariance.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnNormalizationBackward").entered();
            let result = ffi::cudnnNormalizationBackward(
                self.handle,
                mode,
                normops,
                algo,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dnormscalebiasdesc,
                normscaledata,
                normbiasdata,
                dnormscaledata,
                dnormbiasdata,
                epsilon,
                normmeanvardesc,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn spatial_tf_grid_generator_backward(
        &mut self,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        dgrid: *const ::core::ffi::c_void,
        dtheta: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dtheta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dtheta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSpatialTfGridGeneratorBackward")
                    .entered();
            let result =
                ffi::cudnnSpatialTfGridGeneratorBackward(self.handle, stdesc, dgrid, dtheta);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn spatial_tf_sampler_backward(
        &mut self,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        alphadgrid: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        betadgrid: *const ::core::ffi::c_void,
        dgrid: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alphadgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alphadgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if grid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if betadgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if betadgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dgrid.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSpatialTfSamplerBackward")
                    .entered();
            let result = ffi::cudnnSpatialTfSamplerBackward(
                self.handle,
                stdesc,
                alpha,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
                alphadgrid,
                dydesc,
                dy,
                grid,
                betadgrid,
                dgrid,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn dropout_backward(
        &mut self,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDropoutBackward").entered();
            let result = ffi::cudnnDropoutBackward(
                self.handle,
                dropoutdesc,
                dydesc,
                dy,
                dxdesc,
                dx,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn build_rnn_dynamic(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        minibatch: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnBuildRNNDynamic").entered();
            let result = ffi::cudnnBuildRNNDynamic(self.handle, rnndesc, minibatch);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_rnn_temp_space_sizes(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        workspacesize: *mut usize,
        reservespacesize: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if workspacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetRNNTempSpaceSizes").entered();
            let result = ffi::cudnnGetRNNTempSpaceSizes(
                self.handle,
                rnndesc,
                fwdmode,
                xdesc,
                workspacesize,
                reservespacesize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_rnn_weight_space_size(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        weightspacesize: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if weightspacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weightspacesize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetRNNWeightSpaceSize").entered();
            let result = ffi::cudnnGetRNNWeightSpaceSize(self.handle, rnndesc, weightspacesize);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_rnn_weight_params(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        pseudolayer: i32,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        linlayerid: i32,
        mdesc: ffi::cudnnTensorDescriptor_t,
        maddr: *mut *mut ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        baddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if baddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if baddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetRNNWeightParams").entered();
            let result = ffi::cudnnGetRNNWeightParams(
                self.handle,
                rnndesc,
                pseudolayer,
                weightspacesize,
                weightspace,
                linlayerid,
                mdesc,
                maddr,
                bdesc,
                baddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_forward(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        hy: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        cy: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if cx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if cx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if cy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if cy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnRNNForward").entered();
            let result = ffi::cudnnRNNForward(
                self.handle,
                rnndesc,
                fwdmode,
                devseqlengths,
                xdesc,
                x,
                ydesc,
                y,
                hdesc,
                hx,
                hy,
                cdesc,
                cx,
                cy,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_multi_head_attn_buffers(
        &mut self,
        attndesc: ffi::cudnnAttnDescriptor_t,
        weightsizeinbytes: *mut usize,
        workspacesizeinbytes: *mut usize,
        reservespacesizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if weightsizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weightsizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetMultiHeadAttnBuffers")
                .entered();
            let result = ffi::cudnnGetMultiHeadAttnBuffers(
                self.handle,
                attndesc,
                weightsizeinbytes,
                workspacesizeinbytes,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_multi_head_attn_weights(
        &mut self,
        attndesc: ffi::cudnnAttnDescriptor_t,
        wkind: ffi::cudnnMultiHeadAttnWeightKind_t,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnTensorDescriptor_t,
        waddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if waddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if waddr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetMultiHeadAttnWeights")
                .entered();
            let result = ffi::cudnnGetMultiHeadAttnWeights(
                self.handle,
                attndesc,
                wkind,
                weightsizeinbytes,
                weights,
                wdesc,
                waddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn multi_head_attn_forward(
        &mut self,
        attndesc: ffi::cudnnAttnDescriptor_t,
        curridx: ::core::ffi::c_int,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsqo: *const ::core::ffi::c_int,
        devseqlengthskv: *const ::core::ffi::c_int,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        residuals: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        odesc: ffi::cudnnSeqDataDescriptor_t,
        out: *mut ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if lowinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lowinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hiwinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hiwinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if devseqlengthsqo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengthsqo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if devseqlengthskv.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengthskv.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if residuals.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if residuals.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnMultiHeadAttnForward").entered();
            let result = ffi::cudnnMultiHeadAttnForward(
                self.handle,
                attndesc,
                curridx,
                lowinidx,
                hiwinidx,
                devseqlengthsqo,
                devseqlengthskv,
                qdesc,
                queries,
                residuals,
                kdesc,
                keys,
                vdesc,
                values,
                odesc,
                out,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_backward_data_v_8(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        devseqlengths: *const i32,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        dhy: *const ::core::ffi::c_void,
        dhx: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        dcy: *const ::core::ffi::c_void,
        dcx: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dhy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dhy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dhx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dhx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if cx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if cx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dcy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dcy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dcx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dcx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnRNNBackwardData_v8").entered();
            let result = ffi::cudnnRNNBackwardData_v8(
                self.handle,
                rnndesc,
                devseqlengths,
                ydesc,
                y,
                dy,
                xdesc,
                dx,
                hdesc,
                hx,
                dhy,
                dhx,
                cdesc,
                cx,
                dcy,
                dcx,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn rnn_backward_weights_v_8(
        &mut self,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        weightspacesize: usize,
        dweightspace: *mut ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dweightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dweightspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnRNNBackwardWeights_v8").entered();
            let result = ffi::cudnnRNNBackwardWeights_v8(
                self.handle,
                rnndesc,
                addgrad,
                devseqlengths,
                xdesc,
                x,
                hdesc,
                hx,
                ydesc,
                y,
                weightspacesize,
                dweightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn multi_head_attn_backward_data(
        &mut self,
        attndesc: ffi::cudnnAttnDescriptor_t,
        lowinidx: *const ::core::ffi::c_int,
        hiwinidx: *const ::core::ffi::c_int,
        devseqlengthsdqdo: *const ::core::ffi::c_int,
        devseqlengthsdkdv: *const ::core::ffi::c_int,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        dqdesc: ffi::cudnnSeqDataDescriptor_t,
        dqueries: *mut ::core::ffi::c_void,
        queries: *const ::core::ffi::c_void,
        dkdesc: ffi::cudnnSeqDataDescriptor_t,
        dkeys: *mut ::core::ffi::c_void,
        keys: *const ::core::ffi::c_void,
        dvdesc: ffi::cudnnSeqDataDescriptor_t,
        dvalues: *mut ::core::ffi::c_void,
        values: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if lowinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lowinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hiwinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hiwinidx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if devseqlengthsdqdo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengthsdqdo.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if devseqlengthsdkdv.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if devseqlengthsdkdv.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dqueries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dqueries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dkeys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dkeys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dvalues.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dvalues.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnMultiHeadAttnBackwardData")
                    .entered();
            let result = ffi::cudnnMultiHeadAttnBackwardData(
                self.handle,
                attndesc,
                lowinidx,
                hiwinidx,
                devseqlengthsdqdo,
                devseqlengthsdkdv,
                dodesc,
                dout,
                dqdesc,
                dqueries,
                queries,
                dkdesc,
                dkeys,
                keys,
                dvdesc,
                dvalues,
                values,
                weightsizeinbytes,
                weights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn multi_head_attn_backward_weights(
        &mut self,
        attndesc: ffi::cudnnAttnDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        qdesc: ffi::cudnnSeqDataDescriptor_t,
        queries: *const ::core::ffi::c_void,
        kdesc: ffi::cudnnSeqDataDescriptor_t,
        keys: *const ::core::ffi::c_void,
        vdesc: ffi::cudnnSeqDataDescriptor_t,
        values: *const ::core::ffi::c_void,
        dodesc: ffi::cudnnSeqDataDescriptor_t,
        dout: *const ::core::ffi::c_void,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        dweights: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if queries.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if keys.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if values.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if weights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dweights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dweights.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reservespace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnMultiHeadAttnBackwardWeights")
                    .entered();
            let result = ffi::cudnnMultiHeadAttnBackwardWeights(
                self.handle,
                attndesc,
                addgrad,
                qdesc,
                queries,
                kdesc,
                keys,
                vdesc,
                values,
                dodesc,
                dout,
                weightsizeinbytes,
                weights,
                dweights,
                workspacesizeinbytes,
                workspace,
                reservespacesizeinbytes,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn ctc_loss(
        &mut self,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        hostlabels: *const ::core::ffi::c_int,
        hostlabellengths: *const ::core::ffi::c_int,
        hostinputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if probs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if probs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hostlabels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hostlabels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hostlabellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hostlabellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hostinputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hostinputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if costs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if costs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if gradients.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if gradients.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnCTCLoss").entered();
            let result = ffi::cudnnCTCLoss(
                self.handle,
                probsdesc,
                probs,
                hostlabels,
                hostlabellengths,
                hostinputlengths,
                costs,
                gradientsdesc,
                gradients,
                algo,
                ctclossdesc,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn ctc_loss_v_8(
        &mut self,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if probs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if probs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if labels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if labels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if labellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if labellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if inputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if inputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if costs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if costs.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if gradients.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if gradients.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnCTCLoss_v8").entered();
            let result = ffi::cudnnCTCLoss_v8(
                self.handle,
                algo,
                ctclossdesc,
                probsdesc,
                probs,
                labels,
                labellengths,
                inputlengths,
                costs,
                gradientsdesc,
                gradients,
                workspacesizeinbytes,
                workspace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_workspace_size(
        &mut self,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if labels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if labels.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if labellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if labellengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if inputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if inputlengths.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossWorkspaceSize")
                .entered();
            let result = ffi::cudnnGetCTCLossWorkspaceSize(
                self.handle,
                probsdesc,
                gradientsdesc,
                labels,
                labellengths,
                inputlengths,
                algo,
                ctclossdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_ctc_loss_workspace_size_v_8(
        &mut self,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetCTCLossWorkspaceSize_v8")
                    .entered();
            let result = ffi::cudnnGetCTCLossWorkspaceSize_v8(
                self.handle,
                algo,
                ctclossdesc,
                probsdesc,
                gradientsdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_forward_algorithm_max_count(
        &mut self,
        count: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionForwardAlgorithmMaxCount"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionForwardAlgorithmMaxCount(self.handle, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_forward_algorithm_v_7(
        &mut self,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionForwardAlgorithm_v7"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionForwardAlgorithm_v7(
                self.handle,
                srcdesc,
                filterdesc,
                convdesc,
                destdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_forward_algorithm(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionForwardAlgorithm"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionForwardAlgorithm(
                self.handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_forward_algorithm_ex(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionForwardAlgorithmEx"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionForwardAlgorithmEx(
                self.handle,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                ydesc,
                y,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn im_2col(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        colbuffer: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if colbuffer.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if colbuffer.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnIm2Col").entered();
            let result = ffi::cudnnIm2Col(self.handle, xdesc, x, wdesc, convdesc, colbuffer);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn reorder_filter_and_bias(
        &mut self,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        reordertype: ffi::cudnnReorderType_t,
        filterdata: *const ::core::ffi::c_void,
        reorderedfilterdata: *mut ::core::ffi::c_void,
        reorderbias: ::core::ffi::c_int,
        biasdata: *const ::core::ffi::c_void,
        reorderedbiasdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if filterdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if filterdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reorderedfilterdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reorderedfilterdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if biasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if biasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if reorderedbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reorderedbiasdata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnReorderFilterAndBias").entered();
            let result = ffi::cudnnReorderFilterAndBias(
                self.handle,
                filterdesc,
                reordertype,
                filterdata,
                reorderedfilterdata,
                reorderbias,
                biasdata,
                reorderedbiasdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_forward_workspace_size(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionForwardWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionForwardWorkspaceSize(
                self.handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn convolution_forward(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnConvolutionForward").entered();
            let result = ffi::cudnnConvolutionForward(
                self.handle,
                alpha,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn convolution_bias_activation_forward(
        &mut self,
        alpha1: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha2: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        biasdesc: ffi::cudnnTensorDescriptor_t,
        bias: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha1.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha1.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if alpha2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha2.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if z.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if z.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if bias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if bias.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnConvolutionBiasActivationForward"
            )
            .entered();
            let result = ffi::cudnnConvolutionBiasActivationForward(
                self.handle,
                alpha1,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                alpha2,
                zdesc,
                z,
                biasdesc,
                bias,
                activationdesc,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_data_algorithm_max_count(
        &mut self,
        count: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardDataAlgorithmMaxCount"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionBackwardDataAlgorithmMaxCount(self.handle, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_backward_data_algorithm(
        &mut self,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionBackwardDataAlgorithm"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithm(
                self.handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_backward_data_algorithm_ex(
        &mut self,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionBackwardDataAlgorithmEx"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithmEx(
                self.handle,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                dxdesc,
                dx,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_data_algorithm_v_7(
        &mut self,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardDataAlgorithm_v7"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionBackwardDataAlgorithm_v7(
                self.handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_data_workspace_size(
        &mut self,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardDataWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionBackwardDataWorkspaceSize(
                self.handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn convolution_backward_data(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dx.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnConvolutionBackwardData")
                .entered();
            let result = ffi::cudnnConvolutionBackwardData(
                self.handle,
                alpha,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_folded_conv_backward_data_descriptors(
        &mut self,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        transformformat: ffi::cudnnTensorFormat_t,
        foldedfilterdesc: ffi::cudnnFilterDescriptor_t,
        paddeddiffdesc: ffi::cudnnTensorDescriptor_t,
        foldedconvdesc: ffi::cudnnConvolutionDescriptor_t,
        foldedgraddesc: ffi::cudnnTensorDescriptor_t,
        filterfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        diffpadtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradunfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetFoldedConvBackwardDataDescriptors"
            )
            .entered();
            let result = ffi::cudnnGetFoldedConvBackwardDataDescriptors(
                self.handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                transformformat,
                foldedfilterdesc,
                paddeddiffdesc,
                foldedconvdesc,
                foldedgraddesc,
                filterfoldtransdesc,
                diffpadtransdesc,
                gradfoldtransdesc,
                gradunfoldtransdesc,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_filter_algorithm_max_count(
        &mut self,
        count: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if count.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardFilterAlgorithmMaxCount"
            )
            .entered();
            let result =
                ffi::cudnnGetConvolutionBackwardFilterAlgorithmMaxCount(self.handle, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_backward_filter_algorithm(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionBackwardFilterAlgorithm"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithm(
                self.handle,
                xdesc,
                dydesc,
                convdesc,
                dwdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn find_convolution_backward_filter_algorithm_ex(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if y.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dw.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dw.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnFindConvolutionBackwardFilterAlgorithmEx"
            )
            .entered();
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithmEx(
                self.handle,
                xdesc,
                x,
                dydesc,
                y,
                convdesc,
                dwdesc,
                dw,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_filter_algorithm_v_7(
        &mut self,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if returnedalgocount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if perfresults.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardFilterAlgorithm_v7"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionBackwardFilterAlgorithm_v7(
                self.handle,
                srcdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_backward_filter_workspace_size(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionBackwardFilterWorkspaceSize"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionBackwardFilterWorkspaceSize(
                self.handle,
                xdesc,
                dydesc,
                convdesc,
                graddesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn convolution_backward_filter(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if x.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspace.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dw.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dw.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnConvolutionBackwardFilter")
                    .entered();
            let result = ffi::cudnnConvolutionBackwardFilter(
                self.handle,
                alpha,
                xdesc,
                x,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dwdesc,
                dw,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn convolution_backward_bias(
        &mut self,
        alpha: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dbdesc: ffi::cudnnTensorDescriptor_t,
        db: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if alpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dy.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if beta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if db.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if db.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnConvolutionBackwardBias")
                .entered();
            let result =
                ffi::cudnnConvolutionBackwardBias(self.handle, alpha, dydesc, dy, beta, dbdesc, db);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn make_fused_ops_plan(
        &mut self,
        plan: ffi::cudnnFusedOpsPlan_t,
        constpack: ffi::cudnnFusedOpsConstParamPack_t,
        workspacesizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if workspacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if workspacesizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnMakeFusedOpsPlan").entered();
            let result =
                ffi::cudnnMakeFusedOpsPlan(self.handle, plan, constpack, workspacesizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn fused_ops_execute(
        &mut self,
        plan: ffi::cudnnFusedOpsPlan_t,
        varpack: ffi::cudnnFusedOpsVariantParamPack_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnFusedOpsExecute").entered();
            let result = ffi::cudnnFusedOpsExecute(self.handle, plan, varpack);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnFilterDescriptor_t
impl CudnnFilterDescriptor {
    #[inline]
    pub fn set_filter_4d_descriptor(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        format: ffi::cudnnTensorFormat_t,
        k: ::core::ffi::c_int,
        c: ::core::ffi::c_int,
        h: ::core::ffi::c_int,
        w: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetFilter4dDescriptor").entered();
            let result = ffi::cudnnSetFilter4dDescriptor(self.handle, datatype, format, k, c, h, w);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_filter_4d_descriptor(
        &mut self,
        datatype: *mut ffi::cudnnDataType_t,
        format: *mut ffi::cudnnTensorFormat_t,
        k: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if format.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if format.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if k.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if k.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetFilter4dDescriptor").entered();
            let result = ffi::cudnnGetFilter4dDescriptor(self.handle, datatype, format, k, c, h, w);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_filter_nd_descriptor(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        format: ffi::cudnnTensorFormat_t,
        nbdims: ::core::ffi::c_int,
        filterdima: *const ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if filterdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if filterdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetFilterNdDescriptor").entered();
            let result =
                ffi::cudnnSetFilterNdDescriptor(self.handle, datatype, format, nbdims, filterdima);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_filter_nd_descriptor(
        &mut self,
        nbdimsrequested: ::core::ffi::c_int,
        datatype: *mut ffi::cudnnDataType_t,
        format: *mut ffi::cudnnTensorFormat_t,
        nbdims: *mut ::core::ffi::c_int,
        filterdima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if format.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if format.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if filterdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if filterdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetFilterNdDescriptor").entered();
            let result = ffi::cudnnGetFilterNdDescriptor(
                self.handle,
                nbdimsrequested,
                datatype,
                format,
                nbdims,
                filterdima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_filter_size_in_bytes(&mut self, size: *mut usize) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if size.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if size.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetFilterSizeInBytes").entered();
            let result = ffi::cudnnGetFilterSizeInBytes(self.handle, size);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn transform_filter(
        handle: ffi::cudnnHandle_t,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnFilterDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnFilterDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnTransformFilter(
                handle, transdesc, alpha, srcdesc, srcdata, beta, destdesc, destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_2d_forward_output_dim(
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolution2dForwardOutputDim(
                convdesc,
                inputtensordesc,
                filterdesc,
                n,
                c,
                h,
                w,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_nd_forward_output_dim(
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        nbdims: ::core::ffi::c_int,
        tensorouputdima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionNdForwardOutputDim(
                convdesc,
                inputtensordesc,
                filterdesc,
                nbdims,
                tensorouputdima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardAlgorithm_v7(
                handle,
                srcdesc,
                filterdesc,
                convdesc,
                destdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithm(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithmEx(
                handle,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                ydesc,
                y,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn im_2col(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        colbuffer: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnIm2Col(handle, xdesc, x, wdesc, convdesc, colbuffer);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn reorder_filter_and_bias(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        reordertype: ffi::cudnnReorderType_t,
        filterdata: *const ::core::ffi::c_void,
        reorderedfilterdata: *mut ::core::ffi::c_void,
        reorderbias: ::core::ffi::c_int,
        biasdata: *const ::core::ffi::c_void,
        reorderedbiasdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnReorderFilterAndBias(
                handle,
                filterdesc,
                reordertype,
                filterdata,
                reorderedfilterdata,
                reorderbias,
                biasdata,
                reorderedbiasdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardWorkspaceSize(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_forward(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionForward(
                handle,
                alpha,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_bias_activation_forward(
        handle: ffi::cudnnHandle_t,
        alpha1: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha2: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        biasdesc: ffi::cudnnTensorDescriptor_t,
        bias: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBiasActivationForward(
                handle,
                alpha1,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                alpha2,
                zdesc,
                z,
                biasdesc,
                bias,
                activationdesc,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithm(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithmEx(
                handle,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                dxdesc,
                dx,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataAlgorithm_v7(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_workspace_size(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataWorkspaceSize(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_data(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardData(
                handle,
                alpha,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_folded_conv_backward_data_descriptors(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        transformformat: ffi::cudnnTensorFormat_t,
        foldedfilterdesc: ffi::cudnnFilterDescriptor_t,
        paddeddiffdesc: ffi::cudnnTensorDescriptor_t,
        foldedconvdesc: ffi::cudnnConvolutionDescriptor_t,
        foldedgraddesc: ffi::cudnnTensorDescriptor_t,
        filterfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        diffpadtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradunfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetFoldedConvBackwardDataDescriptors(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                transformformat,
                foldedfilterdesc,
                paddeddiffdesc,
                foldedconvdesc,
                foldedgraddesc,
                filterfoldtransdesc,
                diffpadtransdesc,
                gradfoldtransdesc,
                gradunfoldtransdesc,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithm(
                handle,
                xdesc,
                dydesc,
                convdesc,
                dwdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithmEx(
                handle,
                xdesc,
                x,
                dydesc,
                y,
                convdesc,
                dwdesc,
                dw,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterAlgorithm_v7(
                handle,
                srcdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterWorkspaceSize(
                handle,
                xdesc,
                dydesc,
                convdesc,
                graddesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_filter(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardFilter(
                handle,
                alpha,
                xdesc,
                x,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dwdesc,
                dw,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaMemPool_t
impl CudaMemPool {
    pub fn device_set_mem_pool(
        device: ::core::ffi::c_int,
        mempool: ffi::cudaMemPool_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaDeviceSetMemPool(device, mempool);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn mem_pool_trim_to(&mut self, minbytestokeep: usize) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaMemPoolTrimTo").entered();
            let result = ffi::cudaMemPoolTrimTo(self.handle, minbytestokeep);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn mem_pool_set_attribute(
        &mut self,
        attr: ffi::cudaMemPoolAttr,
        value: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemPoolSetAttribute").entered();
            let result = ffi::cudaMemPoolSetAttribute(self.handle, attr, value);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn mem_pool_get_attribute(
        &mut self,
        attr: ffi::cudaMemPoolAttr,
        value: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemPoolGetAttribute").entered();
            let result = ffi::cudaMemPoolGetAttribute(self.handle, attr, value);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn mem_pool_set_access(
        &mut self,
        desclist: *const ffi::cudaMemAccessDesc,
        count: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if desclist.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if desclist.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemPoolSetAccess").entered();
            let result = ffi::cudaMemPoolSetAccess(self.handle, desclist, count);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_pool_get_access(
        flags: *mut ffi::cudaMemAccessFlags,
        mempool: ffi::cudaMemPool_t,
        location: *mut ffi::cudaMemLocation,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemPoolGetAccess(flags, mempool, location);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_set_mem_pool(
        location: *mut ffi::cudaMemLocation,
        type_: ffi::cudaMemAllocationType,
        mempool: ffi::cudaMemPool_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemSetMemPool(location, type_, mempool);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn malloc_from_pool_async(
        ptr: *mut *mut ::core::ffi::c_void,
        size: usize,
        mempool: ffi::cudaMemPool_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMallocFromPoolAsync(ptr, size, mempool, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_pool_export_to_shareable_handle(
        shareablehandle: *mut ::core::ffi::c_void,
        mempool: ffi::cudaMemPool_t,
        handletype: ffi::cudaMemAllocationHandleType,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemPoolExportToShareableHandle(
                shareablehandle,
                mempool,
                handletype,
                flags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn mem_pool_import_pointer(
        ptr: *mut *mut ::core::ffi::c_void,
        mempool: ffi::cudaMemPool_t,
        exportdata: *mut ffi::cudaMemPoolPtrExportData,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaMemPoolImportPointer(ptr, mempool, exportdata);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnConvolutionDescriptor_t
impl CudnnConvolutionDescriptor {
    #[inline]
    pub fn set_convolution_math_type(
        &mut self,
        mathtype: ffi::cudnnMathType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetConvolutionMathType")
                .entered();
            let result = ffi::cudnnSetConvolutionMathType(self.handle, mathtype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_math_type(
        &mut self,
        mathtype: *mut ffi::cudnnMathType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mathtype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnGetConvolutionMathType")
                .entered();
            let result = ffi::cudnnGetConvolutionMathType(self.handle, mathtype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_convolution_group_count(
        &mut self,
        groupcount: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetConvolutionGroupCount")
                    .entered();
            let result = ffi::cudnnSetConvolutionGroupCount(self.handle, groupcount);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_group_count(
        &mut self,
        groupcount: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if groupcount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if groupcount.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetConvolutionGroupCount")
                    .entered();
            let result = ffi::cudnnGetConvolutionGroupCount(self.handle, groupcount);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_convolution_reorder_type(
        &mut self,
        reordertype: ffi::cudnnReorderType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetConvolutionReorderType")
                    .entered();
            let result = ffi::cudnnSetConvolutionReorderType(self.handle, reordertype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_reorder_type(
        &mut self,
        reordertype: *mut ffi::cudnnReorderType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if reordertype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if reordertype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetConvolutionReorderType")
                    .entered();
            let result = ffi::cudnnGetConvolutionReorderType(self.handle, reordertype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_convolution_2d_descriptor(
        &mut self,
        pad_h: ::core::ffi::c_int,
        pad_w: ::core::ffi::c_int,
        u: ::core::ffi::c_int,
        v: ::core::ffi::c_int,
        dilation_h: ::core::ffi::c_int,
        dilation_w: ::core::ffi::c_int,
        mode: ffi::cudnnConvolutionMode_t,
        computetype: ffi::cudnnDataType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetConvolution2dDescriptor")
                    .entered();
            let result = ffi::cudnnSetConvolution2dDescriptor(
                self.handle,
                pad_h,
                pad_w,
                u,
                v,
                dilation_h,
                dilation_w,
                mode,
                computetype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_2d_descriptor(
        &mut self,
        pad_h: *mut ::core::ffi::c_int,
        pad_w: *mut ::core::ffi::c_int,
        u: *mut ::core::ffi::c_int,
        v: *mut ::core::ffi::c_int,
        dilation_h: *mut ::core::ffi::c_int,
        dilation_w: *mut ::core::ffi::c_int,
        mode: *mut ffi::cudnnConvolutionMode_t,
        computetype: *mut ffi::cudnnDataType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pad_h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pad_h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if pad_w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pad_w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if u.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if u.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if v.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if v.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dilation_h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dilation_h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dilation_w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dilation_w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if computetype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if computetype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetConvolution2dDescriptor")
                    .entered();
            let result = ffi::cudnnGetConvolution2dDescriptor(
                self.handle,
                pad_h,
                pad_w,
                u,
                v,
                dilation_h,
                dilation_w,
                mode,
                computetype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_convolution_nd_descriptor(
        &mut self,
        arraylength: ::core::ffi::c_int,
        pada: *const ::core::ffi::c_int,
        filterstridea: *const ::core::ffi::c_int,
        dilationa: *const ::core::ffi::c_int,
        mode: ffi::cudnnConvolutionMode_t,
        computetype: ffi::cudnnDataType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pada.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pada.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if filterstridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if filterstridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dilationa.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dilationa.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetConvolutionNdDescriptor")
                    .entered();
            let result = ffi::cudnnSetConvolutionNdDescriptor(
                self.handle,
                arraylength,
                pada,
                filterstridea,
                dilationa,
                mode,
                computetype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_nd_descriptor(
        &mut self,
        arraylengthrequested: ::core::ffi::c_int,
        arraylength: *mut ::core::ffi::c_int,
        pada: *mut ::core::ffi::c_int,
        stridea: *mut ::core::ffi::c_int,
        dilationa: *mut ::core::ffi::c_int,
        mode: *mut ffi::cudnnConvolutionMode_t,
        computetype: *mut ffi::cudnnDataType_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if arraylength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if arraylength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if pada.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pada.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dilationa.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dilationa.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if mode.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if computetype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if computetype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetConvolutionNdDescriptor")
                    .entered();
            let result = ffi::cudnnGetConvolutionNdDescriptor(
                self.handle,
                arraylengthrequested,
                arraylength,
                pada,
                stridea,
                dilationa,
                mode,
                computetype,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_2d_forward_output_dim(
        &mut self,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolution2dForwardOutputDim"
            )
            .entered();
            let result = ffi::cudnnGetConvolution2dForwardOutputDim(
                self.handle,
                inputtensordesc,
                filterdesc,
                n,
                c,
                h,
                w,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_convolution_nd_forward_output_dim(
        &mut self,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        nbdims: ::core::ffi::c_int,
        tensorouputdima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if tensorouputdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if tensorouputdima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetConvolutionNdForwardOutputDim"
            )
            .entered();
            let result = ffi::cudnnGetConvolutionNdForwardOutputDim(
                self.handle,
                inputtensordesc,
                filterdesc,
                nbdims,
                tensorouputdima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardAlgorithm_v7(
                handle,
                srcdesc,
                filterdesc,
                convdesc,
                destdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithm(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithmEx(
                handle,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                ydesc,
                y,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn im_2col(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        colbuffer: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnIm2Col(handle, xdesc, x, wdesc, convdesc, colbuffer);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardWorkspaceSize(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_forward(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionForward(
                handle,
                alpha,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_bias_activation_forward(
        handle: ffi::cudnnHandle_t,
        alpha1: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha2: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        biasdesc: ffi::cudnnTensorDescriptor_t,
        bias: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBiasActivationForward(
                handle,
                alpha1,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                alpha2,
                zdesc,
                z,
                biasdesc,
                bias,
                activationdesc,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithm(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithmEx(
                handle,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                dxdesc,
                dx,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataAlgorithm_v7(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_workspace_size(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataWorkspaceSize(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_data(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardData(
                handle,
                alpha,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_folded_conv_backward_data_descriptors(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        transformformat: ffi::cudnnTensorFormat_t,
        foldedfilterdesc: ffi::cudnnFilterDescriptor_t,
        paddeddiffdesc: ffi::cudnnTensorDescriptor_t,
        foldedconvdesc: ffi::cudnnConvolutionDescriptor_t,
        foldedgraddesc: ffi::cudnnTensorDescriptor_t,
        filterfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        diffpadtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradunfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetFoldedConvBackwardDataDescriptors(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                transformformat,
                foldedfilterdesc,
                paddeddiffdesc,
                foldedconvdesc,
                foldedgraddesc,
                filterfoldtransdesc,
                diffpadtransdesc,
                gradfoldtransdesc,
                gradunfoldtransdesc,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithm(
                handle,
                xdesc,
                dydesc,
                convdesc,
                dwdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithmEx(
                handle,
                xdesc,
                x,
                dydesc,
                y,
                convdesc,
                dwdesc,
                dw,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterAlgorithm_v7(
                handle,
                srcdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterWorkspaceSize(
                handle,
                xdesc,
                dydesc,
                convdesc,
                graddesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_filter(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardFilter(
                handle,
                alpha,
                xdesc,
                x,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dwdesc,
                dw,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaGraphicsResource_t
impl CudaGraphicsResource {
    #[inline]
    pub fn graphics_unregister_resource(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphicsUnregisterResource")
                    .entered();
            let result = ffi::cudaGraphicsUnregisterResource(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graphics_resource_set_map_flags(
        &mut self,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphicsResourceSetMapFlags")
                    .entered();
            let result = ffi::cudaGraphicsResourceSetMapFlags(self.handle, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_map_resources(
        count: ::core::ffi::c_int,
        resources: *mut ffi::cudaGraphicsResource_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsMapResources(count, resources, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_unmap_resources(
        count: ::core::ffi::c_int,
        resources: *mut ffi::cudaGraphicsResource_t,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsUnmapResources(count, resources, stream);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_resource_get_mapped_pointer(
        devptr: *mut *mut ::core::ffi::c_void,
        size: *mut usize,
        resource: ffi::cudaGraphicsResource_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsResourceGetMappedPointer(devptr, size, resource);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_sub_resource_get_mapped_array(
        array: *mut ffi::cudaArray_t,
        resource: ffi::cudaGraphicsResource_t,
        arrayindex: ::core::ffi::c_uint,
        miplevel: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaGraphicsSubResourceGetMappedArray(array, resource, arrayindex, miplevel);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graphics_resource_get_mapped_mipmapped_array(
        mipmappedarray: *mut ffi::cudaMipmappedArray_t,
        resource: ffi::cudaGraphicsResource_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphicsResourceGetMappedMipmappedArray(mipmappedarray, resource);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaArray_t
impl CudaArray {
    pub fn array_get_info(
        desc: *mut ffi::cudaChannelFormatDesc,
        extent: *mut ffi::cudaExtent,
        flags: *mut ::core::ffi::c_uint,
        array: ffi::cudaArray_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaArrayGetInfo(desc, extent, flags, array);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn array_get_memory_requirements(
        memoryrequirements: *mut ffi::cudaArrayMemoryRequirements,
        array: ffi::cudaArray_t,
        device: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaArrayGetMemoryRequirements(memoryrequirements, array, device);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn array_get_sparse_properties(
        sparseproperties: *mut ffi::cudaArraySparseProperties,
        array: ffi::cudaArray_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaArrayGetSparseProperties(sparseproperties, array);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_2d_to_array(
        &mut self,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        spitch: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemcpy2DToArray").entered();
            let result = ffi::cudaMemcpy2DToArray(
                self.handle,
                woffset,
                hoffset,
                src,
                spitch,
                width,
                height,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_2d_array_to_array(
        &mut self,
        woffsetdst: usize,
        hoffsetdst: usize,
        src: ffi::cudaArray_const_t,
        woffsetsrc: usize,
        hoffsetsrc: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemcpy2DArrayToArray").entered();
            let result = ffi::cudaMemcpy2DArrayToArray(
                self.handle,
                woffsetdst,
                hoffsetdst,
                src,
                woffsetsrc,
                hoffsetsrc,
                width,
                height,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_2d_to_array_async(
        &mut self,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        spitch: usize,
        width: usize,
        height: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemcpy2DToArrayAsync").entered();
            let result = ffi::cudaMemcpy2DToArrayAsync(
                self.handle,
                woffset,
                hoffset,
                src,
                spitch,
                width,
                height,
                kind,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_to_array(
        &mut self,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaMemcpyToArray").entered();
            let result = ffi::cudaMemcpyToArray(self.handle, woffset, hoffset, src, count, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_array_to_array(
        &mut self,
        woffsetdst: usize,
        hoffsetdst: usize,
        src: ffi::cudaArray_const_t,
        woffsetsrc: usize,
        hoffsetsrc: usize,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemcpyArrayToArray").entered();
            let result = ffi::cudaMemcpyArrayToArray(
                self.handle,
                woffsetdst,
                hoffsetdst,
                src,
                woffsetsrc,
                hoffsetsrc,
                count,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn memcpy_to_array_async(
        &mut self,
        woffset: usize,
        hoffset: usize,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
        stream: ffi::cudaStream_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaMemcpyToArrayAsync").entered();
            let result = ffi::cudaMemcpyToArrayAsync(
                self.handle,
                woffset,
                hoffset,
                src,
                count,
                kind,
                stream,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnFusedOpsVariantParamPack_t
impl CudnnFusedOpsVariantParamPack {
    #[inline]
    pub fn set_fused_ops_variant_param_pack_attribute(
        &mut self,
        paramlabel: ffi::cudnnFusedOpsVariantParamLabel_t,
        ptr: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if ptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnSetFusedOpsVariantParamPackAttribute"
            )
            .entered();
            let result =
                ffi::cudnnSetFusedOpsVariantParamPackAttribute(self.handle, paramlabel, ptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_fused_ops_variant_param_pack_attribute(
        &mut self,
        paramlabel: ffi::cudnnFusedOpsVariantParamLabel_t,
        ptr: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if ptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ptr.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudnnGetFusedOpsVariantParamPackAttribute"
            )
            .entered();
            let result =
                ffi::cudnnGetFusedOpsVariantParamPackAttribute(self.handle, paramlabel, ptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn fused_ops_execute(
        handle: ffi::cudnnHandle_t,
        plan: ffi::cudnnFusedOpsPlan_t,
        varpack: ffi::cudnnFusedOpsVariantParamPack_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFusedOpsExecute(handle, plan, varpack);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnLRNDescriptor_t
impl CudnnLRNDescriptor {
    #[inline]
    pub fn set_lrn_descriptor(
        &mut self,
        lrnn: ::core::ffi::c_uint,
        lrnalpha: f64,
        lrnbeta: f64,
        lrnk: f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetLRNDescriptor").entered();
            let result = ffi::cudnnSetLRNDescriptor(self.handle, lrnn, lrnalpha, lrnbeta, lrnk);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_lrn_descriptor(
        &mut self,
        lrnn: *mut ::core::ffi::c_uint,
        lrnalpha: *mut f64,
        lrnbeta: *mut f64,
        lrnk: *mut f64,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if lrnn.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lrnn.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if lrnalpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lrnalpha.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if lrnbeta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lrnbeta.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if lrnk.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if lrnk.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetLRNDescriptor").entered();
            let result = ffi::cudnnGetLRNDescriptor(self.handle, lrnn, lrnalpha, lrnbeta, lrnk);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn lrn_cross_channel_forward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnLRNCrossChannelForward(
                handle, normdesc, lrnmode, alpha, xdesc, x, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn divisive_normalization_forward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDivisiveNormalizationForward(
                handle, normdesc, mode, alpha, xdesc, x, means, temp, temp2, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn lrn_cross_channel_backward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnLRNCrossChannelBackward(
                handle, normdesc, lrnmode, alpha, ydesc, y, dydesc, dy, xdesc, x, beta, dxdesc, dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn divisive_normalization_backward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdmeansdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        dmeans: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDivisiveNormalizationBackward(
                handle,
                normdesc,
                mode,
                alpha,
                xdesc,
                x,
                means,
                dy,
                temp,
                temp2,
                beta,
                dxdmeansdesc,
                dx,
                dmeans,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnRNNDataDescriptor_t
impl CudnnRNNDataDescriptor {
    pub fn get_rnn_temp_space_sizes(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        workspacesize: *mut usize,
        reservespacesize: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNTempSpaceSizes(
                handle,
                rnndesc,
                fwdmode,
                xdesc,
                workspacesize,
                reservespacesize,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_rnn_data_descriptor(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        layout: ffi::cudnnRNNDataLayout_t,
        maxseqlength: ::core::ffi::c_int,
        batchsize: ::core::ffi::c_int,
        vectorsize: ::core::ffi::c_int,
        seqlengtharray: *const ::core::ffi::c_int,
        paddingfill: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetRNNDataDescriptor").entered();
            let result = ffi::cudnnSetRNNDataDescriptor(
                self.handle,
                datatype,
                layout,
                maxseqlength,
                batchsize,
                vectorsize,
                seqlengtharray,
                paddingfill,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_rnn_data_descriptor(
        &mut self,
        datatype: *mut ffi::cudnnDataType_t,
        layout: *mut ffi::cudnnRNNDataLayout_t,
        maxseqlength: *mut ::core::ffi::c_int,
        batchsize: *mut ::core::ffi::c_int,
        vectorsize: *mut ::core::ffi::c_int,
        arraylengthrequested: ::core::ffi::c_int,
        seqlengtharray: *mut ::core::ffi::c_int,
        paddingfill: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if layout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if layout.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if maxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if maxseqlength.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if batchsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if batchsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if vectorsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if vectorsize.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if seqlengtharray.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if paddingfill.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetRNNDataDescriptor").entered();
            let result = ffi::cudnnGetRNNDataDescriptor(
                self.handle,
                datatype,
                layout,
                maxseqlength,
                batchsize,
                vectorsize,
                arraylengthrequested,
                seqlengtharray,
                paddingfill,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_forward(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        hy: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        cy: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNForward(
                handle,
                rnndesc,
                fwdmode,
                devseqlengths,
                xdesc,
                x,
                ydesc,
                y,
                hdesc,
                hx,
                hy,
                cdesc,
                cx,
                cy,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_data_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        devseqlengths: *const i32,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        dhy: *const ::core::ffi::c_void,
        dhx: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        dcy: *const ::core::ffi::c_void,
        dcx: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardData_v8(
                handle,
                rnndesc,
                devseqlengths,
                ydesc,
                y,
                dy,
                xdesc,
                dx,
                hdesc,
                hx,
                dhy,
                dhx,
                cdesc,
                cx,
                dcy,
                dcx,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_weights_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        weightspacesize: usize,
        dweightspace: *mut ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardWeights_v8(
                handle,
                rnndesc,
                addgrad,
                devseqlengths,
                xdesc,
                x,
                hdesc,
                hx,
                ydesc,
                y,
                weightspacesize,
                dweightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudnnTensorDescriptor_t
impl CudnnTensorDescriptor {
    #[inline]
    pub fn set_tensor_4d_descriptor(
        &mut self,
        format: ffi::cudnnTensorFormat_t,
        datatype: ffi::cudnnDataType_t,
        n: ::core::ffi::c_int,
        c: ::core::ffi::c_int,
        h: ::core::ffi::c_int,
        w: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetTensor4dDescriptor").entered();
            let result = ffi::cudnnSetTensor4dDescriptor(self.handle, format, datatype, n, c, h, w);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_tensor_4d_descriptor_ex(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        n: ::core::ffi::c_int,
        c: ::core::ffi::c_int,
        h: ::core::ffi::c_int,
        w: ::core::ffi::c_int,
        nstride: ::core::ffi::c_int,
        cstride: ::core::ffi::c_int,
        hstride: ::core::ffi::c_int,
        wstride: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetTensor4dDescriptorEx")
                .entered();
            let result = ffi::cudnnSetTensor4dDescriptorEx(
                self.handle,
                datatype,
                n,
                c,
                h,
                w,
                nstride,
                cstride,
                hstride,
                wstride,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_tensor_4d_descriptor(
        &mut self,
        datatype: *mut ffi::cudnnDataType_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
        nstride: *mut ::core::ffi::c_int,
        cstride: *mut ::core::ffi::c_int,
        hstride: *mut ::core::ffi::c_int,
        wstride: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if n.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if c.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if h.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if w.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if cstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if cstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if hstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if hstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if wstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if wstride.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetTensor4dDescriptor").entered();
            let result = ffi::cudnnGetTensor4dDescriptor(
                self.handle,
                datatype,
                n,
                c,
                h,
                w,
                nstride,
                cstride,
                hstride,
                wstride,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_tensor_nd_descriptor(
        &mut self,
        datatype: ffi::cudnnDataType_t,
        nbdims: ::core::ffi::c_int,
        dima: *const ::core::ffi::c_int,
        stridea: *const ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnSetTensorNdDescriptor").entered();
            let result =
                ffi::cudnnSetTensorNdDescriptor(self.handle, datatype, nbdims, dima, stridea);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn set_tensor_nd_descriptor_ex(
        &mut self,
        format: ffi::cudnnTensorFormat_t,
        datatype: ffi::cudnnDataType_t,
        nbdims: ::core::ffi::c_int,
        dima: *const ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudnnSetTensorNdDescriptorEx")
                .entered();
            let result =
                ffi::cudnnSetTensorNdDescriptorEx(self.handle, format, datatype, nbdims, dima);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_tensor_nd_descriptor(
        &mut self,
        nbdimsrequested: ::core::ffi::c_int,
        datatype: *mut ffi::cudnnDataType_t,
        nbdims: *mut ::core::ffi::c_int,
        dima: *mut ::core::ffi::c_int,
        stridea: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if datatype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nbdims.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dima.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if stridea.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetTensorNdDescriptor").entered();
            let result = ffi::cudnnGetTensorNdDescriptor(
                self.handle,
                nbdimsrequested,
                datatype,
                nbdims,
                dima,
                stridea,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn get_tensor_size_in_bytes(&mut self, size: *mut usize) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if size.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if size.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnGetTensorSizeInBytes").entered();
            let result = ffi::cudnnGetTensorSizeInBytes(self.handle, size);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn init_transform_dest(
        transformdesc: ffi::cudnnTensorTransformDescriptor_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        destsizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnInitTransformDest(transformdesc, srcdesc, destdesc, destsizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn transform_tensor(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnTransformTensor(handle, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn transform_tensor_ex(
        handle: ffi::cudnnHandle_t,
        transdesc: ffi::cudnnTensorTransformDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        srcdata: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        destdesc: ffi::cudnnTensorDescriptor_t,
        destdata: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnTransformTensorEx(
                handle, transdesc, alpha, srcdesc, srcdata, beta, destdesc, destdata,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn add_tensor(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnAddTensor(handle, alpha, adesc, a, beta, cdesc, c);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn op_tensor(
        handle: ffi::cudnnHandle_t,
        optensordesc: ffi::cudnnOpTensorDescriptor_t,
        alpha1: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        alpha2: *const ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        b: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnOpTensor(
                handle,
                optensordesc,
                alpha1,
                adesc,
                a,
                alpha2,
                bdesc,
                b,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_reduction_indices_size(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetReductionIndicesSize(
                handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_reduction_workspace_size(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        adesc: ffi::cudnnTensorDescriptor_t,
        cdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetReductionWorkspaceSize(
                handle,
                reducetensordesc,
                adesc,
                cdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn reduce_tensor(
        handle: ffi::cudnnHandle_t,
        reducetensordesc: ffi::cudnnReduceTensorDescriptor_t,
        indices: *mut ::core::ffi::c_void,
        indicessizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha: *const ::core::ffi::c_void,
        adesc: ffi::cudnnTensorDescriptor_t,
        a: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        c: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnReduceTensor(
                handle,
                reducetensordesc,
                indices,
                indicessizeinbytes,
                workspace,
                workspacesizeinbytes,
                alpha,
                adesc,
                a,
                beta,
                cdesc,
                c,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn set_tensor(
        handle: ffi::cudnnHandle_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        valueptr: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSetTensor(handle, ydesc, y, valueptr);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn scale_tensor(
        handle: ffi::cudnnHandle_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        alpha: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnScaleTensor(handle, ydesc, y, alpha);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn softmax_forward(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnSoftmaxAlgorithm_t,
        mode: ffi::cudnnSoftmaxMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnSoftmaxForward(handle, algo, mode, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_pooling_nd_forward_output_dim(
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        nbdims: ::core::ffi::c_int,
        outputtensordima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetPoolingNdForwardOutputDim(
                poolingdesc,
                inputtensordesc,
                nbdims,
                outputtensordima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_pooling_2d_forward_output_dim(
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnGetPooling2dForwardOutputDim(poolingdesc, inputtensordesc, n, c, h, w);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn pooling_forward(
        handle: ffi::cudnnHandle_t,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnPoolingForward(handle, poolingdesc, alpha, xdesc, x, beta, ydesc, y);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn activation_forward(
        handle: ffi::cudnnHandle_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnActivationForward(
                handle,
                activationdesc,
                alpha,
                xdesc,
                x,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn lrn_cross_channel_forward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnLRNCrossChannelForward(
                handle, normdesc, lrnmode, alpha, xdesc, x, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn divisive_normalization_forward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDivisiveNormalizationForward(
                handle, normdesc, mode, alpha, xdesc, x, means, temp, temp2, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn derive_bn_tensor_descriptor(
        &mut self,
        xdesc: ffi::cudnnTensorDescriptor_t,
        mode: ffi::cudnnBatchNormMode_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDeriveBNTensorDescriptor")
                    .entered();
            let result = ffi::cudnnDeriveBNTensorDescriptor(self.handle, xdesc, mode);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_forward_inference(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        estimatedmean: *const ::core::ffi::c_void,
        estimatedvariance: *const ::core::ffi::c_void,
        epsilon: f64,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationForwardInference(
                handle,
                mode,
                alpha,
                beta,
                xdesc,
                x,
                ydesc,
                y,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                estimatedmean,
                estimatedvariance,
                epsilon,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn derive_norm_tensor_descriptor(
        &mut self,
        derivednormmeanvardesc: ffi::cudnnTensorDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        mode: ffi::cudnnNormMode_t,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDeriveNormTensorDescriptor")
                    .entered();
            let result = ffi::cudnnDeriveNormTensorDescriptor(
                self.handle,
                derivednormmeanvardesc,
                xdesc,
                mode,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_forward_inference(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        estimatedmean: *const ::core::ffi::c_void,
        estimatedvariance: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        epsilon: f64,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationForwardInference(
                handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                x,
                normscalebiasdesc,
                normscale,
                normbias,
                normmeanvardesc,
                estimatedmean,
                estimatedvariance,
                zdesc,
                z,
                activationdesc,
                ydesc,
                y,
                epsilon,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_sampler_forward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfSamplerForward(
                handle, stdesc, alpha, xdesc, x, grid, beta, ydesc, y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn dropout_get_reserve_space_size(&mut self, sizeinbytes: *mut usize) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if sizeinbytes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudnnDropoutGetReserveSpaceSize")
                    .entered();
            let result = ffi::cudnnDropoutGetReserveSpaceSize(self.handle, sizeinbytes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn dropout_forward(
        handle: ffi::cudnnHandle_t,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDropoutForward(
                handle,
                dropoutdesc,
                xdesc,
                x,
                ydesc,
                y,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn softmax_backward(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnSoftmaxAlgorithm_t,
        mode: ffi::cudnnSoftmaxMode_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSoftmaxBackward(
                handle, algo, mode, alpha, ydesc, y, dydesc, dy, beta, dxdesc, dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn pooling_backward(
        handle: ffi::cudnnHandle_t,
        poolingdesc: ffi::cudnnPoolingDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnPoolingBackward(
                handle,
                poolingdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn activation_backward(
        handle: ffi::cudnnHandle_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnActivationBackward(
                handle,
                activationdesc,
                alpha,
                ydesc,
                y,
                dydesc,
                dy,
                xdesc,
                x,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn lrn_cross_channel_backward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        lrnmode: ffi::cudnnLRNMode_t,
        alpha: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnLRNCrossChannelBackward(
                handle, normdesc, lrnmode, alpha, ydesc, y, dydesc, dy, xdesc, x, beta, dxdesc, dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn divisive_normalization_backward(
        handle: ffi::cudnnHandle_t,
        normdesc: ffi::cudnnLRNDescriptor_t,
        mode: ffi::cudnnDivNormMode_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        means: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        temp: *mut ::core::ffi::c_void,
        temp2: *mut ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdmeansdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        dmeans: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDivisiveNormalizationBackward(
                handle,
                normdesc,
                mode,
                alpha,
                xdesc,
                x,
                means,
                dy,
                temp,
                temp2,
                beta,
                dxdmeansdesc,
                dx,
                dmeans,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_forward_training_ex_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationForwardTrainingExWorkspaceSize(
                handle,
                mode,
                bnops,
                xdesc,
                zdesc,
                ydesc,
                bnscalebiasmeanvardesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_backward_ex_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationBackwardExWorkspaceSize(
                handle,
                mode,
                bnops,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dbnscalebiasdesc,
                activationdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_batch_normalization_training_ex_reserve_space_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetBatchNormalizationTrainingExReserveSpaceSize(
                handle,
                mode,
                bnops,
                activationdesc,
                xdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_forward_training(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationForwardTraining(
                handle,
                mode,
                alpha,
                beta,
                xdesc,
                x,
                ydesc,
                y,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                exponentialaveragefactor,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_forward_training_ex(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        bnscalebiasmeanvardesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        bnbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationForwardTrainingEx(
                handle,
                mode,
                bnops,
                alpha,
                beta,
                xdesc,
                xdata,
                zdesc,
                zdata,
                ydesc,
                ydata,
                bnscalebiasmeanvardesc,
                bnscale,
                bnbias,
                exponentialaveragefactor,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_backward(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        bnscale: *const ::core::ffi::c_void,
        dbnscaleresult: *mut ::core::ffi::c_void,
        dbnbiasresult: *mut ::core::ffi::c_void,
        epsilon: f64,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationBackward(
                handle,
                mode,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                x,
                dydesc,
                dy,
                dxdesc,
                dx,
                dbnscalebiasdesc,
                bnscale,
                dbnscaleresult,
                dbnbiasresult,
                epsilon,
                savedmean,
                savedinvvariance,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn batch_normalization_backward_ex(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnBatchNormMode_t,
        bnops: ffi::cudnnBatchNormOps_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dbnscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        bnscaledata: *const ::core::ffi::c_void,
        bnbiasdata: *const ::core::ffi::c_void,
        dbnscaledata: *mut ::core::ffi::c_void,
        dbnbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnBatchNormalizationBackwardEx(
                handle,
                mode,
                bnops,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dbnscalebiasdesc,
                bnscaledata,
                bnbiasdata,
                dbnscaledata,
                dbnbiasdata,
                epsilon,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_forward_training_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationForwardTrainingWorkspaceSize(
                handle,
                mode,
                normops,
                algo,
                xdesc,
                zdesc,
                ydesc,
                normscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_backward_workspace_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationBackwardWorkspaceSize(
                handle,
                mode,
                normops,
                algo,
                xdesc,
                ydesc,
                dydesc,
                dzdesc,
                dxdesc,
                dnormscalebiasdesc,
                activationdesc,
                normmeanvardesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_normalization_training_reserve_space_size(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetNormalizationTrainingReserveSpaceSize(
                handle,
                mode,
                normops,
                algo,
                activationdesc,
                xdesc,
                sizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_forward_training(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alpha: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        normscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscale: *const ::core::ffi::c_void,
        normbias: *const ::core::ffi::c_void,
        exponentialaveragefactor: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        resultrunningmean: *mut ::core::ffi::c_void,
        resultrunningvariance: *mut ::core::ffi::c_void,
        epsilon: f64,
        resultsavemean: *mut ::core::ffi::c_void,
        resultsaveinvvariance: *mut ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        zdesc: ffi::cudnnTensorDescriptor_t,
        zdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *mut ::core::ffi::c_void,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationForwardTraining(
                handle,
                mode,
                normops,
                algo,
                alpha,
                beta,
                xdesc,
                xdata,
                normscalebiasdesc,
                normscale,
                normbias,
                exponentialaveragefactor,
                normmeanvardesc,
                resultrunningmean,
                resultrunningvariance,
                epsilon,
                resultsavemean,
                resultsaveinvvariance,
                activationdesc,
                zdesc,
                zdata,
                ydesc,
                ydata,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn normalization_backward(
        handle: ffi::cudnnHandle_t,
        mode: ffi::cudnnNormMode_t,
        normops: ffi::cudnnNormOps_t,
        algo: ffi::cudnnNormAlgo_t,
        alphadatadiff: *const ::core::ffi::c_void,
        betadatadiff: *const ::core::ffi::c_void,
        alphaparamdiff: *const ::core::ffi::c_void,
        betaparamdiff: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        xdata: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        ydata: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dydata: *const ::core::ffi::c_void,
        dzdesc: ffi::cudnnTensorDescriptor_t,
        dzdata: *mut ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dxdata: *mut ::core::ffi::c_void,
        dnormscalebiasdesc: ffi::cudnnTensorDescriptor_t,
        normscaledata: *const ::core::ffi::c_void,
        normbiasdata: *const ::core::ffi::c_void,
        dnormscaledata: *mut ::core::ffi::c_void,
        dnormbiasdata: *mut ::core::ffi::c_void,
        epsilon: f64,
        normmeanvardesc: ffi::cudnnTensorDescriptor_t,
        savedmean: *const ::core::ffi::c_void,
        savedinvvariance: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
        groupcnt: ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnNormalizationBackward(
                handle,
                mode,
                normops,
                algo,
                alphadatadiff,
                betadatadiff,
                alphaparamdiff,
                betaparamdiff,
                xdesc,
                xdata,
                ydesc,
                ydata,
                dydesc,
                dydata,
                dzdesc,
                dzdata,
                dxdesc,
                dxdata,
                dnormscalebiasdesc,
                normscaledata,
                normbiasdata,
                dnormscaledata,
                dnormbiasdata,
                epsilon,
                normmeanvardesc,
                savedmean,
                savedinvvariance,
                activationdesc,
                workspace,
                workspacesizeinbytes,
                reservespace,
                reservespacesizeinbytes,
                groupcnt,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn spatial_tf_sampler_backward(
        handle: ffi::cudnnHandle_t,
        stdesc: ffi::cudnnSpatialTransformerDescriptor_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        alphadgrid: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        grid: *const ::core::ffi::c_void,
        betadgrid: *const ::core::ffi::c_void,
        dgrid: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnSpatialTfSamplerBackward(
                handle, stdesc, alpha, xdesc, x, beta, dxdesc, dx, alphadgrid, dydesc, dy, grid,
                betadgrid, dgrid,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn dropout_backward(
        handle: ffi::cudnnHandle_t,
        dropoutdesc: ffi::cudnnDropoutDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        reservespace: *mut ::core::ffi::c_void,
        reservespacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnDropoutBackward(
                handle,
                dropoutdesc,
                dydesc,
                dy,
                dxdesc,
                dx,
                reservespace,
                reservespacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_rnn_weight_params(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        pseudolayer: i32,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        linlayerid: i32,
        mdesc: ffi::cudnnTensorDescriptor_t,
        maddr: *mut *mut ::core::ffi::c_void,
        bdesc: ffi::cudnnTensorDescriptor_t,
        baddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetRNNWeightParams(
                handle,
                rnndesc,
                pseudolayer,
                weightspacesize,
                weightspace,
                linlayerid,
                mdesc,
                maddr,
                bdesc,
                baddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_forward(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        fwdmode: ffi::cudnnForwardMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        hy: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        cy: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNForward(
                handle,
                rnndesc,
                fwdmode,
                devseqlengths,
                xdesc,
                x,
                ydesc,
                y,
                hdesc,
                hx,
                hy,
                cdesc,
                cx,
                cy,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_multi_head_attn_weights(
        handle: ffi::cudnnHandle_t,
        attndesc: ffi::cudnnAttnDescriptor_t,
        wkind: ffi::cudnnMultiHeadAttnWeightKind_t,
        weightsizeinbytes: usize,
        weights: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnTensorDescriptor_t,
        waddr: *mut *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetMultiHeadAttnWeights(
                handle,
                attndesc,
                wkind,
                weightsizeinbytes,
                weights,
                wdesc,
                waddr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_data_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        devseqlengths: *const i32,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        dy: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        dhy: *const ::core::ffi::c_void,
        dhx: *mut ::core::ffi::c_void,
        cdesc: ffi::cudnnTensorDescriptor_t,
        cx: *const ::core::ffi::c_void,
        dcy: *const ::core::ffi::c_void,
        dcx: *mut ::core::ffi::c_void,
        weightspacesize: usize,
        weightspace: *const ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardData_v8(
                handle,
                rnndesc,
                devseqlengths,
                ydesc,
                y,
                dy,
                xdesc,
                dx,
                hdesc,
                hx,
                dhy,
                dhx,
                cdesc,
                cx,
                dcy,
                dcx,
                weightspacesize,
                weightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn rnn_backward_weights_v_8(
        handle: ffi::cudnnHandle_t,
        rnndesc: ffi::cudnnRNNDescriptor_t,
        addgrad: ffi::cudnnWgradMode_t,
        devseqlengths: *const i32,
        xdesc: ffi::cudnnRNNDataDescriptor_t,
        x: *const ::core::ffi::c_void,
        hdesc: ffi::cudnnTensorDescriptor_t,
        hx: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnRNNDataDescriptor_t,
        y: *const ::core::ffi::c_void,
        weightspacesize: usize,
        dweightspace: *mut ::core::ffi::c_void,
        workspacesize: usize,
        workspace: *mut ::core::ffi::c_void,
        reservespacesize: usize,
        reservespace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnRNNBackwardWeights_v8(
                handle,
                rnndesc,
                addgrad,
                devseqlengths,
                xdesc,
                x,
                hdesc,
                hx,
                ydesc,
                y,
                weightspacesize,
                dweightspace,
                workspacesize,
                workspace,
                reservespacesize,
                reservespace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn ctc_loss(
        handle: ffi::cudnnHandle_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        hostlabels: *const ::core::ffi::c_int,
        hostlabellengths: *const ::core::ffi::c_int,
        hostinputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnCTCLoss(
                handle,
                probsdesc,
                probs,
                hostlabels,
                hostlabellengths,
                hostinputlengths,
                costs,
                gradientsdesc,
                gradients,
                algo,
                ctclossdesc,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn ctc_loss_v_8(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        probs: *const ::core::ffi::c_void,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        costs: *mut ::core::ffi::c_void,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        gradients: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        workspace: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnCTCLoss_v8(
                handle,
                algo,
                ctclossdesc,
                probsdesc,
                probs,
                labels,
                labellengths,
                inputlengths,
                costs,
                gradientsdesc,
                gradients,
                workspacesizeinbytes,
                workspace,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_workspace_size(
        handle: ffi::cudnnHandle_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        labels: *const ::core::ffi::c_int,
        labellengths: *const ::core::ffi::c_int,
        inputlengths: *const ::core::ffi::c_int,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossWorkspaceSize(
                handle,
                probsdesc,
                gradientsdesc,
                labels,
                labellengths,
                inputlengths,
                algo,
                ctclossdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_ctc_loss_workspace_size_v_8(
        handle: ffi::cudnnHandle_t,
        algo: ffi::cudnnCTCLossAlgo_t,
        ctclossdesc: ffi::cudnnCTCLossDescriptor_t,
        probsdesc: ffi::cudnnTensorDescriptor_t,
        gradientsdesc: ffi::cudnnTensorDescriptor_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetCTCLossWorkspaceSize_v8(
                handle,
                algo,
                ctclossdesc,
                probsdesc,
                gradientsdesc,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_2d_forward_output_dim(
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        n: *mut ::core::ffi::c_int,
        c: *mut ::core::ffi::c_int,
        h: *mut ::core::ffi::c_int,
        w: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolution2dForwardOutputDim(
                convdesc,
                inputtensordesc,
                filterdesc,
                n,
                c,
                h,
                w,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_nd_forward_output_dim(
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        inputtensordesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        nbdims: ::core::ffi::c_int,
        tensorouputdima: *mut ::core::ffi::c_int,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionNdForwardOutputDim(
                convdesc,
                inputtensordesc,
                filterdesc,
                nbdims,
                tensorouputdima,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        destdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardAlgorithm_v7(
                handle,
                srcdesc,
                filterdesc,
                convdesc,
                destdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithm(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_forward_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionFwdAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionForwardAlgorithmEx(
                handle,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                ydesc,
                y,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn im_2col(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        colbuffer: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnIm2Col(handle, xdesc, x, wdesc, convdesc, colbuffer);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_forward_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionForwardWorkspaceSize(
                handle,
                xdesc,
                wdesc,
                convdesc,
                ydesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_forward(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionForward(
                handle,
                alpha,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_bias_activation_forward(
        handle: ffi::cudnnHandle_t,
        alpha1: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionFwdAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        alpha2: *const ::core::ffi::c_void,
        zdesc: ffi::cudnnTensorDescriptor_t,
        z: *const ::core::ffi::c_void,
        biasdesc: ffi::cudnnTensorDescriptor_t,
        bias: *const ::core::ffi::c_void,
        activationdesc: ffi::cudnnActivationDescriptor_t,
        ydesc: ffi::cudnnTensorDescriptor_t,
        y: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBiasActivationForward(
                handle,
                alpha1,
                xdesc,
                x,
                wdesc,
                w,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                alpha2,
                zdesc,
                z,
                biasdesc,
                bias,
                activationdesc,
                ydesc,
                y,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithm(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_data_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardDataAlgorithmEx(
                handle,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                dxdesc,
                dx,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdDataAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataAlgorithm_v7(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_data_workspace_size(
        handle: ffi::cudnnHandle_t,
        wdesc: ffi::cudnnFilterDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardDataWorkspaceSize(
                handle,
                wdesc,
                dydesc,
                convdesc,
                dxdesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_data(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        wdesc: ffi::cudnnFilterDescriptor_t,
        w: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdDataAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dxdesc: ffi::cudnnTensorDescriptor_t,
        dx: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardData(
                handle,
                alpha,
                wdesc,
                w,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dxdesc,
                dx,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_folded_conv_backward_data_descriptors(
        handle: ffi::cudnnHandle_t,
        filterdesc: ffi::cudnnFilterDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnTensorDescriptor_t,
        transformformat: ffi::cudnnTensorFormat_t,
        foldedfilterdesc: ffi::cudnnFilterDescriptor_t,
        paddeddiffdesc: ffi::cudnnTensorDescriptor_t,
        foldedconvdesc: ffi::cudnnConvolutionDescriptor_t,
        foldedgraddesc: ffi::cudnnTensorDescriptor_t,
        filterfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        diffpadtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
        gradunfoldtransdesc: ffi::cudnnTensorTransformDescriptor_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetFoldedConvBackwardDataDescriptors(
                handle,
                filterdesc,
                diffdesc,
                convdesc,
                graddesc,
                transformformat,
                foldedfilterdesc,
                paddeddiffdesc,
                foldedconvdesc,
                foldedgraddesc,
                filterfoldtransdesc,
                diffpadtransdesc,
                gradfoldtransdesc,
                gradunfoldtransdesc,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithm(
                handle,
                xdesc,
                dydesc,
                convdesc,
                dwdesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn find_convolution_backward_filter_algorithm_ex(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        y: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnFindConvolutionBackwardFilterAlgorithmEx(
                handle,
                xdesc,
                x,
                dydesc,
                y,
                convdesc,
                dwdesc,
                dw,
                requestedalgocount,
                returnedalgocount,
                perfresults,
                workspace,
                workspacesizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_algorithm_v_7(
        handle: ffi::cudnnHandle_t,
        srcdesc: ffi::cudnnTensorDescriptor_t,
        diffdesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        requestedalgocount: ::core::ffi::c_int,
        returnedalgocount: *mut ::core::ffi::c_int,
        perfresults: *mut ffi::cudnnConvolutionBwdFilterAlgoPerf_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterAlgorithm_v7(
                handle,
                srcdesc,
                diffdesc,
                convdesc,
                graddesc,
                requestedalgocount,
                returnedalgocount,
                perfresults,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn get_convolution_backward_filter_workspace_size(
        handle: ffi::cudnnHandle_t,
        xdesc: ffi::cudnnTensorDescriptor_t,
        dydesc: ffi::cudnnTensorDescriptor_t,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        graddesc: ffi::cudnnFilterDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        sizeinbytes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnGetConvolutionBackwardFilterWorkspaceSize(
                handle,
                xdesc,
                dydesc,
                convdesc,
                graddesc,
                algo,
                sizeinbytes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_filter(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        xdesc: ffi::cudnnTensorDescriptor_t,
        x: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        convdesc: ffi::cudnnConvolutionDescriptor_t,
        algo: ffi::cudnnConvolutionBwdFilterAlgo_t,
        workspace: *mut ::core::ffi::c_void,
        workspacesizeinbytes: usize,
        beta: *const ::core::ffi::c_void,
        dwdesc: ffi::cudnnFilterDescriptor_t,
        dw: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudnnConvolutionBackwardFilter(
                handle,
                alpha,
                xdesc,
                x,
                dydesc,
                dy,
                convdesc,
                algo,
                workspace,
                workspacesizeinbytes,
                beta,
                dwdesc,
                dw,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn convolution_backward_bias(
        handle: ffi::cudnnHandle_t,
        alpha: *const ::core::ffi::c_void,
        dydesc: ffi::cudnnTensorDescriptor_t,
        dy: *const ::core::ffi::c_void,
        beta: *const ::core::ffi::c_void,
        dbdesc: ffi::cudnnTensorDescriptor_t,
        db: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnConvolutionBackwardBias(handle, alpha, dydesc, dy, beta, dbdesc, db);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaGraphNode_t
impl CudaGraphNode {
    pub fn stream_begin_capture_to_graph(
        stream: ffi::cudaStream_t,
        graph: ffi::cudaGraph_t,
        dependencies: *const ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        mode: ffi::cudaStreamCaptureMode,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamBeginCaptureToGraph(
                stream,
                graph,
                dependencies,
                dependencydata,
                numdependencies,
                mode,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn stream_get_capture_info(
        stream: ffi::cudaStream_t,
        capturestatus_out: *mut ffi::cudaStreamCaptureStatus,
        id_out: *mut ::core::ffi::c_ulonglong,
        graph_out: *mut ffi::cudaGraph_t,
        dependencies_out: *mut *const ffi::cudaGraphNode_t,
        edgedata_out: *mut *const ffi::cudaGraphEdgeData,
        numdependencies_out: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamGetCaptureInfo(
                stream,
                capturestatus_out,
                id_out,
                graph_out,
                dependencies_out,
                edgedata_out,
                numdependencies_out,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn stream_update_capture_dependencies(
        stream: ffi::cudaStream_t,
        dependencies: *mut ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamUpdateCaptureDependencies(
                stream,
                dependencies,
                dependencydata,
                numdependencies,
                flags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_kernel_node_get_params(
        &mut self,
        pnodeparams: *mut ffi::cudaKernelNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphKernelNodeGetParams")
                .entered();
            let result = ffi::cudaGraphKernelNodeGetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_kernel_node_set_params(
        &mut self,
        pnodeparams: *const ffi::cudaKernelNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphKernelNodeSetParams")
                .entered();
            let result = ffi::cudaGraphKernelNodeSetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_kernel_node_copy_attributes(
        &mut self,
        hsrc: ffi::cudaGraphNode_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphKernelNodeCopyAttributes")
                    .entered();
            let result = ffi::cudaGraphKernelNodeCopyAttributes(self.handle, hsrc);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_kernel_node_get_attribute(
        &mut self,
        attr: ffi::cudaLaunchAttributeID,
        value_out: *mut ffi::cudaLaunchAttributeValue,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphKernelNodeGetAttribute")
                    .entered();
            let result = ffi::cudaGraphKernelNodeGetAttribute(self.handle, attr, value_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_kernel_node_set_attribute(
        &mut self,
        attr: ffi::cudaLaunchAttributeID,
        value: *const ffi::cudaLaunchAttributeValue,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if value.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphKernelNodeSetAttribute")
                    .entered();
            let result = ffi::cudaGraphKernelNodeSetAttribute(self.handle, attr, value);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memcpy_node_get_params(
        &mut self,
        pnodeparams: *mut ffi::cudaMemcpy3DParms,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphMemcpyNodeGetParams")
                .entered();
            let result = ffi::cudaGraphMemcpyNodeGetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memcpy_node_set_params(
        &mut self,
        pnodeparams: *const ffi::cudaMemcpy3DParms,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphMemcpyNodeSetParams")
                .entered();
            let result = ffi::cudaGraphMemcpyNodeSetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memcpy_node_set_params_to_symbol(
        &mut self,
        symbol: *const ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphMemcpyNodeSetParamsToSymbol"
            )
            .entered();
            let result = ffi::cudaGraphMemcpyNodeSetParamsToSymbol(
                self.handle,
                symbol,
                src,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memcpy_node_set_params_from_symbol(
        &mut self,
        dst: *mut ::core::ffi::c_void,
        symbol: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if symbol.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphMemcpyNodeSetParamsFromSymbol"
            )
            .entered();
            let result = ffi::cudaGraphMemcpyNodeSetParamsFromSymbol(
                self.handle,
                dst,
                symbol,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memcpy_node_set_params_1d(
        &mut self,
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dst.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if src.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphMemcpyNodeSetParams1D")
                    .entered();
            let result = ffi::cudaGraphMemcpyNodeSetParams1D(self.handle, dst, src, count, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memset_node_get_params(
        &mut self,
        pnodeparams: *mut ffi::cudaMemsetParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphMemsetNodeGetParams")
                .entered();
            let result = ffi::cudaGraphMemsetNodeGetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_memset_node_set_params(
        &mut self,
        pnodeparams: *const ffi::cudaMemsetParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphMemsetNodeSetParams")
                .entered();
            let result = ffi::cudaGraphMemsetNodeSetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_host_node_get_params(
        &mut self,
        pnodeparams: *mut ffi::cudaHostNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphHostNodeGetParams").entered();
            let result = ffi::cudaGraphHostNodeGetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_host_node_set_params(
        &mut self,
        pnodeparams: *const ffi::cudaHostNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphHostNodeSetParams").entered();
            let result = ffi::cudaGraphHostNodeSetParams(self.handle, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_child_graph_node_get_graph(
        &mut self,
        pgraph: *mut ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pgraph.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pgraph.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphChildGraphNodeGetGraph")
                    .entered();
            let result = ffi::cudaGraphChildGraphNodeGetGraph(self.handle, pgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_event_record_node_get_event(
        &mut self,
        event_out: *mut ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if event_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if event_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphEventRecordNodeGetEvent")
                    .entered();
            let result = ffi::cudaGraphEventRecordNodeGetEvent(self.handle, event_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_event_record_node_set_event(
        &mut self,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphEventRecordNodeSetEvent")
                    .entered();
            let result = ffi::cudaGraphEventRecordNodeSetEvent(self.handle, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_event_wait_node_get_event(
        &mut self,
        event_out: *mut ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if event_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if event_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphEventWaitNodeGetEvent")
                    .entered();
            let result = ffi::cudaGraphEventWaitNodeGetEvent(self.handle, event_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_event_wait_node_set_event(
        &mut self,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphEventWaitNodeSetEvent")
                    .entered();
            let result = ffi::cudaGraphEventWaitNodeSetEvent(self.handle, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_external_semaphores_signal_node_get_params(
        &mut self,
        params_out: *mut ffi::cudaExternalSemaphoreSignalNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExternalSemaphoresSignalNodeGetParams"
            )
            .entered();
            let result =
                ffi::cudaGraphExternalSemaphoresSignalNodeGetParams(self.handle, params_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_external_semaphores_signal_node_set_params(
        &mut self,
        nodeparams: *const ffi::cudaExternalSemaphoreSignalNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExternalSemaphoresSignalNodeSetParams"
            )
            .entered();
            let result =
                ffi::cudaGraphExternalSemaphoresSignalNodeSetParams(self.handle, nodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_external_semaphores_wait_node_get_params(
        &mut self,
        params_out: *mut ffi::cudaExternalSemaphoreWaitNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExternalSemaphoresWaitNodeGetParams"
            )
            .entered();
            let result = ffi::cudaGraphExternalSemaphoresWaitNodeGetParams(self.handle, params_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_external_semaphores_wait_node_set_params(
        &mut self,
        nodeparams: *const ffi::cudaExternalSemaphoreWaitNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!(
                "ffi_call",
                function = "cudaGraphExternalSemaphoresWaitNodeSetParams"
            )
            .entered();
            let result = ffi::cudaGraphExternalSemaphoresWaitNodeSetParams(self.handle, nodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_mem_alloc_node_get_params(
        &mut self,
        params_out: *mut ffi::cudaMemAllocNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if params_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphMemAllocNodeGetParams")
                    .entered();
            let result = ffi::cudaGraphMemAllocNodeGetParams(self.handle, params_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_mem_free_node_get_params(
        &mut self,
        dptr_out: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if dptr_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if dptr_out.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphMemFreeNodeGetParams")
                    .entered();
            let result = ffi::cudaGraphMemFreeNodeGetParams(self.handle, dptr_out);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_get_type(&mut self, ptype: *mut ffi::cudaGraphNodeType) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if ptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if ptype.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphNodeGetType").entered();
            let result = ffi::cudaGraphNodeGetType(self.handle, ptype);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_get_nodes(
        graph: ffi::cudaGraph_t,
        nodes: *mut ffi::cudaGraphNode_t,
        numnodes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphGetNodes(graph, nodes, numnodes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_get_root_nodes(
        graph: ffi::cudaGraph_t,
        prootnodes: *mut ffi::cudaGraphNode_t,
        pnumrootnodes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphGetRootNodes(graph, prootnodes, pnumrootnodes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_get_edges(
        graph: ffi::cudaGraph_t,
        from: *mut ffi::cudaGraphNode_t,
        to: *mut ffi::cudaGraphNode_t,
        edgedata: *mut ffi::cudaGraphEdgeData,
        numedges: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphGetEdges(graph, from, to, edgedata, numedges);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_get_dependencies(
        &mut self,
        pdependencies: *mut ffi::cudaGraphNode_t,
        edgedata: *mut ffi::cudaGraphEdgeData,
        pnumdependencies: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pdependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pdependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if pnumdependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnumdependencies.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphNodeGetDependencies")
                .entered();
            let result = ffi::cudaGraphNodeGetDependencies(
                self.handle,
                pdependencies,
                edgedata,
                pnumdependencies,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_get_dependent_nodes(
        &mut self,
        pdependentnodes: *mut ffi::cudaGraphNode_t,
        edgedata: *mut ffi::cudaGraphEdgeData,
        pnumdependentnodes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if pdependentnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pdependentnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if pnumdependentnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnumdependentnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphNodeGetDependentNodes")
                    .entered();
            let result = ffi::cudaGraphNodeGetDependentNodes(
                self.handle,
                pdependentnodes,
                edgedata,
                pnumdependentnodes,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_dependencies(
        graph: ffi::cudaGraph_t,
        from: *const ffi::cudaGraphNode_t,
        to: *const ffi::cudaGraphNode_t,
        edgedata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddDependencies(graph, from, to, edgedata, numdependencies);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_remove_dependencies(
        graph: ffi::cudaGraph_t,
        from: *const ffi::cudaGraphNode_t,
        to: *const ffi::cudaGraphNode_t,
        edgedata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaGraphRemoveDependencies(graph, from, to, edgedata, numdependencies);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_destroy_node(&mut self) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphDestroyNode").entered();
            let result = ffi::cudaGraphDestroyNode(self.handle);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_kernel_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaKernelNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecKernelNodeSetParams(hgraphexec, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_memcpy_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaMemcpy3DParms,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecMemcpyNodeSetParams(hgraphexec, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_memcpy_node_set_params_to_symbol(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        symbol: *const ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecMemcpyNodeSetParamsToSymbol(
                hgraphexec, node, symbol, src, count, offset, kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_memcpy_node_set_params_from_symbol(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        dst: *mut ::core::ffi::c_void,
        symbol: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecMemcpyNodeSetParamsFromSymbol(
                hgraphexec, node, dst, symbol, count, offset, kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_memcpy_node_set_params_1d(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaGraphExecMemcpyNodeSetParams1D(hgraphexec, node, dst, src, count, kind);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_memset_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaMemsetParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecMemsetNodeSetParams(hgraphexec, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_host_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        pnodeparams: *const ffi::cudaHostNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecHostNodeSetParams(hgraphexec, node, pnodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_child_graph_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        childgraph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecChildGraphNodeSetParams(hgraphexec, node, childgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_event_record_node_set_event(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecEventRecordNodeSetEvent(hgraphexec, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_event_wait_node_set_event(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecEventWaitNodeSetEvent(hgraphexec, hnode, event);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_external_semaphores_signal_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        nodeparams: *const ffi::cudaExternalSemaphoreSignalNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecExternalSemaphoresSignalNodeSetParams(
                hgraphexec, hnode, nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_external_semaphores_wait_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        nodeparams: *const ffi::cudaExternalSemaphoreWaitNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecExternalSemaphoresWaitNodeSetParams(
                hgraphexec, hnode, nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_node_set_enabled(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        isenabled: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphNodeSetEnabled(hgraphexec, hnode, isenabled);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_node_get_enabled(
        hgraphexec: ffi::cudaGraphExec_t,
        hnode: ffi::cudaGraphNode_t,
        isenabled: *mut ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphNodeGetEnabled(hgraphexec, hnode, isenabled);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_node_set_params(
        &mut self,
        nodeparams: *mut ffi::cudaGraphNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodeparams.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphNodeSetParams").entered();
            let result = ffi::cudaGraphNodeSetParams(self.handle, nodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_node_set_params(
        graphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        nodeparams: *mut ffi::cudaGraphNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecNodeSetParams(graphexec, node, nodeparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaGraph_t
impl CudaGraph {
    pub fn stream_begin_capture_to_graph(
        stream: ffi::cudaStream_t,
        graph: ffi::cudaGraph_t,
        dependencies: *const ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        mode: ffi::cudaStreamCaptureMode,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamBeginCaptureToGraph(
                stream,
                graph,
                dependencies,
                dependencydata,
                numdependencies,
                mode,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn stream_end_capture(
        stream: ffi::cudaStream_t,
        pgraph: *mut ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamEndCapture(stream, pgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn stream_get_capture_info(
        stream: ffi::cudaStream_t,
        capturestatus_out: *mut ffi::cudaStreamCaptureStatus,
        id_out: *mut ::core::ffi::c_ulonglong,
        graph_out: *mut ffi::cudaGraph_t,
        dependencies_out: *mut *const ffi::cudaGraphNode_t,
        edgedata_out: *mut *const ffi::cudaGraphEdgeData,
        numdependencies_out: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamGetCaptureInfo(
                stream,
                capturestatus_out,
                id_out,
                graph_out,
                dependencies_out,
                edgedata_out,
                numdependencies_out,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_kernel_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        pnodeparams: *const ffi::cudaKernelNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddKernelNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                pnodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_memcpy_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        pcopyparams: *const ffi::cudaMemcpy3DParms,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemcpyNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                pcopyparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_memcpy_node_to_symbol(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        symbol: *const ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemcpyNodeToSymbol(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                symbol,
                src,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_memcpy_node_from_symbol(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        dst: *mut ::core::ffi::c_void,
        symbol: *const ::core::ffi::c_void,
        count: usize,
        offset: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemcpyNodeFromSymbol(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                dst,
                symbol,
                count,
                offset,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_memcpy_node_1d(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        count: usize,
        kind: ffi::cudaMemcpyKind,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemcpyNode1D(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                dst,
                src,
                count,
                kind,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_memset_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        pmemsetparams: *const ffi::cudaMemsetParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemsetNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                pmemsetparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_host_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        pnodeparams: *const ffi::cudaHostNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddHostNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                pnodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_child_graph_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        childgraph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddChildGraphNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                childgraph,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_child_graph_node_get_graph(
        node: ffi::cudaGraphNode_t,
        pgraph: *mut ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphChildGraphNodeGetGraph(node, pgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_empty_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudaGraphAddEmptyNode(pgraphnode, graph, pdependencies, numdependencies);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_event_record_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddEventRecordNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                event,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_event_wait_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        event: ffi::cudaEvent_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddEventWaitNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                event,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_external_semaphores_signal_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        nodeparams: *const ffi::cudaExternalSemaphoreSignalNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddExternalSemaphoresSignalNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_external_semaphores_wait_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        nodeparams: *const ffi::cudaExternalSemaphoreWaitNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddExternalSemaphoresWaitNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_mem_alloc_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        nodeparams: *mut ffi::cudaMemAllocNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemAllocNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_mem_free_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        numdependencies: usize,
        dptr: *mut ::core::ffi::c_void,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddMemFreeNode(
                pgraphnode,
                graph,
                pdependencies,
                numdependencies,
                dptr,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_node_find_in_clone(
        pnode: *mut ffi::cudaGraphNode_t,
        originalnode: ffi::cudaGraphNode_t,
        clonedgraph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphNodeFindInClone(pnode, originalnode, clonedgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_get_nodes(
        &mut self,
        nodes: *mut ffi::cudaGraphNode_t,
        numnodes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if nodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if nodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if numnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if numnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphGetNodes").entered();
            let result = ffi::cudaGraphGetNodes(self.handle, nodes, numnodes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_get_root_nodes(
        &mut self,
        prootnodes: *mut ffi::cudaGraphNode_t,
        pnumrootnodes: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if prootnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if prootnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if pnumrootnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if pnumrootnodes.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphGetRootNodes").entered();
            let result = ffi::cudaGraphGetRootNodes(self.handle, prootnodes, pnumrootnodes);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_get_edges(
        &mut self,
        from: *mut ffi::cudaGraphNode_t,
        to: *mut ffi::cudaGraphNode_t,
        edgedata: *mut ffi::cudaGraphEdgeData,
        numedges: *mut usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if numedges.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if numedges.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphGetEdges").entered();
            let result = ffi::cudaGraphGetEdges(self.handle, from, to, edgedata, numedges);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_add_dependencies(
        &mut self,
        from: *const ffi::cudaGraphNode_t,
        to: *const ffi::cudaGraphNode_t,
        edgedata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphAddDependencies").entered();
            let result =
                ffi::cudaGraphAddDependencies(self.handle, from, to, edgedata, numdependencies);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_remove_dependencies(
        &mut self,
        from: *const ffi::cudaGraphNode_t,
        to: *const ffi::cudaGraphNode_t,
        edgedata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "strict")]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if from.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if to.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "strict")]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(all(feature = "balanced", not(feature = "strict")))]
            if edgedata.is_null() {
                return Err(Error::NullPointer);
            }
            #[cfg(feature = "tracing")]
            let _span = tracing::trace_span!("ffi_call", function = "cudaGraphRemoveDependencies")
                .entered();
            let result =
                ffi::cudaGraphRemoveDependencies(self.handle, from, to, edgedata, numdependencies);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_instantiate(
        pgraphexec: *mut ffi::cudaGraphExec_t,
        graph: ffi::cudaGraph_t,
        flags: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphInstantiate(pgraphexec, graph, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_instantiate_with_flags(
        pgraphexec: *mut ffi::cudaGraphExec_t,
        graph: ffi::cudaGraph_t,
        flags: ::core::ffi::c_ulonglong,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphInstantiateWithFlags(pgraphexec, graph, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_instantiate_with_params(
        pgraphexec: *mut ffi::cudaGraphExec_t,
        graph: ffi::cudaGraph_t,
        instantiateparams: *mut ffi::cudaGraphInstantiateParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphInstantiateWithParams(pgraphexec, graph, instantiateparams);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_child_graph_node_set_params(
        hgraphexec: ffi::cudaGraphExec_t,
        node: ffi::cudaGraphNode_t,
        childgraph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecChildGraphNodeSetParams(hgraphexec, node, childgraph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_exec_update(
        hgraphexec: ffi::cudaGraphExec_t,
        hgraph: ffi::cudaGraph_t,
        resultinfo: *mut ffi::cudaGraphExecUpdateResultInfo,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphExecUpdate(hgraphexec, hgraph, resultinfo);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_debug_dot_print(
        &mut self,
        path: &str,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let path_cstr = std::ffi::CString::new(path).map_err(|_| Error::NullPointer)?;
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphDebugDotPrint").entered();
            let result = ffi::cudaGraphDebugDotPrint(self.handle, path_cstr.as_ptr(), flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    #[inline]
    pub fn graph_retain_user_object(
        &mut self,
        object: ffi::cudaUserObject_t,
        count: ::core::ffi::c_uint,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            #[cfg(feature = "tracing")]
            let _span =
                tracing::trace_span!("ffi_call", function = "cudaGraphRetainUserObject").entered();
            let result = ffi::cudaGraphRetainUserObject(self.handle, object, count, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_add_node(
        pgraphnode: *mut ffi::cudaGraphNode_t,
        graph: ffi::cudaGraph_t,
        pdependencies: *const ffi::cudaGraphNode_t,
        dependencydata: *const ffi::cudaGraphEdgeData,
        numdependencies: usize,
        nodeparams: *mut ffi::cudaGraphNodeParams,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphAddNode(
                pgraphnode,
                graph,
                pdependencies,
                dependencydata,
                numdependencies,
                nodeparams,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn graph_conditional_handle_create(
        phandle_out: *mut ffi::cudaGraphConditionalHandle,
        graph: ffi::cudaGraph_t,
        defaultlaunchvalue: ::core::ffi::c_uint,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaGraphConditionalHandleCreate(
                phandle_out,
                graph,
                defaultlaunchvalue,
                flags,
            );
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn backend_populate_cuda_graph(
        handle: ffi::cudnnHandle_t,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnBackendPopulateCudaGraph(handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }

    pub fn backend_update_cuda_graph(
        handle: ffi::cudnnHandle_t,
        executionplan: ffi::cudnnBackendDescriptor_t,
        variantpack: ffi::cudnnBackendDescriptor_t,
        graph: ffi::cudaGraph_t,
    ) -> Result<(), Error> {
        unsafe {
            let result =
                ffi::cudnnBackendUpdateCudaGraph(handle, executionplan, variantpack, graph);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Additional methods for cudaStreamCallback_t
impl CudaStreamCallback {
    pub fn stream_add_callback(
        stream: ffi::cudaStream_t,
        callback: ffi::cudaStreamCallback_t,
        userdata: *mut ::core::ffi::c_void,
        flags: ::core::ffi::c_uint,
    ) -> Result<(), Error> {
        unsafe {
            let result = ffi::cudaStreamAddCallback(stream, callback, userdata, flags);
            if result == 0 {
                Ok(())
            } else {
                Err(Error::from(result))
            }
        }
    }
}

// Typestate builder for CudnnHandle
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnHandleBuilderInitial;
pub struct CudnnHandleBuilderBuilt;

pub struct CudnnHandleBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnHandleBuilder<CudnnHandleBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnHandleBuilder<CudnnHandleBuilderInitial> {
    pub fn cudnn_create(self) -> CudnnHandleBuilder<CudnnHandleBuilderBuilt> {
        // Call FFI: cudnnCreate()
        CudnnHandleBuilder::<CudnnHandleBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnHandleBuilder<CudnnHandleBuilderBuilt> {
    pub fn build(self) -> CudnnHandle {
        // Finalize and return CudnnHandle
        todo!("Implement CudnnHandle  construction")
    }
}

// Usage example:
// let obj = CudnnHandleBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnConvolutionDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnConvolutionDescriptorBuilderInitial;
pub struct CudnnConvolutionDescriptorBuilderBuilt;

pub struct CudnnConvolutionDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnConvolutionDescriptorBuilder<CudnnConvolutionDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnConvolutionDescriptorBuilder<CudnnConvolutionDescriptorBuilderInitial> {
    pub fn cudnn_create_convolution_descriptor(
        self,
    ) -> CudnnConvolutionDescriptorBuilder<CudnnConvolutionDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateConvolutionDescriptor()
        CudnnConvolutionDescriptorBuilder::<CudnnConvolutionDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnConvolutionDescriptorBuilder<CudnnConvolutionDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnConvolutionDescriptor {
        // Finalize and return CudnnConvolutionDescriptor
        todo!("Implement CudnnConvolutionDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnConvolutionDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnFilterDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnFilterDescriptorBuilderInitial;
pub struct CudnnFilterDescriptorBuilderBuilt;

pub struct CudnnFilterDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnFilterDescriptorBuilder<CudnnFilterDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFilterDescriptorBuilder<CudnnFilterDescriptorBuilderInitial> {
    pub fn cudnn_create_filter_descriptor(
        self,
    ) -> CudnnFilterDescriptorBuilder<CudnnFilterDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateFilterDescriptor()
        CudnnFilterDescriptorBuilder::<CudnnFilterDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFilterDescriptorBuilder<CudnnFilterDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnFilterDescriptor {
        // Finalize and return CudnnFilterDescriptor
        todo!("Implement CudnnFilterDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnFilterDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnSeqDataDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnSeqDataDescriptorBuilderInitial;
pub struct CudnnSeqDataDescriptorBuilderBuilt;

pub struct CudnnSeqDataDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnSeqDataDescriptorBuilder<CudnnSeqDataDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnSeqDataDescriptorBuilder<CudnnSeqDataDescriptorBuilderInitial> {
    pub fn cudnn_create_seq_data_descriptor(
        self,
    ) -> CudnnSeqDataDescriptorBuilder<CudnnSeqDataDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateSeqDataDescriptor()
        CudnnSeqDataDescriptorBuilder::<CudnnSeqDataDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnSeqDataDescriptorBuilder<CudnnSeqDataDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnSeqDataDescriptor {
        // Finalize and return CudnnSeqDataDescriptor
        todo!("Implement CudnnSeqDataDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnSeqDataDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaMemPool
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaMemPoolBuilderInitial;
pub struct CudaMemPoolBuilderBuilt;

pub struct CudaMemPoolBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaMemPoolBuilder<CudaMemPoolBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaMemPoolBuilder<CudaMemPoolBuilderInitial> {
    pub fn cuda_mem_pool_create(self) -> CudaMemPoolBuilder<CudaMemPoolBuilderBuilt> {
        // Call FFI: cudaMemPoolCreate()
        CudaMemPoolBuilder::<CudaMemPoolBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaMemPoolBuilder<CudaMemPoolBuilderBuilt> {
    pub fn build(self) -> CudaMemPool {
        // Finalize and return CudaMemPool
        todo!("Implement CudaMemPool  construction")
    }
}

// Usage example:
// let obj = CudaMemPoolBuilder::new()
//     .create()
//     .build();

// Typestate builder for SecurityInitCookie
// Ensures compile-time enforcement of builder order

// State marker types
pub struct SecurityInitCookieBuilderInitial;
pub struct SecurityInitCookieBuilderBuilt;

pub struct SecurityInitCookieBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl SecurityInitCookieBuilder<SecurityInitCookieBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl SecurityInitCookieBuilder<SecurityInitCookieBuilderInitial> {
    pub fn __security_init_cookie(
        self,
    ) -> SecurityInitCookieBuilder<SecurityInitCookieBuilderBuilt> {
        // Call FFI: __security_init_cookie()
        SecurityInitCookieBuilder::<SecurityInitCookieBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl SecurityInitCookieBuilder<SecurityInitCookieBuilderBuilt> {
    pub fn build(self) -> SecurityInitCookie {
        // Finalize and return SecurityInitCookie
        todo!("Implement SecurityInitCookie  construction")
    }
}

// Usage example:
// let obj = SecurityInitCookieBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaInitDevice
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaInitDeviceBuilderInitial;
pub struct CudaInitDeviceBuilderBuilt;

pub struct CudaInitDeviceBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaInitDeviceBuilder<CudaInitDeviceBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaInitDeviceBuilder<CudaInitDeviceBuilderInitial> {
    pub fn cuda_init_device(self) -> CudaInitDeviceBuilder<CudaInitDeviceBuilderBuilt> {
        // Call FFI: cudaInitDevice()
        CudaInitDeviceBuilder::<CudaInitDeviceBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaInitDeviceBuilder<CudaInitDeviceBuilderBuilt> {
    pub fn build(self) -> CudaInitDevice {
        // Finalize and return CudaInitDevice
        todo!("Implement CudaInitDevice  construction")
    }
}

// Usage example:
// let obj = CudaInitDeviceBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnOpTensorDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnOpTensorDescriptorBuilderInitial;
pub struct CudnnOpTensorDescriptorBuilderBuilt;

pub struct CudnnOpTensorDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnOpTensorDescriptorBuilder<CudnnOpTensorDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnOpTensorDescriptorBuilder<CudnnOpTensorDescriptorBuilderInitial> {
    pub fn cudnn_create_op_tensor_descriptor(
        self,
    ) -> CudnnOpTensorDescriptorBuilder<CudnnOpTensorDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateOpTensorDescriptor()
        CudnnOpTensorDescriptorBuilder::<CudnnOpTensorDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnOpTensorDescriptorBuilder<CudnnOpTensorDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnOpTensorDescriptor {
        // Finalize and return CudnnOpTensorDescriptor
        todo!("Implement CudnnOpTensorDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnOpTensorDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnSpatialTransformerDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnSpatialTransformerDescriptorBuilderInitial;
pub struct CudnnSpatialTransformerDescriptorBuilderBuilt;

pub struct CudnnSpatialTransformerDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnSpatialTransformerDescriptorBuilder<CudnnSpatialTransformerDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnSpatialTransformerDescriptorBuilder<CudnnSpatialTransformerDescriptorBuilderInitial> {
    pub fn cudnn_create_spatial_transformer_descriptor(
        self,
    ) -> CudnnSpatialTransformerDescriptorBuilder<CudnnSpatialTransformerDescriptorBuilderBuilt>
    {
        // Call FFI: cudnnCreateSpatialTransformerDescriptor()
        CudnnSpatialTransformerDescriptorBuilder::<CudnnSpatialTransformerDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnSpatialTransformerDescriptorBuilder<CudnnSpatialTransformerDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnSpatialTransformerDescriptor {
        // Finalize and return CudnnSpatialTransformerDescriptor
        todo!("Implement CudnnSpatialTransformerDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnSpatialTransformerDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnTensorTransformDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnTensorTransformDescriptorBuilderInitial;
pub struct CudnnTensorTransformDescriptorBuilderBuilt;

pub struct CudnnTensorTransformDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnTensorTransformDescriptorBuilder<CudnnTensorTransformDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnTensorTransformDescriptorBuilder<CudnnTensorTransformDescriptorBuilderInitial> {
    pub fn cudnn_create_tensor_transform_descriptor(
        self,
    ) -> CudnnTensorTransformDescriptorBuilder<CudnnTensorTransformDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateTensorTransformDescriptor()
        CudnnTensorTransformDescriptorBuilder::<CudnnTensorTransformDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnTensorTransformDescriptorBuilder<CudnnTensorTransformDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnTensorTransformDescriptor {
        // Finalize and return CudnnTensorTransformDescriptor
        todo!("Implement CudnnTensorTransformDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnTensorTransformDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnLRNDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnLRNDescriptorBuilderInitial;
pub struct CudnnLRNDescriptorBuilderBuilt;

pub struct CudnnLRNDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnLRNDescriptorBuilder<CudnnLRNDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnLRNDescriptorBuilder<CudnnLRNDescriptorBuilderInitial> {
    pub fn cudnn_create_l_r_n_descriptor(
        self,
    ) -> CudnnLRNDescriptorBuilder<CudnnLRNDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateLRNDescriptor()
        CudnnLRNDescriptorBuilder::<CudnnLRNDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnLRNDescriptorBuilder<CudnnLRNDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnLRNDescriptor {
        // Finalize and return CudnnLRNDescriptor
        todo!("Implement CudnnLRNDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnLRNDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnAttnDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnAttnDescriptorBuilderInitial;
pub struct CudnnAttnDescriptorBuilderBuilt;

pub struct CudnnAttnDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnAttnDescriptorBuilder<CudnnAttnDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnAttnDescriptorBuilder<CudnnAttnDescriptorBuilderInitial> {
    pub fn cudnn_create_attn_descriptor(
        self,
    ) -> CudnnAttnDescriptorBuilder<CudnnAttnDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateAttnDescriptor()
        CudnnAttnDescriptorBuilder::<CudnnAttnDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnAttnDescriptorBuilder<CudnnAttnDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnAttnDescriptor {
        // Finalize and return CudnnAttnDescriptor
        todo!("Implement CudnnAttnDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnAttnDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaCreateChannelDesc
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaCreateChannelDescBuilderInitial;
pub struct CudaCreateChannelDescBuilderBuilt;

pub struct CudaCreateChannelDescBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaCreateChannelDescBuilder<CudaCreateChannelDescBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaCreateChannelDescBuilder<CudaCreateChannelDescBuilderInitial> {
    pub fn cuda_create_channel_desc(
        self,
    ) -> CudaCreateChannelDescBuilder<CudaCreateChannelDescBuilderBuilt> {
        // Call FFI: cudaCreateChannelDesc()
        CudaCreateChannelDescBuilder::<CudaCreateChannelDescBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaCreateChannelDescBuilder<CudaCreateChannelDescBuilderBuilt> {
    pub fn build(self) -> CudaCreateChannelDesc {
        // Finalize and return CudaCreateChannelDesc
        todo!("Implement CudaCreateChannelDesc  construction")
    }
}

// Usage example:
// let obj = CudaCreateChannelDescBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnRNNDataDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnRNNDataDescriptorBuilderInitial;
pub struct CudnnRNNDataDescriptorBuilderBuilt;

pub struct CudnnRNNDataDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnRNNDataDescriptorBuilder<CudnnRNNDataDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnRNNDataDescriptorBuilder<CudnnRNNDataDescriptorBuilderInitial> {
    pub fn cudnn_create_r_n_n_data_descriptor(
        self,
    ) -> CudnnRNNDataDescriptorBuilder<CudnnRNNDataDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateRNNDataDescriptor()
        CudnnRNNDataDescriptorBuilder::<CudnnRNNDataDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnRNNDataDescriptorBuilder<CudnnRNNDataDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnRNNDataDescriptor {
        // Finalize and return CudnnRNNDataDescriptor
        todo!("Implement CudnnRNNDataDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnRNNDataDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnActivationDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnActivationDescriptorBuilderInitial;
pub struct CudnnActivationDescriptorBuilderBuilt;

pub struct CudnnActivationDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnActivationDescriptorBuilder<CudnnActivationDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnActivationDescriptorBuilder<CudnnActivationDescriptorBuilderInitial> {
    pub fn cudnn_create_activation_descriptor(
        self,
    ) -> CudnnActivationDescriptorBuilder<CudnnActivationDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateActivationDescriptor()
        CudnnActivationDescriptorBuilder::<CudnnActivationDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnActivationDescriptorBuilder<CudnnActivationDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnActivationDescriptor {
        // Finalize and return CudnnActivationDescriptor
        todo!("Implement CudnnActivationDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnActivationDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnFusedOpsPlan
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnFusedOpsPlanBuilderInitial;
pub struct CudnnFusedOpsPlanBuilderBuilt;

pub struct CudnnFusedOpsPlanBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnFusedOpsPlanBuilder<CudnnFusedOpsPlanBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsPlanBuilder<CudnnFusedOpsPlanBuilderInitial> {
    pub fn cudnn_create_fused_ops_plan(
        self,
    ) -> CudnnFusedOpsPlanBuilder<CudnnFusedOpsPlanBuilderBuilt> {
        // Call FFI: cudnnCreateFusedOpsPlan()
        CudnnFusedOpsPlanBuilder::<CudnnFusedOpsPlanBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsPlanBuilder<CudnnFusedOpsPlanBuilderBuilt> {
    pub fn build(self) -> CudnnFusedOpsPlan {
        // Finalize and return CudnnFusedOpsPlan
        todo!("Implement CudnnFusedOpsPlan  construction")
    }
}

// Usage example:
// let obj = CudnnFusedOpsPlanBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnTensorDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnTensorDescriptorBuilderInitial;
pub struct CudnnTensorDescriptorBuilderBuilt;

pub struct CudnnTensorDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnTensorDescriptorBuilder<CudnnTensorDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnTensorDescriptorBuilder<CudnnTensorDescriptorBuilderInitial> {
    pub fn cudnn_create_tensor_descriptor(
        self,
    ) -> CudnnTensorDescriptorBuilder<CudnnTensorDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateTensorDescriptor()
        CudnnTensorDescriptorBuilder::<CudnnTensorDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnTensorDescriptorBuilder<CudnnTensorDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnTensorDescriptor {
        // Finalize and return CudnnTensorDescriptor
        todo!("Implement CudnnTensorDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnTensorDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnBackendDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnBackendDescriptorBuilderInitial;
pub struct CudnnBackendDescriptorBuilderBuilt;

pub struct CudnnBackendDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnBackendDescriptorBuilder<CudnnBackendDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnBackendDescriptorBuilder<CudnnBackendDescriptorBuilderInitial> {
    pub fn cudnn_backend_create_descriptor(
        self,
    ) -> CudnnBackendDescriptorBuilder<CudnnBackendDescriptorBuilderBuilt> {
        // Call FFI: cudnnBackendCreateDescriptor()
        CudnnBackendDescriptorBuilder::<CudnnBackendDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnBackendDescriptorBuilder<CudnnBackendDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnBackendDescriptor {
        // Finalize and return CudnnBackendDescriptor
        todo!("Implement CudnnBackendDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnBackendDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaTextureObject
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaTextureObjectBuilderInitial;
pub struct CudaTextureObjectBuilderBuilt;

pub struct CudaTextureObjectBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaTextureObjectBuilder<CudaTextureObjectBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaTextureObjectBuilder<CudaTextureObjectBuilderInitial> {
    pub fn cuda_create_texture_object(
        self,
    ) -> CudaTextureObjectBuilder<CudaTextureObjectBuilderBuilt> {
        // Call FFI: cudaCreateTextureObject()
        CudaTextureObjectBuilder::<CudaTextureObjectBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaTextureObjectBuilder<CudaTextureObjectBuilderBuilt> {
    pub fn build(self) -> CudaTextureObject {
        // Finalize and return CudaTextureObject
        todo!("Implement CudaTextureObject  construction")
    }
}

// Usage example:
// let obj = CudaTextureObjectBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaSurfaceObject
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaSurfaceObjectBuilderInitial;
pub struct CudaSurfaceObjectBuilderBuilt;

pub struct CudaSurfaceObjectBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaSurfaceObjectBuilder<CudaSurfaceObjectBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaSurfaceObjectBuilder<CudaSurfaceObjectBuilderInitial> {
    pub fn cuda_create_surface_object(
        self,
    ) -> CudaSurfaceObjectBuilder<CudaSurfaceObjectBuilderBuilt> {
        // Call FFI: cudaCreateSurfaceObject()
        CudaSurfaceObjectBuilder::<CudaSurfaceObjectBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaSurfaceObjectBuilder<CudaSurfaceObjectBuilderBuilt> {
    pub fn build(self) -> CudaSurfaceObject {
        // Finalize and return CudaSurfaceObject
        todo!("Implement CudaSurfaceObject  construction")
    }
}

// Usage example:
// let obj = CudaSurfaceObjectBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnRNNDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnRNNDescriptorBuilderInitial;
pub struct CudnnRNNDescriptorBuilderBuilt;

pub struct CudnnRNNDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnRNNDescriptorBuilder<CudnnRNNDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnRNNDescriptorBuilder<CudnnRNNDescriptorBuilderInitial> {
    pub fn cudnn_create_r_n_n_descriptor(
        self,
    ) -> CudnnRNNDescriptorBuilder<CudnnRNNDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateRNNDescriptor()
        CudnnRNNDescriptorBuilder::<CudnnRNNDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnRNNDescriptorBuilder<CudnnRNNDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnRNNDescriptor {
        // Finalize and return CudnnRNNDescriptor
        todo!("Implement CudnnRNNDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnRNNDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaGraphConditionalHandle
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaGraphConditionalHandleBuilderInitial;
pub struct CudaGraphConditionalHandleBuilderBuilt;

pub struct CudaGraphConditionalHandleBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaGraphConditionalHandleBuilder<CudaGraphConditionalHandleBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaGraphConditionalHandleBuilder<CudaGraphConditionalHandleBuilderInitial> {
    pub fn cuda_graph_conditional_handle_create(
        self,
    ) -> CudaGraphConditionalHandleBuilder<CudaGraphConditionalHandleBuilderBuilt> {
        // Call FFI: cudaGraphConditionalHandleCreate()
        CudaGraphConditionalHandleBuilder::<CudaGraphConditionalHandleBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaGraphConditionalHandleBuilder<CudaGraphConditionalHandleBuilderBuilt> {
    pub fn build(self) -> CudaGraphConditionalHandle {
        // Finalize and return CudaGraphConditionalHandle
        todo!("Implement CudaGraphConditionalHandle  construction")
    }
}

// Usage example:
// let obj = CudaGraphConditionalHandleBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnPoolingDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnPoolingDescriptorBuilderInitial;
pub struct CudnnPoolingDescriptorBuilderBuilt;

pub struct CudnnPoolingDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnPoolingDescriptorBuilder<CudnnPoolingDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnPoolingDescriptorBuilder<CudnnPoolingDescriptorBuilderInitial> {
    pub fn cudnn_create_pooling_descriptor(
        self,
    ) -> CudnnPoolingDescriptorBuilder<CudnnPoolingDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreatePoolingDescriptor()
        CudnnPoolingDescriptorBuilder::<CudnnPoolingDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnPoolingDescriptorBuilder<CudnnPoolingDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnPoolingDescriptor {
        // Finalize and return CudnnPoolingDescriptor
        todo!("Implement CudnnPoolingDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnPoolingDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnBackendInitialize
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnBackendInitializeBuilderInitial;
pub struct CudnnBackendInitializeBuilderBuilt;

pub struct CudnnBackendInitializeBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnBackendInitializeBuilder<CudnnBackendInitializeBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnBackendInitializeBuilder<CudnnBackendInitializeBuilderInitial> {
    pub fn cudnn_backend_initialize(
        self,
    ) -> CudnnBackendInitializeBuilder<CudnnBackendInitializeBuilderBuilt> {
        // Call FFI: cudnnBackendInitialize()
        CudnnBackendInitializeBuilder::<CudnnBackendInitializeBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnBackendInitializeBuilder<CudnnBackendInitializeBuilderBuilt> {
    pub fn build(self) -> CudnnBackendInitialize {
        // Finalize and return CudnnBackendInitialize
        todo!("Implement CudnnBackendInitialize  construction")
    }
}

// Usage example:
// let obj = CudnnBackendInitializeBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaStream
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaStreamBuilderInitial;
pub struct CudaStreamBuilderBuilt;

pub struct CudaStreamBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaStreamBuilder<CudaStreamBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaStreamBuilder<CudaStreamBuilderInitial> {
    pub fn cuda_stream_create(self) -> CudaStreamBuilder<CudaStreamBuilderBuilt> {
        // Call FFI: cudaStreamCreate()
        CudaStreamBuilder::<CudaStreamBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
    pub fn cuda_stream_create_with_flags(self) -> CudaStreamBuilder<CudaStreamBuilderBuilt> {
        // Call FFI: cudaStreamCreateWithFlags()
        CudaStreamBuilder::<CudaStreamBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
    pub fn cuda_stream_create_with_priority(self) -> CudaStreamBuilder<CudaStreamBuilderBuilt> {
        // Call FFI: cudaStreamCreateWithPriority()
        CudaStreamBuilder::<CudaStreamBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaStreamBuilder<CudaStreamBuilderBuilt> {
    pub fn build(self) -> CudaStream {
        // Finalize and return CudaStream
        todo!("Implement CudaStream  construction")
    }
}

// Usage example:
// let obj = CudaStreamBuilder::new()
//     .create()
//     .cuda_stream_create_with_flags()
//     .cuda_stream_create_with_priority()
//     .build();

// Typestate builder for CudaUserObject
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaUserObjectBuilderInitial;
pub struct CudaUserObjectBuilderBuilt;

pub struct CudaUserObjectBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaUserObjectBuilder<CudaUserObjectBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaUserObjectBuilder<CudaUserObjectBuilderInitial> {
    pub fn cuda_user_object_create(self) -> CudaUserObjectBuilder<CudaUserObjectBuilderBuilt> {
        // Call FFI: cudaUserObjectCreate()
        CudaUserObjectBuilder::<CudaUserObjectBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaUserObjectBuilder<CudaUserObjectBuilderBuilt> {
    pub fn build(self) -> CudaUserObject {
        // Finalize and return CudaUserObject
        todo!("Implement CudaUserObject  construction")
    }
}

// Usage example:
// let obj = CudaUserObjectBuilder::new()
//     .create()
//     .build();

// Typestate builder for Usize
// Ensures compile-time enforcement of builder order

// State marker types
pub struct UsizeBuilderInitial;
pub struct UsizeBuilderBuilt;

pub struct UsizeBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl UsizeBuilder<UsizeBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl UsizeBuilder<UsizeBuilderInitial> {
    pub fn cudnn_init_transform_dest(self) -> UsizeBuilder<UsizeBuilderBuilt> {
        // Call FFI: cudnnInitTransformDest()
        UsizeBuilder::<UsizeBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl UsizeBuilder<UsizeBuilderBuilt> {
    pub fn build(self) -> Usize {
        // Finalize and return Usize
        todo!("Implement Usize  construction")
    }
}

// Usage example:
// let obj = UsizeBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaEvent
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaEventBuilderInitial;
pub struct CudaEventBuilderBuilt;

pub struct CudaEventBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaEventBuilder<CudaEventBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaEventBuilder<CudaEventBuilderInitial> {
    pub fn cuda_event_create(self) -> CudaEventBuilder<CudaEventBuilderBuilt> {
        // Call FFI: cudaEventCreate()
        CudaEventBuilder::<CudaEventBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
    pub fn cuda_event_create_with_flags(self) -> CudaEventBuilder<CudaEventBuilderBuilt> {
        // Call FFI: cudaEventCreateWithFlags()
        CudaEventBuilder::<CudaEventBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaEventBuilder<CudaEventBuilderBuilt> {
    pub fn build(self) -> CudaEvent {
        // Finalize and return CudaEvent
        todo!("Implement CudaEvent  construction")
    }
}

// Usage example:
// let obj = CudaEventBuilder::new()
//     .create()
//     .cuda_event_create_with_flags()
//     .build();

// Typestate builder for CudnnDropoutDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnDropoutDescriptorBuilderInitial;
pub struct CudnnDropoutDescriptorBuilderBuilt;

pub struct CudnnDropoutDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnDropoutDescriptorBuilder<CudnnDropoutDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnDropoutDescriptorBuilder<CudnnDropoutDescriptorBuilderInitial> {
    pub fn cudnn_create_dropout_descriptor(
        self,
    ) -> CudnnDropoutDescriptorBuilder<CudnnDropoutDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateDropoutDescriptor()
        CudnnDropoutDescriptorBuilder::<CudnnDropoutDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnDropoutDescriptorBuilder<CudnnDropoutDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnDropoutDescriptor {
        // Finalize and return CudnnDropoutDescriptor
        todo!("Implement CudnnDropoutDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnDropoutDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnCTCLossDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnCTCLossDescriptorBuilderInitial;
pub struct CudnnCTCLossDescriptorBuilderBuilt;

pub struct CudnnCTCLossDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnCTCLossDescriptorBuilder<CudnnCTCLossDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnCTCLossDescriptorBuilder<CudnnCTCLossDescriptorBuilderInitial> {
    pub fn cudnn_create_c_t_c_loss_descriptor(
        self,
    ) -> CudnnCTCLossDescriptorBuilder<CudnnCTCLossDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateCTCLossDescriptor()
        CudnnCTCLossDescriptorBuilder::<CudnnCTCLossDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnCTCLossDescriptorBuilder<CudnnCTCLossDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnCTCLossDescriptor {
        // Finalize and return CudnnCTCLossDescriptor
        todo!("Implement CudnnCTCLossDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnCTCLossDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnReduceTensorDescriptor
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnReduceTensorDescriptorBuilderInitial;
pub struct CudnnReduceTensorDescriptorBuilderBuilt;

pub struct CudnnReduceTensorDescriptorBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnReduceTensorDescriptorBuilder<CudnnReduceTensorDescriptorBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnReduceTensorDescriptorBuilder<CudnnReduceTensorDescriptorBuilderInitial> {
    pub fn cudnn_create_reduce_tensor_descriptor(
        self,
    ) -> CudnnReduceTensorDescriptorBuilder<CudnnReduceTensorDescriptorBuilderBuilt> {
        // Call FFI: cudnnCreateReduceTensorDescriptor()
        CudnnReduceTensorDescriptorBuilder::<CudnnReduceTensorDescriptorBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnReduceTensorDescriptorBuilder<CudnnReduceTensorDescriptorBuilderBuilt> {
    pub fn build(self) -> CudnnReduceTensorDescriptor {
        // Finalize and return CudnnReduceTensorDescriptor
        todo!("Implement CudnnReduceTensorDescriptor  construction")
    }
}

// Usage example:
// let obj = CudnnReduceTensorDescriptorBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnFusedOpsConstParamPack
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnFusedOpsConstParamPackBuilderInitial;
pub struct CudnnFusedOpsConstParamPackBuilderBuilt;

pub struct CudnnFusedOpsConstParamPackBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnFusedOpsConstParamPackBuilder<CudnnFusedOpsConstParamPackBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsConstParamPackBuilder<CudnnFusedOpsConstParamPackBuilderInitial> {
    pub fn cudnn_create_fused_ops_const_param_pack(
        self,
    ) -> CudnnFusedOpsConstParamPackBuilder<CudnnFusedOpsConstParamPackBuilderBuilt> {
        // Call FFI: cudnnCreateFusedOpsConstParamPack()
        CudnnFusedOpsConstParamPackBuilder::<CudnnFusedOpsConstParamPackBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsConstParamPackBuilder<CudnnFusedOpsConstParamPackBuilderBuilt> {
    pub fn build(self) -> CudnnFusedOpsConstParamPack {
        // Finalize and return CudnnFusedOpsConstParamPack
        todo!("Implement CudnnFusedOpsConstParamPack  construction")
    }
}

// Usage example:
// let obj = CudnnFusedOpsConstParamPackBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudaGraph
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudaGraphBuilderInitial;
pub struct CudaGraphBuilderBuilt;

pub struct CudaGraphBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudaGraphBuilder<CudaGraphBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaGraphBuilder<CudaGraphBuilderInitial> {
    pub fn cuda_graph_create(self) -> CudaGraphBuilder<CudaGraphBuilderBuilt> {
        // Call FFI: cudaGraphCreate()
        CudaGraphBuilder::<CudaGraphBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudaGraphBuilder<CudaGraphBuilderBuilt> {
    pub fn build(self) -> CudaGraph {
        // Finalize and return CudaGraph
        todo!("Implement CudaGraph  construction")
    }
}

// Usage example:
// let obj = CudaGraphBuilder::new()
//     .create()
//     .build();

// Typestate builder for CudnnFusedOpsVariantParamPack
// Ensures compile-time enforcement of builder order

// State marker types
pub struct CudnnFusedOpsVariantParamPackBuilderInitial;
pub struct CudnnFusedOpsVariantParamPackBuilderBuilt;

pub struct CudnnFusedOpsVariantParamPackBuilder<State> {
    _state: std::marker::PhantomData<State>,
    // Builder fields
}

impl CudnnFusedOpsVariantParamPackBuilder<CudnnFusedOpsVariantParamPackBuilderInitial> {
    pub fn new() -> Self {
        Self {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsVariantParamPackBuilder<CudnnFusedOpsVariantParamPackBuilderInitial> {
    pub fn cudnn_create_fused_ops_variant_param_pack(
        self,
    ) -> CudnnFusedOpsVariantParamPackBuilder<CudnnFusedOpsVariantParamPackBuilderBuilt> {
        // Call FFI: cudnnCreateFusedOpsVariantParamPack()
        CudnnFusedOpsVariantParamPackBuilder::<CudnnFusedOpsVariantParamPackBuilderBuilt> {
            _state: std::marker::PhantomData,
        }
    }
}

impl CudnnFusedOpsVariantParamPackBuilder<CudnnFusedOpsVariantParamPackBuilderBuilt> {
    pub fn build(self) -> CudnnFusedOpsVariantParamPack {
        // Finalize and return CudnnFusedOpsVariantParamPack
        todo!("Implement CudnnFusedOpsVariantParamPack  construction")
    }
}

// Usage example:
// let obj = CudnnFusedOpsVariantParamPackBuilder::new()
//     .create()
//     .build();

/// Platform detection utilities
#[cfg(test)]
mod platform_utils {
    /// Check if running on Windows
    #[cfg(target_os = "windows")]
    pub fn is_windows() -> bool {
        true
    }
    #[cfg(not(target_os = "windows"))]
    pub fn is_windows() -> bool {
        false
    }

    /// Check if running on Linux
    #[cfg(target_os = "linux")]
    pub fn is_linux() -> bool {
        true
    }
    #[cfg(not(target_os = "linux"))]
    pub fn is_linux() -> bool {
        false
    }

    /// Check if running on macOS
    #[cfg(target_os = "macos")]
    pub fn is_macos() -> bool {
        true
    }
    #[cfg(not(target_os = "macos"))]
    pub fn is_macos() -> bool {
        false
    }

    /// Check if running on Unix-like system
    #[cfg(unix)]
    pub fn is_unix() -> bool {
        true
    }
    #[cfg(not(unix))]
    pub fn is_unix() -> bool {
        false
    }

    /// Get current platform name
    pub fn current_platform() -> &'static str {
        if cfg!(target_os = "windows") {
            "Windows"
        } else if cfg!(target_os = "linux") {
            "Linux"
        } else if cfg!(target_os = "macos") {
            "macOS"
        } else if cfg!(unix) {
            "Unix"
        } else {
            "Unknown"
        }
    }
}
